{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First derivative, 3-layer CNN, relu activation, first stage, MSE, spectral bias experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import heapq\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset using the second derivative instead of the first\n",
    "\n",
    "The code currently loads a previously created dataset instead of creating a new one each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierSeriesDataset(Dataset):\n",
    "    def __init__(self, num_samples, num_points, max_terms=10):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_points = num_points\n",
    "        self.max_terms = max_terms\n",
    "        self.x = torch.linspace(0, 2*np.pi, num_points, requires_grad=True)\n",
    "        self.functions, self.first_derivatives, self.second_derivatives = self.generate_data()\n",
    "\n",
    "    def generate_data(self):\n",
    "        functions = []\n",
    "        first_derivatives = []\n",
    "        second_derivatives = []\n",
    "\n",
    "        for _ in range(self.num_samples):\n",
    "            # Generate random complex coefficients\n",
    "            n_terms = np.random.randint(1, self.max_terms + 1)\n",
    "            c = torch.complex(torch.randn(2*n_terms+1), torch.randn(2*n_terms+1))\n",
    "\n",
    "            # Compute function values\n",
    "            y = self.complex_fourier_series(self.x, c)\n",
    "            functions.append(y.detach().numpy())\n",
    "\n",
    "            # Compute derivative\n",
    "            dy_dx = torch.autograd.grad(y, self.x, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "            first_derivatives.append(dy_dx.detach().numpy())\n",
    "\n",
    "            d2y_dx2 = torch.autograd.grad(outputs=dy_dx, inputs=self.x, grad_outputs=torch.ones_like(dy_dx), create_graph=True)[0]\n",
    "            second_derivatives.append(d2y_dx2.detach().numpy())\n",
    "\n",
    "        return np.array(functions), np.array(first_derivatives), np.array(second_derivatives)\n",
    "\n",
    "    def complex_fourier_series(self, x, c, P=2*np.pi):\n",
    "        result = torch.zeros_like(x, dtype=torch.complex64)\n",
    "        n_terms = (len(c) - 1) // 2\n",
    "        for n in range(-n_terms, n_terms+1):\n",
    "            result += c[n + len(c)//2] * torch.exp(1j * 2 * np.pi * n * x / P)\n",
    "        return result.real\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.functions[idx]), torch.FloatTensor(self.first_derivatives[idx]), torch.FloatTensor(self.second_derivatives[idx])\n",
    "\n",
    "# Generate dataset\n",
    "num_samples = 10000\n",
    "num_points = 1000\n",
    "\n",
    "# Uncomment below to create dataset\n",
    "# dataset = FourierSeriesDataset(num_samples, num_points)\n",
    "\n",
    "# batch_size = 32\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# torch.save(dataset, 'datasets/both_derivatives_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # When using the workstation:\n",
    "dataset = torch.load('datasets/both_derivatives_dataset.pt')\n",
    "\n",
    "# # When using the cluster:\n",
    "# dataset = torch.load('both_derivatives_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function_and_derivative(dataloader):\n",
    "    # Get a single sample from the dataloader\n",
    "    dataiter = iter(dataloader)\n",
    "    function, derivative, second_derivative = next(dataiter)\n",
    "\n",
    "    # Since we're dealing with batches, let's take the first item in the batch\n",
    "    function = function[0].numpy()\n",
    "    derivative = derivative[0].numpy()\n",
    "    second_derivative = second_derivative[0].numpy()\n",
    "\n",
    "    # Create x-axis values (assuming the domain is [0, 2Ï€])\n",
    "    x = torch.linspace(0, 2*torch.pi, len(function)).numpy()\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, function, label='Function', color='blue')\n",
    "    plt.plot(x, derivative, label='First Derivative', linestyle='--')\n",
    "    plt.plot(x, second_derivative, label='Second Derivative', color='red', linestyle='--')\n",
    "    \n",
    "    plt.title('Fourier Series Function and its Second Derivative')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have already created your dataset and dataloader as before\n",
    "# dataset = FourierSeriesDataset(num_samples, num_points)\n",
    "\n",
    "def get_random_function(dataset, shuffle=True):\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=shuffle)\n",
    "\n",
    "train_dataloader_viz = get_random_function(dataset=train_dataset, shuffle=False)\n",
    "plot_function_and_derivative(train_dataloader_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the CNN uses three layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "model1 = SimpleCNN()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use model from cluster, use\n",
    "# model1.load_state_dict(torch.load('models/E1000_D1_3L_AFrelu_1S.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def model_training(model1, num_epochs, order=None):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    optimizer = optim.Adam(model1.parameters(), lr=1e-3)\n",
    "    for epoch in range(num_epochs):\n",
    "        model1.train()\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        for batch_functions, batch_derivatives, batch_second_derivatives in train_dataloader:\n",
    "            # Reshape input: [batch_size, 1, num_points]\n",
    "            batch_functions = batch_functions.unsqueeze(1)\n",
    "            batch_derivatives = batch_derivatives.unsqueeze(1)\n",
    "            batch_second_derivatives = batch_second_derivatives.unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model1(batch_functions)\n",
    "            loss = criterion(outputs, batch_derivatives)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        model1.eval()\n",
    "        with torch.no_grad():\n",
    "            for b_test_functions, b_test_derivatives, b_test_second_derivatives in test_dataloader:\n",
    "                b_test_functions = b_test_functions.unsqueeze(1)\n",
    "                b_test_derivatives = b_test_derivatives.unsqueeze(1)\n",
    "                b_test_second_derivatives = b_test_second_derivatives.unsqueeze(1)\n",
    "\n",
    "                test_outputs = model1(b_test_functions)\n",
    "                batch_test_loss = criterion(test_outputs, b_test_derivatives)\n",
    "\n",
    "                test_loss += batch_test_loss.item()\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "    \n",
    "    print(f\"Training finished for {order} derivative\")\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncomment below to train and save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses, test_losses = model_training(model1, 10, order='first')\n",
    "# torch.save(model1.state_dict(), 'models/E1000_D1_3L_AFrelu_1S.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = [], []\n",
    "def plot_losses(train_losses, test_losses, save_dir='plots', filename=None, save=False):\n",
    "    if not train_losses:\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, linestyle='-', color='b', label='Training Loss')\n",
    "    plt.plot(epochs, test_losses, linestyle='-', label='Test Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')  # Set the y-axis to logarithmic scale\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses=train_losses, test_losses=test_losses, filename='D1_3L_AFrelu_1S_loss', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(model1, order=None, save_dir='plots', filename=None, save=False): \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    model1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    train_dataloader_viz = get_random_function(dataset=train_dataset, shuffle=True)\n",
    "    # Get a random sample from the dataloader\n",
    "    dataiter = iter(train_dataloader_viz)\n",
    "    function, true_derivative, true_second_derivative = next(dataiter)\n",
    "\n",
    "    # Reshape the input for the model\n",
    "    function = function.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        if order == 1 or order == 2:\n",
    "            predicted_derivative = model1(function)\n",
    "        \n",
    "        if order == 'rollout':\n",
    "            predicted_derivative = model1(function)\n",
    "            predicted_derivative = model1(predicted_derivative)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    x = torch.linspace(0, 2*torch.pi, 1000).numpy()\n",
    "    function = function.squeeze().numpy()\n",
    "\n",
    "    predicted_derivative = predicted_derivative.squeeze().numpy()\n",
    "\n",
    "    true_derivative = true_derivative.squeeze().numpy()\n",
    "    true_second_derivative = true_second_derivative.squeeze().numpy()\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(x, function, label='Original Function', color='blue')\n",
    "    if order == 1:\n",
    "        plt.plot(x, true_derivative, label=f'True {order}st derivative')\n",
    "    if order == 2:\n",
    "        plt.plot(x, true_second_derivative, label=f'True {order}nd derivative')\n",
    "\n",
    "    plt.plot(x[10:-10], predicted_derivative[10:-10], label=f'Predicted {order}nd Derivative', linestyle='--')\n",
    "\n",
    "    plt.title('Function, True Derivatives, and Predicted Derivatives')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output(model1, order=1, filename='D1_3L_AFrelu_1S_output', save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy (MSE)\n",
    "\n",
    "MSE is computed as: $\\frac{1}{n} \\sum (y-f(x))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_combined_output(model1, model2, function_input, true_derivative):\n",
    "    # Predict the derivative from the first model\n",
    "    output = model1(function_input)\n",
    "\n",
    "    # Compute the residual and root mean squared error\n",
    "    residual = output.squeeze() - true_derivative\n",
    "    rms = torch.sqrt(torch.mean(residual**2))\n",
    "\n",
    "    # Predict the derivative from the second model\n",
    "    output2 = model2(function_input)\n",
    "\n",
    "    # Calculate the combined model output\n",
    "    combined_model_output = output + rms * output2\n",
    "\n",
    "    return combined_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(dataset, model1, model2=None):\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    model1.eval()\n",
    "    dataloader = DataLoader(dataset)\n",
    "    for function, deriv, second_deriv in dataloader:\n",
    "        function = function.unsqueeze(1)\n",
    "        deriv = deriv.unsqueeze(1)\n",
    "        second_deriv = second_deriv.unsqueeze(1)\n",
    "\n",
    "        # Compute model output\n",
    "        if model2:\n",
    "            model2.eval()\n",
    "            model_output = calculate_combined_output(model1, model2, function, deriv)\n",
    "            all_targets.append(deriv)\n",
    "        else:\n",
    "            model_output = model1(function)\n",
    "            all_targets.append(deriv)\n",
    "\n",
    "        # Collect outputs\n",
    "        all_outputs.append(model_output)\n",
    "\n",
    "    # Concatenate all collected outputs and targets\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    # Compute MSE\n",
    "    mse = torch.mean((all_outputs - all_targets) ** 2)\n",
    "    # print(f\"Overall MSE over all test functions: {mse.item()}\")\n",
    "    return mse.item()\n",
    "\n",
    "print(f\"MSE over all functions: {compute_mse(test_dataset, model1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized MSE\n",
    "\n",
    "NMSE is computed as: $\\frac{1}{n} \\frac{\\sum (y-f(x))^2}{\\sum y^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nmse(dataset, model1, model2=None):\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    model1.eval()\n",
    "    dataloader = DataLoader(dataset)\n",
    "    for function, deriv, second_deriv in dataloader:\n",
    "        function = function.unsqueeze(1)\n",
    "        deriv = deriv.unsqueeze(1)\n",
    "        second_deriv = second_deriv.unsqueeze(1)\n",
    "\n",
    "        # Compute model output\n",
    "        if model2:\n",
    "            model2.eval()\n",
    "            model_output = calculate_combined_output(model1, model2, function, deriv)\n",
    "            all_targets.append(deriv)\n",
    "        else:\n",
    "            model_output = model1(function)\n",
    "            all_targets.append(deriv)\n",
    "\n",
    "        # Collect outputs\n",
    "        all_outputs.append(model_output)\n",
    "\n",
    "    # Concatenate all collected outputs and targets\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    # Compute MSE\n",
    "    mse = torch.mean((all_outputs - all_targets) ** 2)\n",
    "    normalizing_factor = torch.mean(all_targets ** 2)\n",
    "\n",
    "    nmse = mse / normalizing_factor\n",
    "\n",
    "    # print(f\"Overall NMSE over all test functions: {nmse.item()}\")\n",
    "    return nmse.item()\n",
    "print(f\"NMSE over all functions: {compute_nmse(test_dataset, model1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral biases from Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_frequency(function):\n",
    "    fft_coeffs = np.fft.fft(function)\n",
    "    freqs = np.fft.fftfreq(len(function))\n",
    "    power_spectrum = np.abs(fft_coeffs)**2\n",
    "    significant_freqs = freqs[power_spectrum > (np.max(power_spectrum) * 0.01)]\n",
    "    return np.median(np.abs(significant_freqs))\n",
    "\n",
    "def categorize_functions(dataloader):\n",
    "    functions_with_freqs = []\n",
    "    \n",
    "    for functions, derivatives, sec_derivative in dataloader:\n",
    "        for idx, function in enumerate(functions):\n",
    "            median_frequency = calculate_median_frequency(function.numpy())\n",
    "            functions_with_freqs.append((function.numpy(), derivatives[idx].numpy(), sec_derivative[idx].numpy(), median_frequency))\n",
    "    \n",
    "    # Sort by median frequency\n",
    "    functions_with_freqs.sort(key=lambda x: x[3])\n",
    "    \n",
    "    # Split into low and high frequency datasets\n",
    "    mid_index = len(functions_with_freqs) // 2\n",
    "    low_freq_dataset = functions_with_freqs[:mid_index]\n",
    "    high_freq_dataset = functions_with_freqs[mid_index:]\n",
    "    \n",
    "    # Create new DataLoaders, excluding the median frequency from the data\n",
    "    # Each dataloader contains the function, deriv, and second deriv\n",
    "    low_freq_dataloader = [(f[0], f[1], f[2]) for f in low_freq_dataset]\n",
    "    high_freq_dataloader = [(f[0], f[1], f[2]) for f in high_freq_dataset]\n",
    "    \n",
    "    return low_freq_dataloader, high_freq_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the test dataset to compute frequencies\n",
    "# Should be half of full dataset in each dataloader\n",
    "low_freq_dataset, high_freq_dataset = categorize_functions(test_dataloader)\n",
    "\n",
    "print(f\"Low frequency dataset size: {len(low_freq_dataset)}\")\n",
    "print(f\"High frequency dataset size: {len(high_freq_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference(model1, dataset, save_dir='plots', filename=None, save=False):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    def plot_sliced(x, y, label, linestyle='-'):\n",
    "        plt.plot(x[10:-10], y[10:-10], label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))  # Adjust figure size for a 2x2 grid\n",
    "    \n",
    "    for i in range(1, 5):  # Loop over four different functions\n",
    "        train_dataloader_viz = get_random_function(dataset, shuffle=True)\n",
    "        dataiter = iter(train_dataloader_viz)\n",
    "        function, true_derivative, true_second_derivative = next(dataiter)\n",
    "\n",
    "        function = function.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            predicted_derivative = model1(function)\n",
    "            first_deriv_diff = true_derivative - predicted_derivative\n",
    "\n",
    "            predicted_second_derivative = model1(predicted_derivative)\n",
    "            second_deriv_diff = true_second_derivative - predicted_second_derivative\n",
    "\n",
    "        # Convert tensors to numpy arrays for plotting\n",
    "        x = torch.linspace(0, 2*torch.pi, 1000).numpy()\n",
    "        function = function.squeeze().numpy()\n",
    "        true_derivative = true_derivative.squeeze().numpy()\n",
    "        true_second_derivative = true_second_derivative.squeeze().numpy()\n",
    "        \n",
    "        first_deriv_diff = first_deriv_diff.squeeze().numpy()\n",
    "        second_deriv_diff = second_deriv_diff.squeeze().numpy()\n",
    "\n",
    "        plt.subplot(2, 2, i)  # Adjust subplot position\n",
    "        plot_sliced(x, function, '$u$')\n",
    "        plot_sliced(x, first_deriv_diff, \"$u'_g - u'_{\\\\theta}$\", linestyle='--')\n",
    "        # plot_sliced(x, true_derivative, \"$u'_g$\")\n",
    "        # plot_sliced(x, true_second_derivative, \"$u''_g$\", linestyle='--')\n",
    "\n",
    "        plt.title(f'Difference for Function {i}')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        mse = np.mean((first_deriv_diff) ** 2)\n",
    "        nmse = mse / np.mean(true_derivative ** 2)\n",
    "\n",
    "        print(f\"MSE for function {i} is: {mse}\")        \n",
    "        print(f\"NMSE for function {i} is: {nmse}\\n\")        \n",
    "\n",
    "    if save:\n",
    "        save_path = os.path.join(save_dir, filename if filename else 'multi_plot.png')\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference2(model1, dataset, save_dir='plots', filename=None, save=False):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    def plot_sliced(x, y, label, linestyle='-'):\n",
    "        plt.plot(x[10:-10], y[10:-10], label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.figure(figsize=(12, 6*4))  # Adjust figure size for side-by-side plots\n",
    "    \n",
    "    for i in range(1, 5):  # Loop over four different functions\n",
    "        train_dataloader_viz = get_random_function(dataset, shuffle=True)\n",
    "        dataiter = iter(train_dataloader_viz)\n",
    "        function, true_derivative, true_second_derivative = next(dataiter)\n",
    "\n",
    "        function = function.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            predicted_derivative = model1(function)\n",
    "            first_deriv_diff = true_derivative - predicted_derivative\n",
    "\n",
    "            predicted_second_derivative = model1(predicted_derivative)\n",
    "            second_deriv_diff = true_second_derivative - predicted_second_derivative\n",
    "\n",
    "        # Convert tensors to numpy arrays for plotting\n",
    "        x = torch.linspace(0, 2*torch.pi, 1000).numpy()\n",
    "        function = function.squeeze().numpy()\n",
    "        true_derivative = true_derivative.squeeze().numpy()\n",
    "        true_second_derivative = true_second_derivative.squeeze().numpy()\n",
    "        \n",
    "        first_deriv_diff = first_deriv_diff.squeeze().numpy()\n",
    "        second_deriv_diff = second_deriv_diff.squeeze().numpy()\n",
    "\n",
    "        # Plot original function and its derivative\n",
    "        plt.subplot(4, 2, 2*i-1)  # Adjust subplot position for original function\n",
    "        plot_sliced(x, function, '$u$', linestyle='-')\n",
    "        # plot_sliced(x, true_derivative, \"$u'$\", linestyle='--')\n",
    "        plt.title(f'Function {i} and its derivative')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot difference (error)\n",
    "        plt.subplot(4, 2, 2*i)  # Adjust subplot position for difference plot\n",
    "        plot_sliced(x, first_deriv_diff, \"$u'_g - u'_{\\\\theta}$\", linestyle='--')\n",
    "        plt.title(f'Error in derivative for Function {i}')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        mse = np.mean((first_deriv_diff) ** 2)\n",
    "        nmse = mse / np.mean(true_derivative ** 2)\n",
    "\n",
    "        print(f\"MSE for function {i} is: {mse}\")        \n",
    "        print(f\"NMSE for function {i} is: {nmse}\\n\")        \n",
    "\n",
    "    if save:\n",
    "        save_path = os.path.join(save_dir, filename if filename else 'multi_plot.png')\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New CNN to analyze spectral bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "model2 = SimpleCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From 0-200 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = model_training(model2, 200, order='first')\n",
    "torch.save(model2.state_dict(), 'models/E200_D1_3L_AFrelu_SB.pth')\n",
    "plot_losses(train_losses=train_losses, test_losses=test_losses, save_dir='plots/spectral_bias', filename='E200_D1_3L_AFrelu_loss', save=save)\n",
    "plot_output(model2, order=1, save_dir='plots/spectral_bias', filename='E200_D1_3L_AFrelu_output', save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Epochs 0-200:\\n\")\n",
    "print(f\"MSE over low freq functions: {compute_mse(low_freq_dataset, model2)}\")\n",
    "print(f\"MSE over high freq functions: {compute_mse(high_freq_dataset, model2)}\")\n",
    "print()\n",
    "\n",
    "print(f\"NMSE over low freq functions: {compute_nmse(low_freq_dataset, model2)}\")\n",
    "print(f\"NMSE over high freq functions: {compute_nmse(high_freq_dataset, model2)}\")\n",
    "print()\n",
    "\n",
    "print(f\"MSE over all functions: {compute_mse(test_dataset, model2)}\")\n",
    "print(f\"NMSE over all functions: {compute_nmse(test_dataset, model2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From 200-600 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = model_training(model2, 400, order='first')\n",
    "torch.save(model2.state_dict(), 'models/E600_D1_3L_AFrelu_SB.pth')\n",
    "plot_losses(train_losses=train_losses, test_losses=test_losses, save_dir='plots/spectral_bias', filename='E600_D1_3L_AFrelu_loss', save=save)\n",
    "plot_output(model2, order=1, save_dir='plots/spectral_bias', filename='E600_D1_3L_AFrelu_output', save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Epochs 200-600:\\n\")\n",
    "print(f\"MSE over low freq functions: {compute_mse(low_freq_dataset, model2)}\")\n",
    "print(f\"MSE over high freq functions: {compute_mse(high_freq_dataset, model2)}\")\n",
    "print()\n",
    "\n",
    "print(f\"NMSE over low freq functions: {compute_nmse(low_freq_dataset, model2)}\")\n",
    "print(f\"NMSE over high freq functions: {compute_nmse(high_freq_dataset, model2)}\")\n",
    "print()\n",
    "\n",
    "print(f\"MSE over all functions: {compute_mse(test_dataset, model2)}\")\n",
    "print(f\"NMSE over all functions: {compute_nmse(test_dataset, model2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From 600-1000 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = model_training(model2, 400, order='first')\n",
    "torch.save(model2.state_dict(), 'models/E1000_D1_3L_AFrelu_SB.pth')\n",
    "plot_losses(train_losses=train_losses, test_losses=test_losses, save_dir='plots/spectral_bias', filename='E1000_D1_3L_AFrelu_loss', save=save)\n",
    "plot_output(model2, order=1, save_dir='plots/spectral_bias', filename='E1000_D1_3L_AFrelu_output', save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Epochs 600-1000:\\n\")\n",
    "print(f\"MSE over low freq functions: {compute_mse(low_freq_dataset, model2)}\")\n",
    "print(f\"MSE over high freq functions: {compute_mse(high_freq_dataset, model2)}\")\n",
    "print()\n",
    "\n",
    "print(f\"NMSE over low freq functions: {compute_nmse(low_freq_dataset, model2)}\")\n",
    "print(f\"NMSE over high freq functions: {compute_nmse(high_freq_dataset, model2)}\")\n",
    "print()\n",
    "\n",
    "print(f\"MSE over all functions: {compute_mse(test_dataset, model2)}\")\n",
    "print(f\"NMSE over all functions: {compute_nmse(test_dataset, model2)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
