{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook has the training colormap plots that show spectral information\n",
    "\n",
    "8/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import heapq\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set save to True if you want to save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for python script: uncomment if running on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are both placeholders\n",
    "num_epochs = 1000\n",
    "model_name = 'f0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse command-line arguments\n",
    "# parser = argparse.ArgumentParser(description='Train a neural network model')\n",
    "# parser.add_argument('--epochs', type=int, default=1000, help='Number of training epochs')\n",
    "# parser.add_argument('--model_name', type=str, default='model', help='Name of the saved model')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # Use the parsed arguments\n",
    "# num_epochs = args.epochs\n",
    "# model_name = args.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simplified function generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_freq_dataset(num_samples, num_points, min_freq, max_freq):\n",
    "    x = torch.linspace(0, 2 * np.pi, num_points, requires_grad=True)\n",
    "    functions = []\n",
    "    derivatives = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # The number of different frequency components will be between 1 and 10\n",
    "        num_freqs = torch.randint(1, 10, (1,)).item()\n",
    "        amplitudes = torch.rand(num_freqs * 2)  # Double the number of amplitudes (between 0 and 1)\n",
    "        frequencies = torch.randint(min_freq, max_freq + 1, (num_freqs,)).float()\n",
    "        phases = torch.rand(num_freqs * 2) * 2 * np.pi  # Double the number of phases\n",
    "        \n",
    "        y = sum(a * torch.sin(f * x + p) for a, f, p in zip(amplitudes[:num_freqs], frequencies, phases[:num_freqs])) + \\\n",
    "            sum(a * torch.cos(f * x + p) for a, f, p in zip(amplitudes[num_freqs:], frequencies, phases[num_freqs:]))\n",
    "        \n",
    "        dy_dx = torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "        \n",
    "        functions.append(y.detach().numpy())\n",
    "        derivatives.append(dy_dx.detach().numpy())\n",
    "    \n",
    "    return np.array(functions), np.array(derivatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "num_points = 1000\n",
    "batch_size = 32\n",
    "\n",
    "low_freq_functions, low_freq_derivatives = generate_freq_dataset(num_samples, num_points, 1, 5)\n",
    "general_freq_functions, general_freq_derivatives = generate_freq_dataset(num_samples, num_points, 1, 10)\n",
    "high_freq_functions, high_freq_derivatives = generate_freq_dataset(num_samples, num_points, 6, 10)\n",
    "\n",
    "low_freq_dataset = TensorDataset(torch.tensor(low_freq_functions), torch.tensor(low_freq_derivatives))\n",
    "general_freq_dataset = TensorDataset(torch.tensor(general_freq_functions), torch.tensor(general_freq_derivatives))\n",
    "high_freq_dataset = TensorDataset(torch.tensor(high_freq_functions), torch.tensor(high_freq_derivatives))\n",
    "\n",
    "low_freq_dataloader = DataLoader(TensorDataset(torch.tensor(low_freq_functions), torch.tensor(low_freq_derivatives)), batch_size=batch_size, shuffle=True)\n",
    "high_freq_dataloader = DataLoader(TensorDataset(torch.tensor(high_freq_functions), torch.tensor(high_freq_derivatives)), batch_size=batch_size, shuffle=True)\n",
    "general_freq_dataloader = DataLoader(TensorDataset(torch.tensor(general_freq_functions), torch.tensor(general_freq_derivatives)), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(low_freq_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# low freq\n",
    "train_dataset_l, test_dataset_l = random_split(low_freq_dataset, [train_size, test_size], generator=generator)\n",
    "train_dataloader_l = DataLoader(train_dataset_l, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader_l = DataLoader(test_dataset_l, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "# general freq\n",
    "train_dataset_g, test_dataset_g = random_split(general_freq_dataset, [train_size, test_size], generator=generator)\n",
    "train_dataloader_g = DataLoader(train_dataset_g, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader_g = DataLoader(test_dataset_g, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "# high freq\n",
    "train_dataset_h, test_dataset_h = random_split(high_freq_dataset, [train_size, test_size], generator=generator)\n",
    "train_dataloader_h = DataLoader(train_dataset_h, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader_h = DataLoader(test_dataset_h, batch_size=32, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot random function from one of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(32)\n",
    "\n",
    "fun, deriv = next(iter(low_freq_dataloader))\n",
    "\n",
    "first_function = fun[a]\n",
    "first_derivative = deriv[a]\n",
    "\n",
    "# Generate x values corresponding to the function inputs\n",
    "x_values = np.linspace(0, 2 * np.pi, 1000)\n",
    "\n",
    "# Plotting the function and its derivative\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, first_function, label='Function')\n",
    "plt.plot(x_values, first_derivative, label='Derivative')\n",
    "plt.title('Function and Its Derivative')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "# torch.save(general_freq_dataset, 'datasets/general_freq_dataset.pt')\n",
    "# torch.save(low_freq_dataset, 'datasets/low_freq_dataset.pt')\n",
    "# torch.save(high_freq_dataset, 'datasets/high_freq_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN uses 3 layers, each with kernel size 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = SimpleCNN()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, test_losses, save_dir='plots', filename=None, save=False):\n",
    "    if not train_losses:\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, linestyle='-', color='b', label='Training Loss')\n",
    "    plt.plot(epochs, test_losses, linestyle='-', label='Test Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')  # Set the y-axis to logarithmic scale\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(model1, dataset, order=None, save_dir='plots', filename=None, save=False): \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    model1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    train_dataloader_viz = get_random_function(dataset, shuffle=True)\n",
    "    # Get a random sample from the dataloader\n",
    "    dataiter = iter(train_dataloader_viz)\n",
    "    function, true_derivative = next(dataiter)\n",
    "\n",
    "    # Reshape the input for the model\n",
    "    function = function.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        if order == 1 or order == 2:\n",
    "            predicted_derivative = model1(function)\n",
    "        \n",
    "        if order == 'rollout':\n",
    "            predicted_derivative = model1(function)\n",
    "            predicted_derivative = model1(predicted_derivative)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    x = torch.linspace(0, 2*torch.pi, 1000).numpy()\n",
    "    function = function.squeeze().numpy()\n",
    "\n",
    "    predicted_derivative = predicted_derivative.squeeze().numpy()\n",
    "\n",
    "    true_derivative = true_derivative.squeeze().numpy()\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(x, function, label='Original Function', color='blue')\n",
    "    if order == 1:\n",
    "        plt.plot(x, true_derivative, label=f'True {order}st derivative')\n",
    "\n",
    "    plt.plot(x[10:-10], predicted_derivative[10:-10], label=f'Predicted {order}nd Derivative', linestyle='--')\n",
    "\n",
    "    plt.title('Function, True Derivatives, and Predicted Derivatives')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_function(dataset, shuffle=True):\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, n_layers=3, kernel_size=3, hidden_size=64):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Parameters\n",
    "        self.n_layers = n_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Model\n",
    "        self.convs = nn.ModuleList()\n",
    "        if n_layers == 1:\n",
    "            self.convs.append(nn.Conv1d(1, 1, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "        elif n_layers >= 2:\n",
    "            self.convs.append(nn.Conv1d(1, hidden_size, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "            for _ in range(n_layers - 2):\n",
    "                self.convs.append(nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "            self.convs.append(nn.Conv1d(hidden_size, 1, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = self.relu(conv(x))\n",
    "            else:\n",
    "                x = conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests to see model output frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequencies(function, derivative=None, residue=None, model=None):\n",
    "    x = np.linspace(0, 2*np.pi, 1000)\n",
    "    first_function = function\n",
    "\n",
    "    N = 1000\n",
    "\n",
    "    # frequencies = torch.fft.fftfreq(N, 2*np.pi/N) * 2*np.pi\n",
    "    frequencies = np.fft.fftfreq(N, 1/N)\n",
    "    positive_freq_indices = frequencies >= 0\n",
    "    positive_freqs = frequencies[positive_freq_indices]\n",
    "\n",
    "    F = np.fft.fft(first_function.detach().numpy())\n",
    "    magnitudes = np.abs(F) / N\n",
    "    positive_magnitudes = magnitudes[positive_freq_indices]\n",
    "\n",
    "    if residue:\n",
    "        model.eval()\n",
    "        F_derivative = np.fft.fft(derivative.detach().numpy())\n",
    "        F_output = np.fft.fft(model(function.unsqueeze(0)).squeeze().detach().numpy())\n",
    "\n",
    "        F_residue = F_derivative - F_output\n",
    "        magnitudes = np.abs(F_residue) / N\n",
    "        print(\"residue\")\n",
    "\n",
    "\n",
    "    # Plotting the frequency spectrum\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(positive_freqs, positive_magnitudes, label='Function')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Magnitude')\n",
    "    plt.title('Frequency Spectrum of the Function')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 20)  # Adjust this based on your frequency range\n",
    "    print(f\"lim: 18\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0, 32)\n",
    "function = test_dataset_g[a][0]\n",
    "derivative = test_dataset_g[a][1]\n",
    "\n",
    "plot_frequencies(derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "L3ModelK3 = SimpleCNN(n_layers=3, kernel_size=3)\n",
    "L3ModelK3.load_state_dict(torch.load('../../models/3_layers.pth'))\n",
    "\n",
    "L3ModelK3_untrained = SimpleCNN(n_layers=3, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function1 = function.unsqueeze(0)\n",
    "output = L3ModelK3(function1).squeeze()\n",
    "plot_frequencies(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_frequencies(function=function, derivative=derivative, residue=True, model=L3ModelK3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(dataloader, model):\n",
    "    \"\"\"\n",
    "    Takes in a dataloader and a model to compute MSE.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    for function, deriv in dataloader:\n",
    "        function = function.unsqueeze(1)\n",
    "        deriv = deriv.unsqueeze(1)\n",
    "\n",
    "        # Compute model output\n",
    "        model_output = model(function)\n",
    "        all_targets.append(deriv)\n",
    "\n",
    "        # Collect outputs\n",
    "        all_outputs.append(model_output)\n",
    "\n",
    "    # Concatenate all collected outputs and targets\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    # Compute MSE\n",
    "    mse = torch.mean((all_targets - all_outputs) ** 2)\n",
    "    nmse = mse / torch.mean(all_targets ** 2)\n",
    "\n",
    "    return mse.item(), nmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_store_metrics(f0):\n",
    "    return compute_mse(train_dataloader_l, f0)[1], compute_mse(train_dataloader_g, f0)[1], compute_mse(train_dataloader_h, f0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model):\n",
    "    print(f\"NMSE over low freq test functions: {compute_mse(test_dataloader_l, model)[1]}\")\n",
    "    print(f\"NMSE over general freq test functions: {compute_mse(test_dataloader_g, model)[1]}\")\n",
    "    print(f\"NMSE over high freq test functions: {compute_mse(test_dataloader_h, model)[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_outputs(model, model_name):\n",
    "    plot_output(model, dataset=test_dataset_l, order=1, save_dir='../plots/spectral_bias', filename=f'{model_name}_E{num_epochs}_lf_output', save=save)\n",
    "    plot_output(model, dataset=test_dataset_g, order=1, save_dir='../plots/spectral_bias', filename=f'{model_name}_E{num_epochs}_lf_output', save=save)\n",
    "    plot_output(model, dataset=test_dataset_h, order=1, save_dir='../plots/spectral_bias', filename=f'{model_name}_E{num_epochs}_lf_output', save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color map plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMS(x):\n",
    "    return torch.sqrt(torch.mean(x**2, dim=1)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft_and_max_freq(dataloader, deriv=False, model=None, residue=False):\n",
    "    fft_amplitudes = []\n",
    "    max_frequencies = []\n",
    "    T = 2 * torch.pi\n",
    "    N = 1000\n",
    "\n",
    "    # The spacing is T / N, i.e. 2pi/1000, but since we interpret f(x)=sin(5x) to\n",
    "    # have a frequency of 5 over the domain x=[0,2pi], then we scale up by 2pi \n",
    "    # to get the unit cycle back to 1\n",
    "    frequencies = torch.fft.fftfreq(N, T / N) * T\n",
    "    positive_freq_indices = frequencies >= 0\n",
    "    positive_freqs = frequencies[positive_freq_indices]\n",
    "\n",
    "    plot_type = ''\n",
    "\n",
    "    # Iterate over each batch\n",
    "    for functions, derivatives in dataloader:  # Note that derivatives are ignored in this loop\n",
    "        \n",
    "        if deriv and not model and not residue: # If you only want the derivative\n",
    "            functions = derivatives\n",
    "            F = torch.fft.fft(functions)\n",
    "            plot_type = \"ground truth u_g'\"\n",
    "            \n",
    "            \n",
    "        elif not deriv and model and not residue: # If you only want the model output\n",
    "            functions = model(functions.unsqueeze(1)).squeeze()\n",
    "            F = torch.fft.fft(functions)\n",
    "            plot_type = 'model output f(u_g)'\n",
    "\n",
    "            # output = model(functions)\n",
    "            \n",
    "            # output = output.squeeze()\n",
    "            # functions = output # set this so that the FFTs can be computed in the next line\n",
    "        \n",
    "        elif residue == 'error of fourier' and model: # If you only want the spectral error\n",
    "            functions = functions.unsqueeze(1)\n",
    "            outputs = model(functions).squeeze()\n",
    "            F_outputs = torch.fft.fft(outputs)\n",
    "            F_derivatives = torch.fft.fft(derivatives)\n",
    "            residues = F_derivatives - F_outputs\n",
    "            # F = residues / RMS(F_derivatives)\n",
    "            F = torch.abs(residues) / torch.abs(F_derivatives)\n",
    "            plot_type = 'spectral error'\n",
    "\n",
    "        \n",
    "        elif residue == 'fourier of error' and model:\n",
    "            functions = functions.unsqueeze(1)\n",
    "            outputs = model(functions).squeeze()\n",
    "\n",
    "            residues = derivatives - outputs\n",
    "            F = torch.fft.fft(residues)\n",
    "            plot_type = 'fourier transform of error'\n",
    "\n",
    "        else:\n",
    "            plot_type = 'ground truth u_g'\n",
    "            F = torch.fft.fft(functions)\n",
    "\n",
    "        # else: # If you only want the original function u_g\n",
    "        magnitudes = torch.abs(F) / N\n",
    "\n",
    "        # Consider only positive frequencies\n",
    "        positive_magnitudes = magnitudes[:, positive_freq_indices]\n",
    "\n",
    "        fft_amplitudes.append(positive_magnitudes)\n",
    "        \n",
    "        # Maximum frequency based on the highest amplitude for each function in the batch\n",
    "        max_indices = torch.argmax(positive_magnitudes, dim=1)\n",
    "        batch_max_freqs = positive_freqs[max_indices]\n",
    "        max_frequencies.extend(batch_max_freqs)\n",
    "    \n",
    "    print(f\"Plotting {plot_type}\")\n",
    "\n",
    "    return torch.vstack(fft_amplitudes), torch.tensor(max_frequencies), positive_freqs, plot_type\n",
    "\n",
    "def plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type, xmin=0, xmax=0,\\\n",
    "    first=False, sorted_indices=None):\n",
    "\n",
    "    fft_amplitudes = fft_amplitudes.detach().numpy()\n",
    "    max_frequencies = max_frequencies.detach().numpy()\n",
    "    freqs = freqs.detach().numpy()\n",
    "\n",
    "    \n",
    "    if first:\n",
    "        print(\"Sorting u_g for the first time\")\n",
    "        # Sort functions by dominant frequency in descending order\n",
    "        sorted_indices = np.argsort(-max_frequencies) \n",
    "        sorted_fft = fft_amplitudes[sorted_indices]\n",
    "    else:\n",
    "        print(\"Using predefined sort\")\n",
    "        sorted_fft = fft_amplitudes[sorted_indices]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # im = plt.imshow(sorted_fft, aspect='auto', extent=[freqs[0], freqs[-1], 0, len(sorted_fft)],\\\n",
    "    #     interpolation='nearest')\n",
    "    im = plt.imshow(sorted_fft, aspect='auto', extent=[freqs[0], freqs[-1], 0, len(sorted_fft)],\n",
    "                     interpolation='nearest', norm = LogNorm(vmin=0.01, vmax=10))\n",
    "\n",
    "    plt.colorbar(im, label='Amplitude')\n",
    "    plt.xlabel('Frequency (rad/s)')\n",
    "    plt.ylabel('Function Index (sorted by max frequency)')\n",
    "    plt.title(f'FFT Amplitude Heatmap for {fun_type}')\n",
    "    plt.xlim([xmin, xmax])\n",
    "    \n",
    "\n",
    "    if first:\n",
    "        return sorted_indices\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is for showing the side by side of spectral error and model output\n",
    "def plot_combined_heatmap(fft_amplitudes1, max_frequencies1, freqs1, fun_type1,\\\n",
    "    fft_amplitudes2, max_frequencies2, freqs2, fun_type2,\\\n",
    "    xmin=0, xmax=0, first=False, sorted_indices=None):\n",
    "\n",
    "    fft_amplitudes1 = fft_amplitudes1.detach().numpy()\n",
    "    max_frequencies1 = max_frequencies1.detach().numpy()\n",
    "    freqs1 = freqs1.detach().numpy()\n",
    "\n",
    "    fft_amplitudes2 = fft_amplitudes2.detach().numpy()\n",
    "    max_frequencies2 = max_frequencies2.detach().numpy()\n",
    "    freqs2 = freqs2.detach().numpy()\n",
    "\n",
    "    \n",
    "    if first:\n",
    "        print(\"Sorting u_g for the first time\")\n",
    "        # Sort functions by dominant frequency in descending order\n",
    "        sorted_indices1 = np.argsort(-max_frequencies1) \n",
    "        sorted_fft1 = fft_amplitudes1[sorted_indices]\n",
    "\n",
    "        sorted_indices2 = np.argsort(-max_frequencies2) \n",
    "        sorted_fft2 = fft_amplitudes2[sorted_indices]\n",
    "    else:\n",
    "        print(\"Using predefined sort\")\n",
    "        sorted_fft1 = fft_amplitudes1[sorted_indices]\n",
    "        sorted_fft2 = fft_amplitudes2[sorted_indices]\n",
    "\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12))\n",
    "\n",
    "    # Plot the first heatmap\n",
    "    im1 = ax1.imshow(sorted_fft1, aspect='auto', extent=[freqs1[0], freqs1[-1], 0, len(sorted_fft1)],\n",
    "                     interpolation='nearest')\n",
    "    ax1.set_xlabel('Frequency (rad/s)')\n",
    "    ax1.set_ylabel('Function Index (sorted by max frequency)')\n",
    "    ax1.set_title(f'FFT Amplitude Heatmap for {fun_type1}')\n",
    "    ax1.set_xlim([xmin, xmax])\n",
    "    fig.colorbar(im1, ax=ax1, label='Amplitude')\n",
    "\n",
    "    # Plot the second heatmap\n",
    "    # im2 = ax2.imshow(sorted_fft2, aspect='auto', extent=[freqs2[0], freqs2[-1], 0, len(sorted_fft2)],\n",
    "    #                  interpolation='nearest', vmax=0.005)\n",
    "\n",
    "    im2 = ax2.imshow(sorted_fft2, aspect='auto', extent=[freqs2[0], freqs2[-1], 0, len(sorted_fft2)],\n",
    "                     interpolation='nearest', norm = LogNorm(vmin=0.01, vmax=10))\n",
    "    ax2.set_xlabel('Frequency (rad/s)')\n",
    "    ax2.set_ylabel('Function Index (sorted by max frequency)')\n",
    "    ax2.set_title(f'FFT Amplitude Heatmap for {fun_type2}')\n",
    "    ax2.set_xlim([xmin, xmax])\n",
    "    fig.colorbar(im2, ax=ax2, label='Amplitude')\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if first:\n",
    "        return sorted_indices1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is u_g\n",
    "# This function plots the heatmaps for all frequencies for the test datlaoaders\n",
    "def plot_heatmaps(deriv=None, model=None, residue=False, label=None, all=True, epoch=None,\\\n",
    "    first=False, sorted_indices=None):\n",
    "    if all: # Plot all three datasets\n",
    "        fft_amplitudes, max_frequencies, freqs, label = compute_fft_and_max_freq(test_dataloader_l,\\\n",
    "            deriv=deriv, model=model, residue=residue)\n",
    "        plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'Low freq {label} at epoch {epoch}',\\\n",
    "            xmin=0, xmax=6, sorted_indices=sorted_indices, first=first)\n",
    "\n",
    "        fft_amplitudes, max_frequencies, freqs, label = compute_fft_and_max_freq(test_dataloader_g,\\\n",
    "            deriv=deriv, model=model, residue=residue)\n",
    "        plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'General freq {label} at epoch {epoch}',\\\n",
    "            xmin=0, xmax=11, sorted_indices=sorted_indices, first=first)\n",
    "\n",
    "        fft_amplitudes, max_frequencies, freqs, label = compute_fft_and_max_freq(test_dataloader_h,\\\n",
    "            deriv=deriv, model=model, residue=residue)\n",
    "        plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'High freq {label} at epoch {epoch}',\\\n",
    "            xmin=6, xmax=11, sorted_indices=sorted_indices, first=first)\n",
    "\n",
    "    else: # Plot only the general frequency dataset\n",
    "        if model and residue:\n",
    "            print(\"got the new amplitudes\")\n",
    "            # Get only the model outputs\n",
    "            fft_amplitudes_model, max_frequencies_model, freqs_model, label_model = compute_fft_and_max_freq(test_dataloader_g,\\\n",
    "            deriv=deriv, model=model, residue=None)\n",
    "            # Get only the residue\n",
    "            fft_amplitudes_res, max_frequencies_res, freqs_res, label_res = compute_fft_and_max_freq(test_dataloader_g,\\\n",
    "            deriv=deriv, model=model, residue=residue)\n",
    "        else: # If we don't want the model or residue plots, then use passed in settings\n",
    "            fft_amplitudes, max_frequencies, freqs, label = compute_fft_and_max_freq(test_dataloader_g,\\\n",
    "            deriv=deriv, model=model, residue=residue)\n",
    "\n",
    "        if first: # If first calculation, then need to only get the order of the original functions u_g\n",
    "            fft_amplitudes, max_frequencies, freqs, label = compute_fft_and_max_freq(test_dataloader_g,\\\n",
    "            deriv=False, model=False, residue=False)\n",
    "            return plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'General freq {label} at epoch {epoch}',\\\n",
    "            xmin=0, xmax=11, sorted_indices=sorted_indices, first=first)\n",
    "        else:\n",
    "            if model and residue:\n",
    "                # plot_heatmap(fft_amplitudes_model, max_frequencies_model, freqs_model, fun_type=f'General freq {label_model} at epoch {epoch}',\\\n",
    "                # xmin=0, xmax=11, sorted_indices=sorted_indices, first=first)\n",
    "\n",
    "                plot_combined_heatmap(fft_amplitudes1=fft_amplitudes_model, max_frequencies1=max_frequencies_model,\\\n",
    "                    freqs1=freqs_model, fun_type1=f'General freq {label_model} at epoch {epoch}',\\\n",
    "                    fft_amplitudes2=fft_amplitudes_res, max_frequencies2=max_frequencies_res,\\\n",
    "                    freqs2=freqs_res, fun_type2=f'General freq {label_res} at epoch {epoch}',\\\n",
    "                    xmin=0, xmax=11, sorted_indices=sorted_indices, first=first)\n",
    "\n",
    "            else:\n",
    "                plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'General freq {label} at epoch {epoch}',\\\n",
    "                xmin=0, xmax=11, sorted_indices=sorted_indices, first=first)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = [], []\n",
    "\n",
    "def model_training_plots(model, train_dataloader, test_dataloader, num_epochs,\\\n",
    "    split_freq=1, filename=None, save=None, order=None, nmse=False,\\\n",
    "        deriv=None, residue=None, lr=1e-3, heatmap=True):\n",
    "\n",
    "    \"\"\"\n",
    "    model: provide a model to train\n",
    "    train/test_dataloader: provide a specific dataloader \n",
    "    num_epochs: train for this many epochs\n",
    "    split_freq: really should be called \"number of colormaps to show\"\n",
    "    filename: filename to save final loss vs iterations plot as\n",
    "    save: whether to save the file\n",
    "    order: not sure this even matters\n",
    "    nmse: set to True to use NMSE as loss function during training\n",
    "    deriv: set to True to show derivative\n",
    "    residue: set to 1 to show spectral error, i.e., hat(u_g') - hat(f(u_g)),\n",
    "        and set to 2 to show fourier transform of error, i.e., hat(u_g' - f(u_g))\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    low_freq_nmses = []\n",
    "    general_freq_nmses = []\n",
    "    high_freq_nmses = []\n",
    "    epoch_list = []\n",
    "\n",
    "    lr = lr\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    # If nmse, then use NMSE as loss\n",
    "    if nmse:\n",
    "        def criterion(target, output, nmse=None):\n",
    "            mse = torch.mean((target - output) ** 2)\n",
    "            mse = mse / torch.mean(target ** 2)\n",
    "            \n",
    "            return mse\n",
    "    \n",
    "    num_plots = split_freq\n",
    "    split_freq = num_epochs // split_freq\n",
    "    print(split_freq)\n",
    "\n",
    "    # At the first epoch, compute the order of the functions before training\n",
    "    sorted_indices = plot_heatmaps(label=f'first', all=False, first=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        for batch_functions, batch_derivatives in train_dataloader:\n",
    "            batch_functions = batch_functions.unsqueeze(1)\n",
    "            batch_derivatives = batch_derivatives.unsqueeze(1)\n",
    "\n",
    "            outputs = model(batch_functions)\n",
    "            loss = criterion(outputs, batch_derivatives)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for b_test_functions, b_test_derivatives in test_dataloader:\n",
    "                b_test_functions = b_test_functions.unsqueeze(1)\n",
    "                b_test_derivatives = b_test_derivatives.unsqueeze(1)\n",
    "\n",
    "                test_outputs = model(b_test_functions)\n",
    "                batch_test_loss = criterion(test_outputs, b_test_derivatives)\n",
    "                \n",
    "\n",
    "                test_loss += batch_test_loss.item()\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "        l, g, h = print_and_store_metrics(model)\n",
    "        low_freq_nmses.append(l)\n",
    "        general_freq_nmses.append(g)\n",
    "        high_freq_nmses.append(h)\n",
    "        epoch_list.append(epoch)\n",
    "\n",
    "        # If iteration reached, then plot the colormap once\n",
    "        # if heatmap:\n",
    "        if (epoch) % split_freq == 0:\n",
    "            print(f\"Plotting the colormap once at iteration {epoch}\")\n",
    "            label = epoch // split_freq\n",
    "\n",
    "            # First is false here, but we pass in\n",
    "            plot_heatmaps(model=model, label=f'{label}', all=False,\\\n",
    "                deriv=deriv, residue=residue, epoch=epoch, sorted_indices=sorted_indices)\n",
    "\n",
    "            if heatmap:\n",
    "                plt.show()\n",
    "\n",
    "    print(f\"Training finished for {order}st derivative\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epoch_list, low_freq_nmses, label='Low freq NMSE')\n",
    "    plt.plot(epoch_list, general_freq_nmses, label='General freq NMSE')\n",
    "    plt.plot(epoch_list, high_freq_nmses, label='High freq NMSE')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('NMSE')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.title('NMSEs of different frequencies during training')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(filename)  \n",
    "\n",
    "    return train_losses, test_losses, low_freq_nmses, general_freq_nmses, high_freq_nmses, epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "L3ModelK3_low = SimpleCNN(n_layers=3, kernel_size=3)\n",
    "plot_heatmaps(model=L3ModelK3_low, residue='fourier of error', all=False, first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The above looks a lot like the trained model output or true derivative**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **USE THIS for analyzing the training dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "L3ModelK3_low = SimpleCNN(n_layers=3, kernel_size=3)\n",
    "# residue_type = 'error of fourier'\n",
    "# residue_type = \n",
    "nmse = False\n",
    "deriv = False\n",
    "\n",
    "train_losses, test_losses, *_ = model_training_plots(L3ModelK3_low, train_dataloader_g, test_dataloader_g,\\\n",
    "    num_epochs=300, split_freq=100, filename='../plots/spectral_bias/f0_E2000_phased_training',\\\n",
    "    save=save, order='first', deriv=deriv, residue=residue_type, lr=1e-4, nmse=nmse)\n",
    "plot_losses(train_losses, test_losses, save_dir='../plots/spectral_bias', filename='f0_E2000_phased_training', save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multiple_runs(train_dataloader, test_dataloader, num_epochs, random_seeds, **kwargs):\n",
    "    overall_low_freq_nmses = []\n",
    "    overall_general_freq_nmses = []\n",
    "    overall_high_freq_nmses = []\n",
    "    \n",
    "    for seed in random_seeds:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        set_seed(seed)\n",
    "        model = SimpleCNN(n_layers=3, kernel_size=3)\n",
    "\n",
    "        \n",
    "        train_losses, test_losses, low_freq_nmses, general_freq_nmses, high_freq_nmses, epoch_list = model_training_plots(\n",
    "            model, train_dataloader, test_dataloader, num_epochs, **kwargs\n",
    "        )\n",
    "        \n",
    "        overall_low_freq_nmses.append(low_freq_nmses)\n",
    "        overall_general_freq_nmses.append(general_freq_nmses)\n",
    "        overall_high_freq_nmses.append(high_freq_nmses)\n",
    "    \n",
    "    return overall_low_freq_nmses, overall_general_freq_nmses, overall_high_freq_nmses, epoch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_with_error_bars(overall_low_freq_nmses, overall_general_freq_nmses,\\\n",
    "    overall_high_freq_nmses, epoch_list, fig_path):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for data, label in zip([overall_low_freq_nmses, overall_general_freq_nmses, overall_high_freq_nmses], \n",
    "                           ['Low freq NMSE', 'General freq NMSE', 'High freq NMSE']):\n",
    "        mean_losses = np.mean(data, axis=0)\n",
    "        std_losses = np.std(data, axis=0)\n",
    "        \n",
    "        plt.plot(epoch_list, mean_losses, label=f'Mean {label}')\n",
    "        plt.fill_between(epoch_list, mean_losses - std_losses, mean_losses + std_losses, alpha=0.2)\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('NMSE')\n",
    "    plt.yscale('log')\n",
    "    plt.title('Mean NMSEs of different frequencies during training (with std dev)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    plt.savefig(fig_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seeds = [1, 2, 3, 4, 5]\n",
    "random_seeds = [1, 2]\n",
    "num_epochs = 20\n",
    "\n",
    "overall_low_freq_nmses, overall_general_freq_nmses, overall_high_freq_nmses,\\\n",
    "    epoch_list = train_multiple_runs(train_dataloader_g, test_dataloader_g, num_epochs, random_seeds)\n",
    "\n",
    "# Plot the results\n",
    "plot_results_with_error_bars(overall_low_freq_nmses, overall_general_freq_nmses,\\\n",
    "    overall_high_freq_nmses, epoch_list, fig_path='/home/users/erikwang/multistage/plots/spectral_bias/L3K3_MSE_runs.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
