{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with training different dataset \n",
    "\n",
    "Goal is to see if training on high freq leads to better performance on low freq dataset than training on low freq dataset for high freq data  \n",
    "\n",
    "8/19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import heapq\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set save to True if you want to save plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only for python script: uncomment if running on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are both placeholders\n",
    "num_epochs = 1000\n",
    "model_name = 'f0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    'axes.titlesize': 30,     # Font size for titles\n",
    "    'axes.labelsize': 30,     # Font size for x and y labels\n",
    "    'xtick.labelsize': 20,    # Font size for x-axis tick labels\n",
    "    'ytick.labelsize': 20,    # Font size for y-axis tick labels\n",
    "    'legend.fontsize': 20,    # Font size for the legend\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse command-line arguments\n",
    "# parser = argparse.ArgumentParser(description='Train a neural network model')\n",
    "# parser.add_argument('--epochs', type=int, default=1000, help='Number of training epochs')\n",
    "# parser.add_argument('--model_name', type=str, default='model', help='Name of the saved model')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # Use the parsed arguments\n",
    "# num_epochs = args.epochs\n",
    "# model_name = args.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if CUDA is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "seed = 42\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simplified function generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_freq_dataset(num_samples, num_points, min_freq, max_freq):\n",
    "    x = torch.linspace(0, 2 * np.pi, num_points, requires_grad=True)\n",
    "    functions = []\n",
    "    derivatives = []\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        # Fix maximum of 10 frequency components \n",
    "        num_freqs = torch.randint(1, 10, (1,)).item()\n",
    "        amplitudes = torch.rand(num_freqs * 2)  # Double the number of amplitudes\n",
    "        frequencies = torch.randint(min_freq, max_freq + 1, (num_freqs,)).float()\n",
    "        phases = torch.rand(num_freqs * 2) * 2 * np.pi  # Double the number of phases\n",
    "        \n",
    "        y = sum(a * torch.sin(f * x + p) for a, f, p in zip(amplitudes[:num_freqs], frequencies, phases[:num_freqs])) + \\\n",
    "            sum(a * torch.cos(f * x + p) for a, f, p in zip(amplitudes[num_freqs:], frequencies, phases[num_freqs:]))\n",
    "        \n",
    "        dy_dx = torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "        \n",
    "        functions.append(y.detach().numpy())\n",
    "        derivatives.append(dy_dx.detach().numpy())\n",
    "    \n",
    "    return np.array(functions), np.array(derivatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "num_points = 1000\n",
    "batch_size = 32\n",
    "\n",
    "low_freq_functions, low_freq_derivatives = generate_freq_dataset(num_samples, num_points, 1, 5)\n",
    "general_freq_functions, general_freq_derivatives = generate_freq_dataset(num_samples, num_points, 1, 15)\n",
    "high_freq_functions, high_freq_derivatives = generate_freq_dataset(num_samples, num_points, 10, 15)\n",
    "\n",
    "low_freq_dataset = TensorDataset(torch.tensor(low_freq_functions), torch.tensor(low_freq_derivatives))\n",
    "general_freq_dataset = TensorDataset(torch.tensor(general_freq_functions), torch.tensor(general_freq_derivatives))\n",
    "high_freq_dataset = TensorDataset(torch.tensor(high_freq_functions), torch.tensor(high_freq_derivatives))\n",
    "\n",
    "low_freq_dataloader = DataLoader(TensorDataset(torch.tensor(low_freq_functions), torch.tensor(low_freq_derivatives)), batch_size=batch_size, shuffle=True)\n",
    "high_freq_dataloader = DataLoader(TensorDataset(torch.tensor(high_freq_functions), torch.tensor(high_freq_derivatives)), batch_size=batch_size, shuffle=True)\n",
    "general_freq_dataloader = DataLoader(TensorDataset(torch.tensor(general_freq_functions), torch.tensor(general_freq_derivatives)), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(low_freq_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# low freq\n",
    "train_dataset_l, test_dataset_l = random_split(low_freq_dataset, [train_size, test_size], generator=generator)\n",
    "train_dataloader_l = DataLoader(train_dataset_l, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader_l = DataLoader(test_dataset_l, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "# general freq\n",
    "train_dataset_g, test_dataset_g = random_split(general_freq_dataset, [train_size, test_size], generator=generator)\n",
    "train_dataloader_g = DataLoader(train_dataset_g, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader_g = DataLoader(test_dataset_g, batch_size=32, shuffle=False, drop_last=True)\n",
    "\n",
    "# high freq\n",
    "train_dataset_h, test_dataset_h = random_split(high_freq_dataset, [train_size, test_size], generator=generator)\n",
    "train_dataloader_h = DataLoader(train_dataset_h, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader_h = DataLoader(test_dataset_h, batch_size=32, shuffle=False, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot random function from one of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.random.randint(32)\n",
    "\n",
    "fun, deriv = next(iter(low_freq_dataloader))\n",
    "\n",
    "first_function = fun[a]\n",
    "first_derivative = deriv[a]\n",
    "\n",
    "# Generate x values corresponding to the function inputs\n",
    "x_values = np.linspace(0, 2 * np.pi, 1000)\n",
    "\n",
    "# Plotting the function and its derivative\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x_values, first_function, label='Function')\n",
    "plt.plot(x_values, first_derivative, label='Derivative')\n",
    "plt.title('Function and Its Derivative')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save datasets\n",
    "# torch.save(general_freq_dataset, 'datasets/general_freq_dataset.pt')\n",
    "# torch.save(low_freq_dataset, 'datasets/low_freq_dataset.pt')\n",
    "# torch.save(high_freq_dataset, 'datasets/high_freq_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopped here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This CNN uses 3 layers, each with kernel size 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = SimpleCNN()\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, test_losses, save_dir='plots', filename=None, save=False):\n",
    "    if not train_losses:\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, linestyle='-', color='b', label='Training Loss')\n",
    "    plt.plot(epochs, test_losses, linestyle='-', label='Test Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')  # Set the y-axis to logarithmic scale\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(model1, dataset, order=None, save_dir='plots', filename=None, save=False): \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    model1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    train_dataloader_viz = get_random_function(dataset, shuffle=True)\n",
    "    # Get a random sample from the dataloader\n",
    "    dataiter = iter(train_dataloader_viz)\n",
    "    function, true_derivative = next(dataiter)\n",
    "\n",
    "    # Reshape the input for the model\n",
    "    function = function.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        if order == 1 or order == 2:\n",
    "            predicted_derivative = model1(function)\n",
    "        \n",
    "        if order == 'rollout':\n",
    "            predicted_derivative = model1(function)\n",
    "            predicted_derivative = model1(predicted_derivative)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    x = torch.linspace(0, 2*torch.pi, 1000).numpy()\n",
    "    function = function.squeeze().numpy()\n",
    "\n",
    "    predicted_derivative = predicted_derivative.squeeze().numpy()\n",
    "\n",
    "    true_derivative = true_derivative.squeeze().numpy()\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(x, function, label='Original Function', color='blue')\n",
    "    if order == 1:\n",
    "        plt.plot(x, true_derivative, label=f'True {order}st derivative')\n",
    "\n",
    "    plt.plot(x[10:-10], predicted_derivative[10:-10], label=f'Predicted {order}nd Derivative', linestyle='--')\n",
    "\n",
    "    plt.title('Function, True Derivatives, and Predicted Derivatives')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_function(dataset, shuffle=True):\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = [], []\n",
    "\n",
    "def model_training(model, train_dataloader, test_dataloader, num_epochs,\\\n",
    "    split_freq=None, filename=None, save=None, order=None, nmse=None):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    low_freq_nmses = []\n",
    "    general_freq_nmses = []\n",
    "    high_freq_nmses = []\n",
    "    epoch_list = []\n",
    "\n",
    "    lr = 1e-3\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Define a new loss function that can use NMSE\n",
    "    def criterion2(target, output, nmse=None):\n",
    "        mse = torch.mean((target - output) ** 2)\n",
    "        if nmse:\n",
    "            mse = mse / torch.mean(target ** 2)\n",
    "        \n",
    "        return mse\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        for batch_functions, batch_derivatives in train_dataloader:\n",
    "            batch_functions = batch_functions.unsqueeze(1)\n",
    "            batch_derivatives = batch_derivatives.unsqueeze(1)\n",
    "\n",
    "            outputs = model(batch_functions)\n",
    "            loss = criterion2(outputs, batch_derivatives, nmse=nmse)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        \n",
    "        # l, g, h = print_and_store_metrics(model, nmse=nmse)\n",
    "        epoch_list.append(epoch)\n",
    "\n",
    "        l, g, h = compute_mse(model, criterion2, optimizer, nmse=True)\n",
    "        low_freq_nmses.append(l)\n",
    "        general_freq_nmses.append(g)\n",
    "        high_freq_nmses.append(h)\n",
    "        print(f\"The metrics are: {l}, {g}, and {h}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for b_test_functions, b_test_derivatives in test_dataloader:\n",
    "                b_test_functions = b_test_functions.unsqueeze(1)\n",
    "                b_test_derivatives = b_test_derivatives.unsqueeze(1)\n",
    "\n",
    "                test_outputs = model(b_test_functions)\n",
    "                batch_test_loss = criterion2(test_outputs, b_test_derivatives, nmse=True)\n",
    "\n",
    "                test_loss += batch_test_loss.item()\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "    print(f\"Training finished for {order}st derivative\")\n",
    "\n",
    "    if nmse:\n",
    "        loss_function = \"NMSE\"\n",
    "    else:\n",
    "        loss_function = \"MSE\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epoch_list, low_freq_nmses, label=f'Low frequency NMSE')\n",
    "    plt.plot(epoch_list, general_freq_nmses, label=f'General frequency NMSE')\n",
    "    plt.plot(epoch_list, high_freq_nmses, label=f'High frequency NMSE')\n",
    "\n",
    "    # Adding labels and title\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('NMSE')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    plt.title(f'Training Loss using {loss_function}')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    if save:\n",
    "        plt.savefig(filename)  \n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_mse(dataloader, model):\n",
    "#     \"\"\"\n",
    "#     Takes in a dataloader and a model to compute MSE.\n",
    "#     \"\"\"\n",
    "\n",
    "#     model.eval()\n",
    "#     all_outputs = []\n",
    "#     all_targets = []\n",
    "\n",
    "#     for function, deriv in dataloader:\n",
    "#         function = function.unsqueeze(1)\n",
    "#         deriv = deriv.unsqueeze(1)\n",
    "\n",
    "#         # Compute model output\n",
    "#         model_output = model(function)\n",
    "#         all_targets.append(deriv)\n",
    "\n",
    "#         # Collect outputs\n",
    "#         all_outputs.append(model_output)\n",
    "\n",
    "#     # Concatenate all collected outputs and targets\n",
    "#     all_outputs = torch.cat(all_outputs, dim=0)\n",
    "#     all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "#     # Compute MSE\n",
    "#     mse = torch.mean((all_targets - all_outputs) ** 2)\n",
    "#     nmse = mse / torch.mean(all_targets ** 2)\n",
    "\n",
    "#     return mse.item(), nmse.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(model, criterion2, optimizer, nmse=True):\n",
    "    test_loss_g = 0.0\n",
    "    test_loss_l = 0.0\n",
    "    test_loss_h = 0.0\n",
    "\n",
    "    def criterion2(target, output, nmse=nmse):\n",
    "        mse = torch.mean((target - output) ** 2)\n",
    "        if nmse:\n",
    "            mse = mse / torch.mean(target ** 2)\n",
    "        \n",
    "        return mse\n",
    "\n",
    "    for batch_functions, batch_derivatives in test_dataloader_g:\n",
    "        batch_functions = batch_functions.unsqueeze(1)\n",
    "        batch_derivatives = batch_derivatives.unsqueeze(1)\n",
    "\n",
    "        outputs = model(batch_functions)\n",
    "        loss = criterion2(outputs, batch_derivatives, nmse=nmse)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        test_loss_g += loss.item()\n",
    "    test_loss_g /= len(test_dataloader_g)\n",
    "\n",
    "    for batch_functions, batch_derivatives in test_dataloader_l:\n",
    "        batch_functions = batch_functions.unsqueeze(1)\n",
    "        batch_derivatives = batch_derivatives.unsqueeze(1)\n",
    "\n",
    "        outputs = model(batch_functions)\n",
    "        loss = criterion2(outputs, batch_derivatives, nmse=nmse)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        test_loss_l += loss.item()\n",
    "    test_loss_l /= len(test_dataloader_l)\n",
    "\n",
    "    for batch_functions, batch_derivatives in test_dataloader_h:\n",
    "        batch_functions = batch_functions.unsqueeze(1)\n",
    "        batch_derivatives = batch_derivatives.unsqueeze(1)\n",
    "\n",
    "        outputs = model(batch_functions)\n",
    "        loss = criterion2(outputs, batch_derivatives, nmse=nmse)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        test_loss_h += loss.item()\n",
    "    test_loss_h /= len(test_dataloader_h)\n",
    "    \n",
    "    return test_loss_l, test_loss_g, test_loss_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_and_store_metrics(f0, nmse=False):\n",
    "    if nmse:\n",
    "        return compute_mse(train_dataloader_l, f0)[1], compute_mse(train_dataloader_g, f0)[1], compute_mse(train_dataloader_h, f0)[1]\n",
    "    else:\n",
    "        return compute_mse(train_dataloader_l, f0)[0], compute_mse(train_dataloader_g, f0)[0], compute_mse(train_dataloader_h, f0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(model):\n",
    "    print(f\"NMSE over low freq test functions: {compute_mse(test_dataloader_l, model)[1]}\")\n",
    "    print(f\"NMSE over general freq test functions: {compute_mse(test_dataloader_g, model)[1]}\")\n",
    "    print(f\"NMSE over high freq test functions: {compute_mse(test_dataloader_h, model)[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, n_layers=3, kernel_size=3, hidden_size=64):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # Parameters\n",
    "        self.n_layers = n_layers\n",
    "        self.kernel_size = kernel_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Model\n",
    "        self.convs = nn.ModuleList()\n",
    "        if n_layers == 1:\n",
    "            self.convs.append(nn.Conv1d(1, 1, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "        elif n_layers >= 2:\n",
    "            self.convs.append(nn.Conv1d(1, hidden_size, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "            for _ in range(n_layers - 2):\n",
    "                self.convs.append(nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "            self.convs.append(nn.Conv1d(hidden_size, 1, kernel_size=kernel_size, padding=kernel_size//2))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, conv in enumerate(self.convs):\n",
    "            if i < len(self.convs) - 1:\n",
    "                x = self.relu(conv(x))\n",
    "            else:\n",
    "                x = conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "L3ModelK3 = SimpleCNN(n_layers=3, kernel_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_outputs(model, model_name):\n",
    "    plot_output(model, dataset=test_dataset_l, order=1, save_dir='../plots/spectral_bias', filename=f'{model_name}_E{num_epochs}_lf_output', save=save)\n",
    "    plot_output(model, dataset=test_dataset_g, order=1, save_dir='../plots/spectral_bias', filename=f'{model_name}_E{num_epochs}_lf_output', save=save)\n",
    "    plot_output(model, dataset=test_dataset_h, order=1, save_dir='../plots/spectral_bias', filename=f'{model_name}_E{num_epochs}_lf_output', save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color map plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fft_and_max_freq(dataloader, deriv=False, model=None, residue=False):\n",
    "    fft_amplitudes = []\n",
    "    max_frequencies = []\n",
    "    T = 2 * torch.pi\n",
    "    N = 1000\n",
    "\n",
    "    # Calculate frequencies for the FFT\n",
    "    frequencies = torch.fft.fftfreq(N, T / (2 * torch.pi * N))\n",
    "    positive_freq_indices = frequencies >= 0\n",
    "    positive_freqs = frequencies[positive_freq_indices]\n",
    "\n",
    "    # Iterate over each batch\n",
    "    for functions, derivatives in dataloader:  # Note that derivatives are ignored in this loop\n",
    "        \n",
    "        if deriv and not model: # If deriv is true and model is none then use derivatives\n",
    "            functions = derivatives\n",
    "            \n",
    "        if not deriv and model and not residue: # If deriv is false and model is entered then compute derivative\n",
    "            functions = model(functions.unsqueeze(1)).squeeze()\n",
    "            # output = model(functions)\n",
    "            \n",
    "            # output = output.squeeze()\n",
    "            # functions = output # set this so that the FFTs can be computed in the next line\n",
    "        \n",
    "        elif residue and model:\n",
    "            print(\"computing residue\")\n",
    "            outputs = model(functions.unsqueeze(1)).squeeze()\n",
    "            residues = derivatives - outputs\n",
    "            norm_residues = residues / derivatives\n",
    "            functions = norm_residues\n",
    "\n",
    "        # Compute FFT using PyTorch\n",
    "        F = torch.fft.fft(functions)\n",
    "        magnitudes = torch.abs(F) / N\n",
    "\n",
    "        # Consider only positive frequencies\n",
    "        positive_magnitudes = magnitudes[:, positive_freq_indices]\n",
    "\n",
    "        fft_amplitudes.append(positive_magnitudes)\n",
    "        \n",
    "        # Maximum frequency based on the highest amplitude for each function in the batch\n",
    "        max_indices = torch.argmax(positive_magnitudes, dim=1)\n",
    "        batch_max_freqs = positive_freqs[max_indices]\n",
    "        max_frequencies.extend(batch_max_freqs)\n",
    "\n",
    "    return torch.vstack(fft_amplitudes), torch.tensor(max_frequencies), positive_freqs\n",
    "\n",
    "def plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type, xmin=0, xmax=0):\n",
    "    fft_amplitudes = fft_amplitudes.detach().numpy()\n",
    "    max_frequencies = max_frequencies.detach().numpy()\n",
    "    freqs = freqs.detach().numpy()\n",
    "    \n",
    "    # Sort functions by the maximum frequency\n",
    "    sorted_indices = np.argsort(-max_frequencies)  # Sort in descending order\n",
    "    sorted_fft = fft_amplitudes[sorted_indices]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    im = plt.imshow(sorted_fft, aspect='auto', extent=[freqs[0], freqs[-1], 0, len(sorted_fft)],\\\n",
    "        interpolation='nearest')\n",
    "    plt.colorbar(im, label='Amplitude')\n",
    "    plt.xlabel('Frequency (rad/s)')\n",
    "    plt.ylabel('Function Index (sorted by max frequency)')\n",
    "    plt.title(f'FFT Amplitude Heatmap for {fun_type}')\n",
    "    plt.xlim([xmin, xmax])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default is u_g\n",
    "# This function plots the heatmaps for all frequencies for the test datlaoaders\n",
    "def plot_heatmaps(deriv=None, model=None, residue=False, label=None):\n",
    "    fft_amplitudes, max_frequencies, freqs = compute_fft_and_max_freq(test_dataloader_l,\\\n",
    "        deriv=deriv, model=model, residue=residue)\n",
    "    plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'Low freq {label}', xmin=0, xmax=6)\n",
    "\n",
    "    fft_amplitudes, max_frequencies, freqs = compute_fft_and_max_freq(test_dataloader_g,\\\n",
    "        deriv=deriv, model=model, residue=residue)\n",
    "    plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'General freq {label}', xmin=0, xmax=16)\n",
    "\n",
    "    fft_amplitudes, max_frequencies, freqs = compute_fft_and_max_freq(test_dataloader_h,\\\n",
    "        deriv=deriv, model=model, residue=residue)\n",
    "    plot_heatmap(fft_amplitudes, max_frequencies, freqs, fun_type=f'High freq {label}', xmin=10, xmax=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_heatmaps(label='u_g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments with training on different datasets\n",
    "\n",
    "3 layers, kernel size 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on general frequency dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics are: 18.928510665893555, 185.12230428059897, and 190.80015563964844\n",
      "Epoch [1/2000], Train Loss: 2863.9548, Test Loss: 84.8689\n",
      "The metrics are: 6.219575723012288, 43.09280904134115, and 67.14850362141927\n",
      "Epoch [2/2000], Train Loss: 62.1119, Test Loss: 33.4864\n",
      "The metrics are: 3.982736349105835, 24.135496139526367, and 40.038071950276695\n",
      "Epoch [3/2000], Train Loss: 29.0616, Test Loss: 20.5393\n",
      "The metrics are: 2.9629782835642495, 16.046422004699707, and 26.996461232503254\n",
      "Epoch [4/2000], Train Loss: 18.2587, Test Loss: 14.1148\n",
      "The metrics are: 2.389023780822754, 11.549614906311035, and 19.55951499938965\n",
      "Epoch [5/2000], Train Loss: 12.7501, Test Loss: 10.4210\n",
      "The metrics are: 2.0408480962117515, 8.854738235473633, and 14.987677256266275\n",
      "Epoch [6/2000], Train Loss: 9.5735, Test Loss: 8.1265\n",
      "The metrics are: 1.813366691271464, 7.099374294281006, and 11.993839581807455\n",
      "Epoch [7/2000], Train Loss: 7.6082, Test Loss: 6.6241\n",
      "The metrics are: 1.6622757116953533, 5.93719498316447, and 9.99726390838623\n",
      "Epoch [8/2000], Train Loss: 6.1939, Test Loss: 5.6185\n",
      "The metrics are: 1.5568227370580037, 5.136000474294026, and 8.588817278544107\n",
      "Epoch [9/2000], Train Loss: 5.3689, Test Loss: 4.9041\n",
      "The metrics are: 1.4789557854334514, 4.546837488810222, and 7.544576644897461\n",
      "Epoch [10/2000], Train Loss: 4.6909, Test Loss: 4.3728\n",
      "The metrics are: 1.4195140997568767, 4.100863218307495, and 6.741775989532471\n",
      "Epoch [11/2000], Train Loss: 4.2392, Test Loss: 3.9625\n",
      "The metrics are: 1.3721760908762615, 3.744911511739095, and 6.103131453196208\n",
      "Epoch [12/2000], Train Loss: 3.8132, Test Loss: 3.6361\n",
      "The metrics are: 1.3341389099756877, 3.4609317779541016, and 5.5869700113932295\n",
      "Epoch [13/2000], Train Loss: 3.5310, Test Loss: 3.3714\n",
      "The metrics are: 1.3027087450027466, 3.2266010443369546, and 5.1598812739054365\n",
      "Epoch [14/2000], Train Loss: 3.2736, Test Loss: 3.1521\n",
      "The metrics are: 1.2764278650283813, 3.031184991200765, and 4.801952838897705\n",
      "Epoch [15/2000], Train Loss: 3.0595, Test Loss: 2.9680\n",
      "The metrics are: 1.253994623819987, 2.8647408485412598, and 4.495843569437663\n",
      "Epoch [16/2000], Train Loss: 2.9014, Test Loss: 2.8104\n",
      "The metrics are: 1.2346952358881633, 2.721599817276001, and 4.232366402943929\n",
      "Epoch [17/2000], Train Loss: 2.7411, Test Loss: 2.6747\n",
      "The metrics are: 1.217847426732381, 2.5969457626342773, and 4.001893361409505\n",
      "Epoch [18/2000], Train Loss: 2.6344, Test Loss: 2.5558\n",
      "The metrics are: 1.2029698292414348, 2.4867192109425864, and 3.7985458374023438\n",
      "Epoch [19/2000], Train Loss: 2.5225, Test Loss: 2.4509\n",
      "The metrics are: 1.1900099515914917, 2.391047557195028, and 3.6209041277567544\n",
      "Epoch [20/2000], Train Loss: 2.4046, Test Loss: 2.3592\n",
      "The metrics are: 1.178479790687561, 2.3059144020080566, and 3.4628783067067466\n",
      "Epoch [21/2000], Train Loss: 2.3075, Test Loss: 2.2775\n",
      "The metrics are: 1.1681758960088093, 2.2298709551493325, and 3.321602741877238\n",
      "Epoch [22/2000], Train Loss: 2.2214, Test Loss: 2.2045\n",
      "The metrics are: 1.1588789621988933, 2.1614905993143716, and 3.1938026746114097\n",
      "Epoch [23/2000], Train Loss: 2.1702, Test Loss: 2.1384\n",
      "The metrics are: 1.1504236062367756, 2.099209944407145, and 3.0776943365732827\n",
      "Epoch [24/2000], Train Loss: 2.1044, Test Loss: 2.0783\n",
      "The metrics are: 1.1427818934122722, 2.0430668592453003, and 2.972553014755249\n",
      "Epoch [25/2000], Train Loss: 2.0455, Test Loss: 2.0239\n",
      "The metrics are: 1.1357929706573486, 1.991714636484782, and 2.876396417617798\n",
      "Epoch [26/2000], Train Loss: 1.9927, Test Loss: 1.9741\n",
      "The metrics are: 1.1293313105901082, 1.9442185560862224, and 2.7875168323516846\n",
      "Epoch [27/2000], Train Loss: 1.9559, Test Loss: 1.9281\n",
      "The metrics are: 1.1234129667282104, 1.9007141590118408, and 2.706099033355713\n",
      "Epoch [28/2000], Train Loss: 1.9033, Test Loss: 1.8859\n",
      "The metrics are: 1.1177181005477905, 1.8595879077911377, and 2.626324415206909\n",
      "Epoch [29/2000], Train Loss: 1.8688, Test Loss: 1.8439\n",
      "The metrics are: 1.110554536183675, 1.8106768528620403, and 2.5216201146443686\n",
      "Epoch [30/2000], Train Loss: 1.8119, Test Loss: 1.7871\n",
      "The metrics are: 1.0994960864384968, 1.7352110544840496, and 2.361764113108317\n",
      "Epoch [31/2000], Train Loss: 1.7618, Test Loss: 1.7015\n",
      "The metrics are: 1.0857433875401814, 1.637786865234375, and 2.169184764226278\n",
      "Epoch [32/2000], Train Loss: 1.6600, Test Loss: 1.6008\n",
      "The metrics are: 1.0721110105514526, 1.5382028023401897, and 1.9826853275299072\n",
      "Epoch [33/2000], Train Loss: 1.5618, Test Loss: 1.5049\n",
      "The metrics are: 1.0605376561482747, 1.4521249930063884, and 1.8262286980946858\n",
      "Epoch [34/2000], Train Loss: 1.4701, Test Loss: 1.4251\n",
      "The metrics are: 1.0513776540756226, 1.3834157387415569, and 1.7029143969217937\n",
      "Epoch [35/2000], Train Loss: 1.3956, Test Loss: 1.3623\n",
      "The metrics are: 1.0442682107289631, 1.329904317855835, and 1.6072352329889934\n",
      "Epoch [36/2000], Train Loss: 1.3389, Test Loss: 1.3136\n",
      "The metrics are: 1.0387349526087444, 1.2882821957270305, and 1.5325747728347778\n",
      "Epoch [37/2000], Train Loss: 1.2956, Test Loss: 1.2755\n",
      "The metrics are: 1.034388542175293, 1.2556370894114177, and 1.473752498626709\n",
      "Epoch [38/2000], Train Loss: 1.2586, Test Loss: 1.2455\n",
      "The metrics are: 1.0308845440546672, 1.229381004969279, and 1.4261651436487834\n",
      "Epoch [39/2000], Train Loss: 1.2329, Test Loss: 1.2211\n",
      "The metrics are: 1.0280142625172932, 1.2078791459401448, and 1.387122909228007\n",
      "Epoch [40/2000], Train Loss: 1.2091, Test Loss: 1.2010\n",
      "The metrics are: 1.025612195332845, 1.1899288495381672, and 1.3543502887090046\n",
      "Epoch [41/2000], Train Loss: 1.1936, Test Loss: 1.1842\n",
      "The metrics are: 1.023589054743449, 1.1747854948043823, and 1.3267481327056885\n",
      "Epoch [42/2000], Train Loss: 1.1749, Test Loss: 1.1699\n",
      "The metrics are: 1.0218586126963298, 1.1618934472401936, and 1.3030338684717815\n",
      "Epoch [43/2000], Train Loss: 1.1646, Test Loss: 1.1577\n",
      "The metrics are: 1.0203713178634644, 1.1508153676986694, and 1.2826311985651653\n",
      "Epoch [44/2000], Train Loss: 1.1508, Test Loss: 1.1472\n",
      "The metrics are: 1.019071340560913, 1.1411476135253906, and 1.2647608518600464\n",
      "Epoch [45/2000], Train Loss: 1.1417, Test Loss: 1.1379\n",
      "The metrics are: 1.0179201761881511, 1.1325862010320027, and 1.2489279905954997\n",
      "Epoch [46/2000], Train Loss: 1.1336, Test Loss: 1.1297\n",
      "The metrics are: 1.0168969631195068, 1.12496018409729, and 1.2348705530166626\n",
      "Epoch [47/2000], Train Loss: 1.1244, Test Loss: 1.1225\n",
      "The metrics are: 1.0159908533096313, 1.1182422240575154, and 1.222360889116923\n",
      "Epoch [48/2000], Train Loss: 1.1182, Test Loss: 1.1160\n",
      "The metrics are: 1.0151700576146443, 1.1121481657028198, and 1.2110408147176106\n",
      "Epoch [49/2000], Train Loss: 1.1122, Test Loss: 1.1101\n",
      "The metrics are: 1.0144290924072266, 1.106650948524475, and 1.2008110284805298\n",
      "Epoch [50/2000], Train Loss: 1.1064, Test Loss: 1.1048\n",
      "The metrics are: 1.013750433921814, 1.1016115347544353, and 1.1914414564768474\n",
      "Epoch [51/2000], Train Loss: 1.1021, Test Loss: 1.0999\n",
      "The metrics are: 1.0131345589955647, 1.0970474481582642, and 1.182923674583435\n",
      "Epoch [52/2000], Train Loss: 1.0972, Test Loss: 1.0955\n",
      "The metrics are: 1.0125715732574463, 1.0928733348846436, and 1.1751360098520915\n",
      "Epoch [53/2000], Train Loss: 1.0921, Test Loss: 1.0914\n",
      "The metrics are: 1.0120541254679363, 1.0890363454818726, and 1.1679774125417073\n",
      "Epoch [54/2000], Train Loss: 1.0876, Test Loss: 1.0877\n",
      "The metrics are: 1.0115710496902466, 1.085454265276591, and 1.1612894932428997\n",
      "Epoch [55/2000], Train Loss: 1.0858, Test Loss: 1.0842\n",
      "The metrics are: 1.011127511660258, 1.082170009613037, and 1.1551433801651\n",
      "Epoch [56/2000], Train Loss: 1.0814, Test Loss: 1.0810\n",
      "The metrics are: 1.0107136170069377, 1.0791061719258626, and 1.1494081417719524\n",
      "Epoch [57/2000], Train Loss: 1.0787, Test Loss: 1.0781\n",
      "The metrics are: 1.0103298823038738, 1.0762712160746257, and 1.1440788507461548\n",
      "Epoch [58/2000], Train Loss: 1.0760, Test Loss: 1.0753\n",
      "The metrics are: 1.0099688371022542, 1.0735969543457031, and 1.1390743652979534\n",
      "Epoch [59/2000], Train Loss: 1.0731, Test Loss: 1.0727\n",
      "The metrics are: 1.0096296072006226, 1.0710837443669636, and 1.1343715985616047\n",
      "Epoch [60/2000], Train Loss: 1.0708, Test Loss: 1.0702\n",
      "The metrics are: 1.0093108812967937, 1.068723201751709, and 1.1299502849578857\n",
      "Epoch [61/2000], Train Loss: 1.0688, Test Loss: 1.0679\n",
      "The metrics are: 1.0090144872665405, 1.0665310621261597, and 1.1258318026860554\n",
      "Epoch [62/2000], Train Loss: 1.0656, Test Loss: 1.0658\n",
      "The metrics are: 1.008734663327535, 1.0644646088282268, and 1.1219404538472493\n",
      "Epoch [63/2000], Train Loss: 1.0641, Test Loss: 1.0637\n",
      "The metrics are: 1.0084693034489949, 1.06250003973643, and 1.1182555357615154\n",
      "Epoch [64/2000], Train Loss: 1.0618, Test Loss: 1.0618\n",
      "The metrics are: 1.0082184473673503, 1.0606420040130615, and 1.1147698163986206\n",
      "Epoch [65/2000], Train Loss: 1.0600, Test Loss: 1.0600\n",
      "The metrics are: 1.007982889811198, 1.0589031378428142, and 1.111492911974589\n",
      "Epoch [66/2000], Train Loss: 1.0578, Test Loss: 1.0583\n",
      "The metrics are: 1.0077575047810872, 1.0572394927342732, and 1.1083567539850872\n",
      "Epoch [67/2000], Train Loss: 1.0571, Test Loss: 1.0567\n",
      "The metrics are: 1.0075440406799316, 1.055660088857015, and 1.1053890387217205\n",
      "Epoch [68/2000], Train Loss: 1.0546, Test Loss: 1.0551\n",
      "The metrics are: 1.007339596748352, 1.0541510979334514, and 1.1025437116622925\n",
      "Epoch [69/2000], Train Loss: 1.0542, Test Loss: 1.0536\n",
      "The metrics are: 1.0071452856063843, 1.0527127583821614, and 1.0998425483703613\n",
      "Epoch [70/2000], Train Loss: 1.0520, Test Loss: 1.0522\n",
      "The metrics are: 1.0069603125254314, 1.0513488451639812, and 1.0972659985224407\n",
      "Epoch [71/2000], Train Loss: 1.0512, Test Loss: 1.0509\n",
      "The metrics are: 1.0067826509475708, 1.0500346819559734, and 1.0947948296864827\n",
      "Epoch [72/2000], Train Loss: 1.0498, Test Loss: 1.0496\n",
      "The metrics are: 1.0066144069035847, 1.0487913688023884, and 1.0924522082010906\n",
      "Epoch [73/2000], Train Loss: 1.0479, Test Loss: 1.0484\n",
      "The metrics are: 1.0064528385798137, 1.0475999116897583, and 1.0902012586593628\n",
      "Epoch [74/2000], Train Loss: 1.0473, Test Loss: 1.0472\n",
      "The metrics are: 1.0062979459762573, 1.0464548667271931, and 1.088043451309204\n",
      "Epoch [75/2000], Train Loss: 1.0460, Test Loss: 1.0461\n",
      "The metrics are: 1.006149411201477, 1.0453593333562214, and 1.0859780708948772\n",
      "Epoch [76/2000], Train Loss: 1.0448, Test Loss: 1.0450\n",
      "The metrics are: 1.006007711092631, 1.044310450553894, and 1.0840012232462566\n",
      "Epoch [77/2000], Train Loss: 1.0434, Test Loss: 1.0439\n",
      "The metrics are: 1.005870779355367, 1.0432995160420735, and 1.0820928812026978\n",
      "Epoch [78/2000], Train Loss: 1.0429, Test Loss: 1.0429\n",
      "The metrics are: 1.0057396094004314, 1.0423316955566406, and 1.0802661577860515\n",
      "Epoch [79/2000], Train Loss: 1.0416, Test Loss: 1.0420\n",
      "The metrics are: 1.0056137641270955, 1.0414011875788372, and 1.0785123904546101\n",
      "Epoch [80/2000], Train Loss: 1.0404, Test Loss: 1.0411\n",
      "The metrics are: 1.0054914951324463, 1.0404963890711467, and 1.0768099625905354\n",
      "Epoch [81/2000], Train Loss: 1.0399, Test Loss: 1.0402\n",
      "The metrics are: 1.0053750276565552, 1.0396395126978557, and 1.0751848220825195\n",
      "Epoch [82/2000], Train Loss: 1.0390, Test Loss: 1.0393\n",
      "The metrics are: 1.0052621364593506, 1.0388052860895793, and 1.073609749476115\n",
      "Epoch [83/2000], Train Loss: 1.0381, Test Loss: 1.0385\n",
      "The metrics are: 1.0051531791687012, 1.0380014181137085, and 1.0720898310343425\n",
      "Epoch [84/2000], Train Loss: 1.0374, Test Loss: 1.0377\n",
      "The metrics are: 1.0050471623738606, 1.0372178554534912, and 1.0706134637196858\n",
      "Epoch [85/2000], Train Loss: 1.0367, Test Loss: 1.0369\n",
      "The metrics are: 1.0049463113149006, 1.0364734331766765, and 1.0692038138707478\n",
      "Epoch [86/2000], Train Loss: 1.0356, Test Loss: 1.0362\n",
      "The metrics are: 1.004847526550293, 1.0357437928517659, and 1.0678274631500244\n",
      "Epoch [87/2000], Train Loss: 1.0352, Test Loss: 1.0355\n",
      "The metrics are: 1.0047526756922405, 1.0350441932678223, and 1.0665035247802734\n",
      "Epoch [88/2000], Train Loss: 1.0343, Test Loss: 1.0348\n",
      "The metrics are: 1.0046602487564087, 1.0343622366587322, and 1.0652130842208862\n",
      "Epoch [89/2000], Train Loss: 1.0341, Test Loss: 1.0341\n",
      "The metrics are: 1.0045708815256755, 1.03370201587677, and 1.063966989517212\n",
      "Epoch [90/2000], Train Loss: 1.0331, Test Loss: 1.0335\n",
      "The metrics are: 1.0044840971628826, 1.03306249777476, and 1.0627568165461223\n",
      "Epoch [91/2000], Train Loss: 1.0327, Test Loss: 1.0328\n",
      "The metrics are: 1.0044004519780476, 1.0324441989262898, and 1.0615877707799275\n",
      "Epoch [92/2000], Train Loss: 1.0318, Test Loss: 1.0322\n",
      "The metrics are: 1.0043184359868367, 1.0318379402160645, and 1.0604452689488728\n",
      "Epoch [93/2000], Train Loss: 1.0314, Test Loss: 1.0316\n",
      "The metrics are: 1.0042394797007244, 1.0312551657358806, and 1.059343417485555\n",
      "Epoch [94/2000], Train Loss: 1.0307, Test Loss: 1.0311\n",
      "The metrics are: 1.004163146018982, 1.0306919415791829, and 1.0582758982976277\n",
      "Epoch [95/2000], Train Loss: 1.0302, Test Loss: 1.0305\n",
      "The metrics are: 1.0040887991587322, 1.03014341990153, and 1.057238499323527\n",
      "Epoch [96/2000], Train Loss: 1.0295, Test Loss: 1.0299\n",
      "The metrics are: 1.0040162404378254, 1.0296082496643066, and 1.0562266111373901\n",
      "Epoch [97/2000], Train Loss: 1.0292, Test Loss: 1.0294\n",
      "The metrics are: 1.0039457082748413, 1.0290884971618652, and 1.0552409489949544\n",
      "Epoch [98/2000], Train Loss: 1.0289, Test Loss: 1.0289\n",
      "The metrics are: 1.0038769245147705, 1.0285801887512207, and 1.0542809963226318\n",
      "Epoch [99/2000], Train Loss: 1.0283, Test Loss: 1.0284\n",
      "The metrics are: 1.0038105249404907, 1.0280899206797283, and 1.053352991739909\n",
      "Epoch [100/2000], Train Loss: 1.0276, Test Loss: 1.0279\n",
      "The metrics are: 1.0037459929784138, 1.0276134808858235, and 1.0524510939915974\n",
      "Epoch [101/2000], Train Loss: 1.0270, Test Loss: 1.0274\n",
      "The metrics are: 1.0036829710006714, 1.0271497170130413, and 1.051572283109029\n",
      "Epoch [102/2000], Train Loss: 1.0266, Test Loss: 1.0270\n",
      "The metrics are: 1.0036216179529827, 1.0266964038213093, and 1.0507133801778157\n",
      "Epoch [103/2000], Train Loss: 1.0263, Test Loss: 1.0265\n",
      "The metrics are: 1.0035619735717773, 1.026256004969279, and 1.04987899462382\n",
      "Epoch [104/2000], Train Loss: 1.0257, Test Loss: 1.0261\n",
      "The metrics are: 1.003503640492757, 1.0258257389068604, and 1.0490647157033284\n",
      "Epoch [105/2000], Train Loss: 1.0253, Test Loss: 1.0257\n",
      "The metrics are: 1.0034465789794922, 1.0254046122233074, and 1.0482677618662517\n",
      "Epoch [106/2000], Train Loss: 1.0250, Test Loss: 1.0253\n",
      "The metrics are: 1.003390868504842, 1.0249933004379272, and 1.0474864641825359\n",
      "Epoch [107/2000], Train Loss: 1.0250, Test Loss: 1.0248\n",
      "The metrics are: 1.0033363501230876, 1.0245910088221233, and 1.046725829442342\n",
      "Epoch [108/2000], Train Loss: 1.0242, Test Loss: 1.0244\n",
      "The metrics are: 1.003283421198527, 1.0242009162902832, and 1.0459853013356526\n",
      "Epoch [109/2000], Train Loss: 1.0239, Test Loss: 1.0241\n",
      "The metrics are: 1.0032314856847127, 1.0238181749979656, and 1.0452603101730347\n",
      "Epoch [110/2000], Train Loss: 1.0235, Test Loss: 1.0237\n",
      "The metrics are: 1.0031810998916626, 1.0234459241231282, and 1.0445551872253418\n",
      "Epoch [111/2000], Train Loss: 1.0230, Test Loss: 1.0233\n",
      "The metrics are: 1.003131588300069, 1.0230807463328044, and 1.043862779935201\n",
      "Epoch [112/2000], Train Loss: 1.0228, Test Loss: 1.0230\n",
      "The metrics are: 1.0030829111735027, 1.022721807161967, and 1.0431841611862183\n",
      "Epoch [113/2000], Train Loss: 1.0224, Test Loss: 1.0226\n",
      "The metrics are: 1.0030357042948406, 1.0223737955093384, and 1.0425246953964233\n",
      "Epoch [114/2000], Train Loss: 1.0219, Test Loss: 1.0223\n",
      "The metrics are: 1.0029898881912231, 1.0220355987548828, and 1.0418822367986043\n",
      "Epoch [115/2000], Train Loss: 1.0216, Test Loss: 1.0219\n",
      "The metrics are: 1.0029444694519043, 1.0217008988062541, and 1.0412468512852986\n",
      "Epoch [116/2000], Train Loss: 1.0216, Test Loss: 1.0216\n",
      "The metrics are: 1.0028998057047527, 1.021370569864909, and 1.0406252145767212\n",
      "Epoch [117/2000], Train Loss: 1.0209, Test Loss: 1.0213\n",
      "The metrics are: 1.0028566122055054, 1.021052877108256, and 1.0400203863779705\n",
      "Epoch [118/2000], Train Loss: 1.0209, Test Loss: 1.0209\n",
      "The metrics are: 1.0028137763341267, 1.020735780398051, and 1.039422829945882\n",
      "Epoch [119/2000], Train Loss: 1.0205, Test Loss: 1.0206\n",
      "The metrics are: 1.0027721722920735, 1.020430286725362, and 1.0388428767522175\n",
      "Epoch [120/2000], Train Loss: 1.0202, Test Loss: 1.0203\n",
      "The metrics are: 1.002731204032898, 1.020127773284912, and 1.0382712682088215\n",
      "Epoch [121/2000], Train Loss: 1.0200, Test Loss: 1.0200\n",
      "The metrics are: 1.002691109975179, 1.019834041595459, and 1.0377167065938313\n",
      "Epoch [122/2000], Train Loss: 1.0193, Test Loss: 1.0197\n",
      "The metrics are: 1.0026519298553467, 1.0195460319519043, and 1.037171721458435\n",
      "Epoch [123/2000], Train Loss: 1.0192, Test Loss: 1.0194\n",
      "The metrics are: 1.0026137034098308, 1.019266168276469, and 1.0366407632827759\n",
      "Epoch [124/2000], Train Loss: 1.0189, Test Loss: 1.0192\n",
      "The metrics are: 1.002576231956482, 1.0189897219340007, and 1.0361178318659465\n",
      "Epoch [125/2000], Train Loss: 1.0187, Test Loss: 1.0189\n",
      "The metrics are: 1.0025394757588704, 1.0187199513117473, and 1.0356066226959229\n",
      "Epoch [126/2000], Train Loss: 1.0184, Test Loss: 1.0186\n",
      "The metrics are: 1.0025035937627156, 1.018454670906067, and 1.035105307896932\n",
      "Epoch [127/2000], Train Loss: 1.0181, Test Loss: 1.0184\n",
      "The metrics are: 1.0024686257044475, 1.0181970198949177, and 1.0346165498097737\n",
      "Epoch [128/2000], Train Loss: 1.0178, Test Loss: 1.0181\n",
      "The metrics are: 1.0024340947469075, 1.017941912015279, and 1.0341329177220662\n",
      "Epoch [129/2000], Train Loss: 1.0178, Test Loss: 1.0179\n",
      "The metrics are: 1.0024000406265259, 1.0176914930343628, and 1.0336602926254272\n",
      "Epoch [130/2000], Train Loss: 1.0173, Test Loss: 1.0176\n",
      "The metrics are: 1.0023672978083293, 1.0174497365951538, and 1.0332011779149373\n",
      "Epoch [131/2000], Train Loss: 1.0169, Test Loss: 1.0174\n",
      "The metrics are: 1.0023345152537029, 1.0172086954116821, and 1.0327433347702026\n",
      "Epoch [132/2000], Train Loss: 1.0172, Test Loss: 1.0171\n",
      "The metrics are: 1.002302606900533, 1.0169724225997925, and 1.0322962999343872\n",
      "Epoch [133/2000], Train Loss: 1.0167, Test Loss: 1.0169\n",
      "The metrics are: 1.0022714535395305, 1.016742746035258, and 1.0318597555160522\n",
      "Epoch [134/2000], Train Loss: 1.0165, Test Loss: 1.0167\n",
      "The metrics are: 1.002240498860677, 1.0165156523386638, and 1.0314292112986247\n",
      "Epoch [135/2000], Train Loss: 1.0163, Test Loss: 1.0164\n",
      "The metrics are: 1.002210219701131, 1.016291618347168, and 1.0310053428014119\n",
      "Epoch [136/2000], Train Loss: 1.0161, Test Loss: 1.0162\n",
      "The metrics are: 1.002180576324463, 1.0160738229751587, and 1.0305922031402588\n",
      "Epoch [137/2000], Train Loss: 1.0157, Test Loss: 1.0160\n",
      "The metrics are: 1.0021512111028035, 1.0158571004867554, and 1.030181606610616\n",
      "Epoch [138/2000], Train Loss: 1.0158, Test Loss: 1.0158\n",
      "The metrics are: 1.0021225214004517, 1.0156455437342327, and 1.0297811428705852\n",
      "Epoch [139/2000], Train Loss: 1.0154, Test Loss: 1.0156\n",
      "The metrics are: 1.0020947058995564, 1.0154401063919067, and 1.029390533765157\n",
      "Epoch [140/2000], Train Loss: 1.0151, Test Loss: 1.0154\n",
      "The metrics are: 1.0020670493443806, 1.0152359008789062, and 1.0290038188298543\n",
      "Epoch [141/2000], Train Loss: 1.0150, Test Loss: 1.0152\n",
      "The metrics are: 1.002039949099223, 1.01503590742747, and 1.0286242961883545\n",
      "Epoch [142/2000], Train Loss: 1.0148, Test Loss: 1.0150\n",
      "The metrics are: 1.0020132859547932, 1.014839808146159, and 1.0282526016235352\n",
      "Epoch [143/2000], Train Loss: 1.0145, Test Loss: 1.0148\n",
      "The metrics are: 1.0019872188568115, 1.0146475235621135, and 1.0278878211975098\n",
      "Epoch [144/2000], Train Loss: 1.0143, Test Loss: 1.0146\n",
      "The metrics are: 1.0019614299138386, 1.0144577423731487, and 1.0275282859802246\n",
      "Epoch [145/2000], Train Loss: 1.0141, Test Loss: 1.0144\n",
      "The metrics are: 1.0019362767537434, 1.014272650082906, and 1.027175744374593\n",
      "Epoch [146/2000], Train Loss: 1.0140, Test Loss: 1.0142\n",
      "The metrics are: 1.0019113222757976, 1.0140880743662517, and 1.0268268585205078\n",
      "Epoch [147/2000], Train Loss: 1.0138, Test Loss: 1.0140\n",
      "The metrics are: 1.0018868048985798, 1.0139076709747314, and 1.0264848073323567\n",
      "Epoch [148/2000], Train Loss: 1.0136, Test Loss: 1.0138\n",
      "The metrics are: 1.0018627246220906, 1.0137309630711873, and 1.0261488755544026\n",
      "Epoch [149/2000], Train Loss: 1.0134, Test Loss: 1.0137\n",
      "The metrics are: 1.0018390814463298, 1.0135558446248372, and 1.0258175134658813\n",
      "Epoch [150/2000], Train Loss: 1.0132, Test Loss: 1.0135\n",
      "The metrics are: 1.0018157561620076, 1.013384183247884, and 1.0254915555318196\n",
      "Epoch [151/2000], Train Loss: 1.0131, Test Loss: 1.0133\n",
      "The metrics are: 1.0017927487691243, 1.0132143100102742, and 1.025169809659322\n",
      "Epoch [152/2000], Train Loss: 1.0129, Test Loss: 1.0132\n",
      "The metrics are: 1.00177005926768, 1.0130470196406047, and 1.0248520374298096\n",
      "Epoch [153/2000], Train Loss: 1.0129, Test Loss: 1.0130\n",
      "The metrics are: 1.001747687657674, 1.0128827492396038, and 1.0245391527811687\n",
      "Epoch [154/2000], Train Loss: 1.0128, Test Loss: 1.0128\n",
      "The metrics are: 1.0017256339391072, 1.0127205451329548, and 1.0242315928141277\n",
      "Epoch [155/2000], Train Loss: 1.0125, Test Loss: 1.0127\n",
      "The metrics are: 1.0017039775848389, 1.0125608046849568, and 1.0239288806915283\n",
      "Epoch [156/2000], Train Loss: 1.0124, Test Loss: 1.0125\n",
      "The metrics are: 1.0016827980677288, 1.012404203414917, and 1.023632009824117\n",
      "Epoch [157/2000], Train Loss: 1.0121, Test Loss: 1.0123\n",
      "The metrics are: 1.001661737759908, 1.0122495492299397, and 1.023338794708252\n",
      "Epoch [158/2000], Train Loss: 1.0120, Test Loss: 1.0122\n",
      "The metrics are: 1.0016411542892456, 1.0120973189671834, and 1.0230501492818196\n",
      "Epoch [159/2000], Train Loss: 1.0119, Test Loss: 1.0120\n",
      "The metrics are: 1.001620928446452, 1.0119482676188152, and 1.0227666695912678\n",
      "Epoch [160/2000], Train Loss: 1.0117, Test Loss: 1.0119\n",
      "The metrics are: 1.0016009012858074, 1.01180100440979, and 1.0224873622258503\n",
      "Epoch [161/2000], Train Loss: 1.0115, Test Loss: 1.0117\n",
      "The metrics are: 1.0015811522801716, 1.0116551319758098, and 1.0222113927205403\n",
      "Epoch [162/2000], Train Loss: 1.0114, Test Loss: 1.0116\n",
      "The metrics are: 1.0015618801116943, 1.0115137497584026, and 1.0219417015711467\n",
      "Epoch [163/2000], Train Loss: 1.0113, Test Loss: 1.0115\n",
      "The metrics are: 1.0015426476796467, 1.0113718112309773, and 1.0216727654139202\n",
      "Epoch [164/2000], Train Loss: 1.0112, Test Loss: 1.0113\n",
      "The metrics are: 1.0015238523483276, 1.0112329721450806, and 1.0214095910390217\n",
      "Epoch [165/2000], Train Loss: 1.0109, Test Loss: 1.0112\n",
      "The metrics are: 1.001505176226298, 1.0110955635706584, and 1.0211488008499146\n",
      "Epoch [166/2000], Train Loss: 1.0109, Test Loss: 1.0110\n",
      "The metrics are: 1.001486857732137, 1.010960857073466, and 1.0208924214045207\n",
      "Epoch [167/2000], Train Loss: 1.0108, Test Loss: 1.0109\n",
      "The metrics are: 1.0014687776565552, 1.0108274618784587, and 1.0206389427185059\n",
      "Epoch [168/2000], Train Loss: 1.0107, Test Loss: 1.0108\n",
      "The metrics are: 1.0014509359995525, 1.0106952985127766, and 1.0203888018925984\n",
      "Epoch [169/2000], Train Loss: 1.0105, Test Loss: 1.0106\n",
      "The metrics are: 1.001433293024699, 1.010566512743632, and 1.0201442241668701\n",
      "Epoch [170/2000], Train Loss: 1.0102, Test Loss: 1.0105\n",
      "The metrics are: 1.0014160474141438, 1.0104384024937947, and 1.0199010372161865\n",
      "Epoch [171/2000], Train Loss: 1.0103, Test Loss: 1.0104\n",
      "The metrics are: 1.0013991196950276, 1.0103134314219158, and 1.0196639696757\n",
      "Epoch [172/2000], Train Loss: 1.0100, Test Loss: 1.0103\n",
      "The metrics are: 1.0013822317123413, 1.010189414024353, and 1.0194286505381267\n",
      "Epoch [173/2000], Train Loss: 1.0099, Test Loss: 1.0101\n",
      "The metrics are: 1.0013654629389446, 1.0100669463475545, and 1.0191954771677654\n",
      "Epoch [174/2000], Train Loss: 1.0099, Test Loss: 1.0100\n",
      "The metrics are: 1.0013490915298462, 1.0099455912907918, and 1.018965721130371\n",
      "Epoch [175/2000], Train Loss: 1.0097, Test Loss: 1.0099\n",
      "The metrics are: 1.001332958539327, 1.0098265012105305, and 1.0187394221623738\n",
      "Epoch [176/2000], Train Loss: 1.0097, Test Loss: 1.0098\n",
      "The metrics are: 1.001316984494527, 1.009708841641744, and 1.0185163418451946\n",
      "Epoch [177/2000], Train Loss: 1.0095, Test Loss: 1.0097\n",
      "The metrics are: 1.0013012091318767, 1.00959308942159, and 1.0182962814966838\n",
      "Epoch [178/2000], Train Loss: 1.0094, Test Loss: 1.0096\n",
      "The metrics are: 1.0012856324513753, 1.0094777345657349, and 1.0180778503417969\n",
      "Epoch [179/2000], Train Loss: 1.0093, Test Loss: 1.0094\n",
      "The metrics are: 1.0012702941894531, 1.0093650817871094, and 1.017863432566325\n",
      "Epoch [180/2000], Train Loss: 1.0092, Test Loss: 1.0093\n",
      "The metrics are: 1.0012551148732503, 1.009252945582072, and 1.0176503260930378\n",
      "Epoch [181/2000], Train Loss: 1.0092, Test Loss: 1.0092\n",
      "The metrics are: 1.0012401342391968, 1.0091431935628254, and 1.0174413919448853\n",
      "Epoch [182/2000], Train Loss: 1.0090, Test Loss: 1.0091\n",
      "The metrics are: 1.0012253522872925, 1.0090343157450359, and 1.0172348817189534\n",
      "Epoch [183/2000], Train Loss: 1.0088, Test Loss: 1.0090\n",
      "The metrics are: 1.0012108484903972, 1.0089272658030193, and 1.0170313119888306\n",
      "Epoch [184/2000], Train Loss: 1.0088, Test Loss: 1.0089\n",
      "The metrics are: 1.001196304957072, 1.0088204940160115, and 1.016828974088033\n",
      "Epoch [185/2000], Train Loss: 1.0087, Test Loss: 1.0088\n",
      "The metrics are: 1.0011820793151855, 1.0087153911590576, and 1.0166293382644653\n",
      "Epoch [186/2000], Train Loss: 1.0086, Test Loss: 1.0087\n",
      "The metrics are: 1.0011680920918782, 1.0086122353871663, and 1.0164333581924438\n",
      "Epoch [187/2000], Train Loss: 1.0084, Test Loss: 1.0086\n",
      "The metrics are: 1.001154104868571, 1.0085101922353108, and 1.0162392854690552\n",
      "Epoch [188/2000], Train Loss: 1.0084, Test Loss: 1.0085\n",
      "The metrics are: 1.0011404355367024, 1.008409063021342, and 1.0160478353500366\n",
      "Epoch [189/2000], Train Loss: 1.0082, Test Loss: 1.0084\n",
      "The metrics are: 1.0011269648869832, 1.0083096027374268, and 1.0158580938975017\n",
      "Epoch [190/2000], Train Loss: 1.0082, Test Loss: 1.0083\n",
      "The metrics are: 1.001113494237264, 1.0082106192906697, and 1.0156701803207397\n",
      "Epoch [191/2000], Train Loss: 1.0081, Test Loss: 1.0082\n",
      "The metrics are: 1.0011002620061238, 1.008112907409668, and 1.0154850482940674\n",
      "Epoch [192/2000], Train Loss: 1.0080, Test Loss: 1.0081\n",
      "The metrics are: 1.0010871887207031, 1.008016586303711, and 1.015302300453186\n",
      "Epoch [193/2000], Train Loss: 1.0079, Test Loss: 1.0080\n",
      "The metrics are: 1.0010741551717122, 1.0079212586085002, and 1.0151212612787883\n",
      "Epoch [194/2000], Train Loss: 1.0078, Test Loss: 1.0079\n",
      "The metrics are: 1.00106147925059, 1.0078280369440715, and 1.0149435997009277\n",
      "Epoch [195/2000], Train Loss: 1.0077, Test Loss: 1.0078\n",
      "The metrics are: 1.0010489225387573, 1.0077346960703533, and 1.0147669315338135\n",
      "Epoch [196/2000], Train Loss: 1.0076, Test Loss: 1.0077\n",
      "The metrics are: 1.0010364452997844, 1.0076428254445393, and 1.0145922899246216\n",
      "Epoch [197/2000], Train Loss: 1.0075, Test Loss: 1.0076\n",
      "The metrics are: 1.0010242064793904, 1.0075531005859375, and 1.0144213040669758\n",
      "Epoch [198/2000], Train Loss: 1.0074, Test Loss: 1.0075\n",
      "The metrics are: 1.0010119279225667, 1.0074630578358967, and 1.0142505566279094\n",
      "Epoch [199/2000], Train Loss: 1.0073, Test Loss: 1.0074\n",
      "The metrics are: 1.0010000864664714, 1.007374922434489, and 1.014083703358968\n",
      "Epoch [200/2000], Train Loss: 1.0071, Test Loss: 1.0073\n",
      "The metrics are: 1.000988205273946, 1.0072877804438274, and 1.0139178435007732\n",
      "Epoch [201/2000], Train Loss: 1.0072, Test Loss: 1.0073\n",
      "The metrics are: 1.0009764035542805, 1.0072016318639119, and 1.0137535730997722\n",
      "Epoch [202/2000], Train Loss: 1.0071, Test Loss: 1.0072\n",
      "The metrics are: 1.0009646813074748, 1.0071158011754353, and 1.0135906140009563\n",
      "Epoch [203/2000], Train Loss: 1.0070, Test Loss: 1.0071\n",
      "The metrics are: 1.0009533564249675, 1.0070315599441528, and 1.0134303967158\n",
      "Epoch [204/2000], Train Loss: 1.0069, Test Loss: 1.0070\n",
      "The metrics are: 1.0009419520696003, 1.0069478352864583, and 1.0132712920506795\n",
      "Epoch [205/2000], Train Loss: 1.0068, Test Loss: 1.0069\n",
      "The metrics are: 1.0009307463963826, 1.0068646669387817, and 1.0131136973698933\n",
      "Epoch [206/2000], Train Loss: 1.0068, Test Loss: 1.0068\n",
      "The metrics are: 1.000919500986735, 1.0067827701568604, and 1.0129581689834595\n",
      "Epoch [207/2000], Train Loss: 1.0067, Test Loss: 1.0068\n",
      "The metrics are: 1.0009085337320964, 1.0067023038864136, and 1.0128049453099568\n",
      "Epoch [208/2000], Train Loss: 1.0066, Test Loss: 1.0067\n",
      "The metrics are: 1.0008979241053264, 1.0066228707631428, and 1.0126542647679646\n",
      "Epoch [209/2000], Train Loss: 1.0064, Test Loss: 1.0066\n",
      "The metrics are: 1.000887115796407, 1.006543715794881, and 1.012503981590271\n",
      "Epoch [210/2000], Train Loss: 1.0064, Test Loss: 1.0065\n",
      "The metrics are: 1.0008763869603474, 1.0064653555552165, and 1.0123549699783325\n",
      "Epoch [211/2000], Train Loss: 1.0064, Test Loss: 1.0064\n",
      "The metrics are: 1.0008658170700073, 1.0063876310984294, and 1.0122073491414387\n",
      "Epoch [212/2000], Train Loss: 1.0063, Test Loss: 1.0064\n",
      "The metrics are: 1.0008554061253865, 1.0063111782073975, and 1.0120619138081868\n",
      "Epoch [213/2000], Train Loss: 1.0062, Test Loss: 1.0063\n",
      "The metrics are: 1.000845233599345, 1.0062354405721028, and 1.0119179089864094\n",
      "Epoch [214/2000], Train Loss: 1.0061, Test Loss: 1.0062\n",
      "The metrics are: 1.0008350213368733, 1.0061604579289753, and 1.0117757717768352\n",
      "Epoch [215/2000], Train Loss: 1.0060, Test Loss: 1.0061\n",
      "The metrics are: 1.0008249282836914, 1.0060867468516033, and 1.0116351048151653\n",
      "Epoch [216/2000], Train Loss: 1.0060, Test Loss: 1.0061\n",
      "The metrics are: 1.0008148749669392, 1.0060132344563801, and 1.0114954710006714\n",
      "Epoch [217/2000], Train Loss: 1.0059, Test Loss: 1.0060\n",
      "The metrics are: 1.0008050600687664, 1.0059407154719036, and 1.0113574266433716\n",
      "Epoch [218/2000], Train Loss: 1.0059, Test Loss: 1.0059\n",
      "The metrics are: 1.0007952054341633, 1.0058683554331462, and 1.0112202962239583\n",
      "Epoch [219/2000], Train Loss: 1.0058, Test Loss: 1.0058\n",
      "The metrics are: 1.0007855494817097, 1.0057971477508545, and 1.0110851923624675\n",
      "Epoch [220/2000], Train Loss: 1.0057, Test Loss: 1.0058\n",
      "The metrics are: 1.0007761716842651, 1.0057268937428792, and 1.0109515984853108\n",
      "Epoch [221/2000], Train Loss: 1.0056, Test Loss: 1.0057\n",
      "The metrics are: 1.0007667144139607, 1.005657434463501, and 1.0108197530110676\n",
      "Epoch [222/2000], Train Loss: 1.0055, Test Loss: 1.0056\n",
      "The metrics are: 1.0007573366165161, 1.0055889288584392, and 1.0106890598932903\n",
      "Epoch [223/2000], Train Loss: 1.0055, Test Loss: 1.0056\n",
      "The metrics are: 1.000748078028361, 1.0055211385091145, and 1.0105603535970051\n",
      "Epoch [224/2000], Train Loss: 1.0053, Test Loss: 1.0055\n",
      "The metrics are: 1.0007389386494954, 1.0054539839426677, and 1.010432481765747\n",
      "Epoch [225/2000], Train Loss: 1.0054, Test Loss: 1.0054\n",
      "The metrics are: 1.0007297595342, 1.0053869883219402, and 1.0103052457173665\n",
      "Epoch [226/2000], Train Loss: 1.0053, Test Loss: 1.0054\n",
      "The metrics are: 1.0007208188374836, 1.00532066822052, and 1.0101792414983113\n",
      "Epoch [227/2000], Train Loss: 1.0053, Test Loss: 1.0053\n",
      "The metrics are: 1.000711997350057, 1.0052554607391357, and 1.0100552638371785\n",
      "Epoch [228/2000], Train Loss: 1.0051, Test Loss: 1.0052\n",
      "The metrics are: 1.0007030566533406, 1.0051906903584797, and 1.0099318027496338\n",
      "Epoch [229/2000], Train Loss: 1.0052, Test Loss: 1.0052\n",
      "The metrics are: 1.0006943543752034, 1.0051261981328328, and 1.0098090569178264\n",
      "Epoch [230/2000], Train Loss: 1.0051, Test Loss: 1.0051\n",
      "The metrics are: 1.0006856520970662, 1.005062500635783, and 1.0096883376439412\n",
      "Epoch [231/2000], Train Loss: 1.0049, Test Loss: 1.0050\n",
      "The metrics are: 1.0006771087646484, 1.0049996773401897, and 1.009568691253662\n",
      "Epoch [232/2000], Train Loss: 1.0049, Test Loss: 1.0050\n",
      "The metrics are: 1.0006686449050903, 1.0049372911453247, and 1.0094503164291382\n",
      "Epoch [233/2000], Train Loss: 1.0048, Test Loss: 1.0049\n",
      "The metrics are: 1.0006603399912517, 1.004875938097636, and 1.009333610534668\n",
      "Epoch [234/2000], Train Loss: 1.0047, Test Loss: 1.0049\n",
      "The metrics are: 1.0006520350774128, 1.0048150618871052, and 1.009217619895935\n",
      "Epoch [235/2000], Train Loss: 1.0047, Test Loss: 1.0048\n",
      "The metrics are: 1.0006438493728638, 1.0047541856765747, and 1.0091025829315186\n",
      "Epoch [236/2000], Train Loss: 1.0046, Test Loss: 1.0047\n",
      "The metrics are: 1.0006356239318848, 1.0046944220860798, and 1.0089890162150066\n",
      "Epoch [237/2000], Train Loss: 1.0046, Test Loss: 1.0047\n",
      "The metrics are: 1.0006276369094849, 1.0046351353327434, and 1.008876085281372\n",
      "Epoch [238/2000], Train Loss: 1.0046, Test Loss: 1.0046\n",
      "The metrics are: 1.000619610150655, 1.004576325416565, and 1.0087637901306152\n",
      "Epoch [239/2000], Train Loss: 1.0045, Test Loss: 1.0046\n",
      "The metrics are: 1.0006115436553955, 1.0045177539189656, and 1.008652647336324\n",
      "Epoch [240/2000], Train Loss: 1.0044, Test Loss: 1.0045\n",
      "The metrics are: 1.0006037950515747, 1.0044602155685425, and 1.0085432926813762\n",
      "Epoch [241/2000], Train Loss: 1.0044, Test Loss: 1.0044\n",
      "The metrics are: 1.000596006711324, 1.004402995109558, and 1.0084344546000164\n",
      "Epoch [242/2000], Train Loss: 1.0043, Test Loss: 1.0044\n",
      "The metrics are: 1.0005882581075032, 1.0043463706970215, and 1.0083268483479817\n",
      "Epoch [243/2000], Train Loss: 1.0043, Test Loss: 1.0043\n",
      "The metrics are: 1.0005807081858318, 1.0042901833852131, and 1.0082199176152546\n",
      "Epoch [244/2000], Train Loss: 1.0042, Test Loss: 1.0043\n",
      "The metrics are: 1.0005730390548706, 1.0042342344919841, and 1.0081135034561157\n",
      "Epoch [245/2000], Train Loss: 1.0042, Test Loss: 1.0042\n",
      "The metrics are: 1.000565489133199, 1.0041789213816326, and 1.0080084800720215\n",
      "Epoch [246/2000], Train Loss: 1.0041, Test Loss: 1.0042\n",
      "The metrics are: 1.0005580981572468, 1.0041242440541585, and 1.0079044898351033\n",
      "Epoch [247/2000], Train Loss: 1.0040, Test Loss: 1.0041\n",
      "The metrics are: 1.0005507469177246, 1.0040701230367024, and 1.0078014532725017\n",
      "Epoch [248/2000], Train Loss: 1.0040, Test Loss: 1.0041\n",
      "The metrics are: 1.0005433559417725, 1.0040164788564045, and 1.0076994101206462\n",
      "Epoch [249/2000], Train Loss: 1.0040, Test Loss: 1.0040\n",
      "The metrics are: 1.0005360841751099, 1.0039631128311157, and 1.00759756565094\n",
      "Epoch [250/2000], Train Loss: 1.0040, Test Loss: 1.0039\n",
      "The metrics are: 1.000528891881307, 1.003909985224406, and 1.00749675432841\n",
      "Epoch [251/2000], Train Loss: 1.0038, Test Loss: 1.0039\n",
      "The metrics are: 1.0005218585332234, 1.0038578510284424, and 1.0073978106180828\n",
      "Epoch [252/2000], Train Loss: 1.0038, Test Loss: 1.0038\n",
      "The metrics are: 1.0005147457122803, 1.0038060744603474, and 1.0072993040084839\n",
      "Epoch [253/2000], Train Loss: 1.0037, Test Loss: 1.0038\n",
      "The metrics are: 1.0005076726277669, 1.0037548542022705, and 1.007201910018921\n",
      "Epoch [254/2000], Train Loss: 1.0037, Test Loss: 1.0037\n",
      "The metrics are: 1.0005007982254028, 1.0037037134170532, and 1.0071046749750774\n",
      "Epoch [255/2000], Train Loss: 1.0037, Test Loss: 1.0037\n",
      "The metrics are: 1.0004938840866089, 1.0036531289418538, and 1.0070083538691204\n",
      "Epoch [256/2000], Train Loss: 1.0036, Test Loss: 1.0036\n",
      "The metrics are: 1.0004870891571045, 1.0036028623580933, and 1.0069129467010498\n",
      "Epoch [257/2000], Train Loss: 1.0035, Test Loss: 1.0036\n",
      "The metrics are: 1.0004802147547405, 1.0035531918207805, and 1.006818373998006\n",
      "Epoch [258/2000], Train Loss: 1.0035, Test Loss: 1.0035\n",
      "The metrics are: 1.0004736582438152, 1.0035039186477661, and 1.0067245165507\n",
      "Epoch [259/2000], Train Loss: 1.0035, Test Loss: 1.0035\n",
      "The metrics are: 1.00046702226003, 1.00345512231191, and 1.0066321690877278\n",
      "Epoch [260/2000], Train Loss: 1.0034, Test Loss: 1.0034\n",
      "The metrics are: 1.0004603862762451, 1.0034066836039226, and 1.0065399408340454\n",
      "Epoch [261/2000], Train Loss: 1.0033, Test Loss: 1.0034\n",
      "The metrics are: 1.0004539092381795, 1.003359039624532, and 1.0064489444096882\n",
      "Epoch [262/2000], Train Loss: 1.0033, Test Loss: 1.0033\n",
      "The metrics are: 1.0004474719365437, 1.0033111174901326, and 1.0063581069310505\n",
      "Epoch [263/2000], Train Loss: 1.0033, Test Loss: 1.0033\n",
      "The metrics are: 1.0004409154256184, 1.0032637516657512, and 1.0062678654988606\n",
      "Epoch [264/2000], Train Loss: 1.0032, Test Loss: 1.0032\n",
      "The metrics are: 1.0004344781239827, 1.003216822942098, and 1.0061788161595662\n",
      "Epoch [265/2000], Train Loss: 1.0031, Test Loss: 1.0032\n",
      "The metrics are: 1.0004281997680664, 1.003170410792033, and 1.0060900449752808\n",
      "Epoch [266/2000], Train Loss: 1.0032, Test Loss: 1.0032\n",
      "The metrics are: 1.0004218022028606, 1.0031238794326782, and 1.0060018301010132\n",
      "Epoch [267/2000], Train Loss: 1.0031, Test Loss: 1.0031\n",
      "The metrics are: 1.000415563583374, 1.003078023592631, and 1.005914608637492\n",
      "Epoch [268/2000], Train Loss: 1.0030, Test Loss: 1.0031\n",
      "The metrics are: 1.000409444173177, 1.0030326843261719, and 1.0058281024297078\n",
      "Epoch [269/2000], Train Loss: 1.0030, Test Loss: 1.0030\n",
      "The metrics are: 1.0004033247629802, 1.0029874642690022, and 1.0057424306869507\n",
      "Epoch [270/2000], Train Loss: 1.0029, Test Loss: 1.0030\n",
      "The metrics are: 1.0003970861434937, 1.0029429197311401, and 1.005657394727071\n",
      "Epoch [271/2000], Train Loss: 1.0029, Test Loss: 1.0029\n",
      "The metrics are: 1.000391165415446, 1.0028982162475586, and 1.00557275613149\n",
      "Epoch [272/2000], Train Loss: 1.0028, Test Loss: 1.0029\n",
      "The metrics are: 1.000385085741679, 1.0028545061747234, and 1.0054893096288045\n",
      "Epoch [273/2000], Train Loss: 1.0028, Test Loss: 1.0028\n",
      "The metrics are: 1.000379165013631, 1.0028108755747478, and 1.005406379699707\n",
      "Epoch [274/2000], Train Loss: 1.0028, Test Loss: 1.0028\n",
      "The metrics are: 1.0003732442855835, 1.0027672449747722, and 1.0053237279256184\n",
      "Epoch [275/2000], Train Loss: 1.0027, Test Loss: 1.0028\n",
      "The metrics are: 1.0003674030303955, 1.002724250157674, and 1.005241831143697\n",
      "Epoch [276/2000], Train Loss: 1.0027, Test Loss: 1.0027\n",
      "The metrics are: 1.0003615617752075, 1.002681573232015, and 1.0051603714625041\n",
      "Epoch [277/2000], Train Loss: 1.0027, Test Loss: 1.0027\n",
      "The metrics are: 1.0003557999928792, 1.0026390552520752, and 1.0050793091456096\n",
      "Epoch [278/2000], Train Loss: 1.0026, Test Loss: 1.0026\n",
      "The metrics are: 1.000350038210551, 1.0025969346364338, and 1.004999081293742\n",
      "Epoch [279/2000], Train Loss: 1.0026, Test Loss: 1.0026\n",
      "The metrics are: 1.0003443559010823, 1.0025548537572224, and 1.004919131596883\n",
      "Epoch [280/2000], Train Loss: 1.0025, Test Loss: 1.0025\n",
      "The metrics are: 1.0003386338551838, 1.0025132497151692, and 1.0048402150472004\n",
      "Epoch [281/2000], Train Loss: 1.0025, Test Loss: 1.0025\n",
      "The metrics are: 1.0003331104914348, 1.002471923828125, and 1.0047616958618164\n",
      "Epoch [282/2000], Train Loss: 1.0024, Test Loss: 1.0025\n",
      "The metrics are: 1.000327467918396, 1.0024307568868, and 1.0046833356221516\n",
      "Epoch [283/2000], Train Loss: 1.0024, Test Loss: 1.0024\n",
      "The metrics are: 1.0003217856089275, 1.0023900667826335, and 1.004605809847514\n",
      "Epoch [284/2000], Train Loss: 1.0023, Test Loss: 1.0024\n",
      "The metrics are: 1.0003161032994587, 1.0023489793141682, and 1.0045278469721477\n",
      "Epoch [285/2000], Train Loss: 1.0023, Test Loss: 1.0023\n",
      "The metrics are: 1.000310738881429, 1.002308964729309, and 1.0044517119725545\n",
      "Epoch [286/2000], Train Loss: 1.0023, Test Loss: 1.0023\n",
      "The metrics are: 1.00030517578125, 1.00226887067159, and 1.0043754577636719\n",
      "Epoch [287/2000], Train Loss: 1.0022, Test Loss: 1.0023\n",
      "The metrics are: 1.0002998908360798, 1.0022294521331787, and 1.0043002367019653\n",
      "Epoch [288/2000], Train Loss: 1.0022, Test Loss: 1.0022\n",
      "The metrics are: 1.00029456615448, 1.002189834912618, and 1.0042253335316975\n",
      "Epoch [289/2000], Train Loss: 1.0021, Test Loss: 1.0022\n",
      "The metrics are: 1.0002891620000203, 1.0021509329477947, and 1.0041512250900269\n",
      "Epoch [290/2000], Train Loss: 1.0021, Test Loss: 1.0021\n",
      "The metrics are: 1.0002838373184204, 1.0021120707194011, and 1.0040773550669353\n",
      "Epoch [291/2000], Train Loss: 1.0021, Test Loss: 1.0021\n",
      "The metrics are: 1.00027863184611, 1.002073605855306, and 1.0040039618810017\n",
      "Epoch [292/2000], Train Loss: 1.0020, Test Loss: 1.0021\n",
      "The metrics are: 1.00027334690094, 1.0020352999369304, and 1.0039313236872356\n",
      "Epoch [293/2000], Train Loss: 1.0020, Test Loss: 1.0020\n",
      "The metrics are: 1.0002681811650593, 1.0019973119099934, and 1.0038588047027588\n",
      "Epoch [294/2000], Train Loss: 1.0020, Test Loss: 1.0020\n",
      "The metrics are: 1.000262935956319, 1.0019590854644775, and 1.0037862459818523\n",
      "Epoch [295/2000], Train Loss: 1.0020, Test Loss: 1.0019\n",
      "The metrics are: 1.0002578496932983, 1.0019216934839885, and 1.0037148396174114\n",
      "Epoch [296/2000], Train Loss: 1.0019, Test Loss: 1.0019\n",
      "The metrics are: 1.0002528031667073, 1.0018842617670696, and 1.0036438703536987\n",
      "Epoch [297/2000], Train Loss: 1.0018, Test Loss: 1.0019\n",
      "The metrics are: 1.0002477963765461, 1.0018474260965984, and 1.0035736958185832\n",
      "Epoch [298/2000], Train Loss: 1.0018, Test Loss: 1.0018\n",
      "The metrics are: 1.0002427101135254, 1.0018105506896973, and 1.0035034815470378\n",
      "Epoch [299/2000], Train Loss: 1.0018, Test Loss: 1.0018\n",
      "The metrics are: 1.0002376635869343, 1.0017739534378052, and 1.0034339030583699\n",
      "Epoch [300/2000], Train Loss: 1.0017, Test Loss: 1.0018\n",
      "The metrics are: 1.0002326170603435, 1.0017374753952026, and 1.0033644835154216\n",
      "Epoch [301/2000], Train Loss: 1.0017, Test Loss: 1.0017\n",
      "The metrics are: 1.0002278089523315, 1.0017011562983196, and 1.0032954613367717\n",
      "Epoch [302/2000], Train Loss: 1.0017, Test Loss: 1.0017\n",
      "The metrics are: 1.0002228418986003, 1.0016650358835857, and 1.0032268365224202\n",
      "Epoch [303/2000], Train Loss: 1.0016, Test Loss: 1.0017\n",
      "The metrics are: 1.000217874844869, 1.0016291936238606, and 1.0031583706537883\n",
      "Epoch [304/2000], Train Loss: 1.0016, Test Loss: 1.0016\n",
      "The metrics are: 1.0002129872639973, 1.0015933911005657, and 1.0030903418858845\n",
      "Epoch [305/2000], Train Loss: 1.0016, Test Loss: 1.0016\n",
      "The metrics are: 1.0002081394195557, 1.00155770778656, and 1.0030225118001301\n",
      "Epoch [306/2000], Train Loss: 1.0015, Test Loss: 1.0015\n",
      "The metrics are: 1.0002033313115437, 1.001522382100423, and 1.0029552380243938\n",
      "Epoch [307/2000], Train Loss: 1.0015, Test Loss: 1.0015\n",
      "The metrics are: 1.000198483467102, 1.001487135887146, and 1.0028884410858154\n",
      "Epoch [308/2000], Train Loss: 1.0015, Test Loss: 1.0015\n",
      "The metrics are: 1.00019375483195, 1.001452644666036, and 1.0028226375579834\n",
      "Epoch [309/2000], Train Loss: 1.0014, Test Loss: 1.0014\n",
      "The metrics are: 1.000188906987508, 1.0014177163441975, and 1.0027561982472737\n",
      "Epoch [310/2000], Train Loss: 1.0014, Test Loss: 1.0014\n",
      "The metrics are: 1.000184138615926, 1.0013830661773682, and 1.0026905536651611\n",
      "Epoch [311/2000], Train Loss: 1.0014, Test Loss: 1.0014\n",
      "The metrics are: 1.0001794497172039, 1.0013487736384075, and 1.0026252269744873\n",
      "Epoch [312/2000], Train Loss: 1.0013, Test Loss: 1.0013\n",
      "The metrics are: 1.000174840291341, 1.0013145605723064, and 1.002560059229533\n",
      "Epoch [313/2000], Train Loss: 1.0013, Test Loss: 1.0013\n",
      "The metrics are: 1.0001702706019084, 1.001280387242635, and 1.0024951696395874\n",
      "Epoch [314/2000], Train Loss: 1.0013, Test Loss: 1.0013\n",
      "The metrics are: 1.000165581703186, 1.0012465715408325, and 1.0024306774139404\n",
      "Epoch [315/2000], Train Loss: 1.0012, Test Loss: 1.0012\n",
      "The metrics are: 1.0001609325408936, 1.00121275583903, and 1.0023663838704426\n",
      "Epoch [316/2000], Train Loss: 1.0012, Test Loss: 1.0012\n",
      "The metrics are: 1.0001563628514607, 1.0011790990829468, and 1.0023023287455242\n",
      "Epoch [317/2000], Train Loss: 1.0012, Test Loss: 1.0012\n",
      "The metrics are: 1.0001516739527385, 1.001145601272583, and 1.002238392829895\n",
      "Epoch [318/2000], Train Loss: 1.0011, Test Loss: 1.0011\n",
      "The metrics are: 1.0001471439997356, 1.0011121829350789, and 1.0021750926971436\n",
      "Epoch [319/2000], Train Loss: 1.0011, Test Loss: 1.0011\n",
      "The metrics are: 1.0001425743103027, 1.0010791619618733, and 1.0021121899286907\n",
      "Epoch [320/2000], Train Loss: 1.0011, Test Loss: 1.0011\n",
      "The metrics are: 1.0001382033030193, 1.0010463794072468, and 1.0020495255788167\n",
      "Epoch [321/2000], Train Loss: 1.0010, Test Loss: 1.0010\n",
      "The metrics are: 1.000133713086446, 1.0010135173797607, and 1.001987059911092\n",
      "Epoch [322/2000], Train Loss: 1.0010, Test Loss: 1.0010\n",
      "The metrics are: 1.0001291036605835, 1.0009804964065552, and 1.0019242763519287\n",
      "Epoch [323/2000], Train Loss: 1.0010, Test Loss: 1.0010\n",
      "The metrics are: 1.0001246134440105, 1.0009479125340779, and 1.0018622477849324\n",
      "Epoch [324/2000], Train Loss: 1.0009, Test Loss: 1.0009\n",
      "The metrics are: 1.0001201629638672, 1.0009153286616008, and 1.0018001794815063\n",
      "Epoch [325/2000], Train Loss: 1.0009, Test Loss: 1.0009\n",
      "The metrics are: 1.0001157919565837, 1.0008830229441326, and 1.0017388661702473\n",
      "Epoch [326/2000], Train Loss: 1.0009, Test Loss: 1.0009\n",
      "The metrics are: 1.0001112620035808, 1.0008506774902344, and 1.0016771952311199\n",
      "Epoch [327/2000], Train Loss: 1.0009, Test Loss: 1.0008\n",
      "The metrics are: 1.0001068512598674, 1.0008185307184856, and 1.00161608060201\n",
      "Epoch [328/2000], Train Loss: 1.0008, Test Loss: 1.0008\n",
      "The metrics are: 1.0001025199890137, 1.000786264737447, and 1.0015548865000408\n",
      "Epoch [329/2000], Train Loss: 1.0008, Test Loss: 1.0008\n",
      "The metrics are: 1.0000981489817302, 1.0007543166478474, and 1.0014938910802205\n",
      "Epoch [330/2000], Train Loss: 1.0007, Test Loss: 1.0007\n",
      "The metrics are: 1.0000937382380168, 1.0007221698760986, and 1.00143297513326\n",
      "Epoch [331/2000], Train Loss: 1.0007, Test Loss: 1.0007\n",
      "The metrics are: 1.0000893274943035, 1.0006903807322185, and 1.0013724168141682\n",
      "Epoch [332/2000], Train Loss: 1.0007, Test Loss: 1.0007\n",
      "The metrics are: 1.0000849564870198, 1.0006582736968994, and 1.0013116598129272\n",
      "Epoch [333/2000], Train Loss: 1.0007, Test Loss: 1.0006\n",
      "The metrics are: 1.0000805854797363, 1.000626564025879, and 1.0012511014938354\n",
      "Epoch [334/2000], Train Loss: 1.0006, Test Loss: 1.0006\n",
      "The metrics are: 1.0000763336817424, 1.0005950530370076, and 1.0011912981669109\n",
      "Epoch [335/2000], Train Loss: 1.0006, Test Loss: 1.0006\n",
      "The metrics are: 1.000071922938029, 1.0005635023117065, and 1.0011314551035564\n",
      "Epoch [336/2000], Train Loss: 1.0006, Test Loss: 1.0006\n",
      "The metrics are: 1.0000675916671753, 1.000532070795695, and 1.0010713338851929\n",
      "Epoch [337/2000], Train Loss: 1.0005, Test Loss: 1.0005\n",
      "The metrics are: 1.0000632603963215, 1.0005006392796834, and 1.001011610031128\n",
      "Epoch [338/2000], Train Loss: 1.0005, Test Loss: 1.0005\n",
      "The metrics are: 1.000058929125468, 1.0004692872365315, and 1.0009518067042034\n",
      "Epoch [339/2000], Train Loss: 1.0005, Test Loss: 1.0005\n",
      "The metrics are: 1.0000547568003337, 1.000438133875529, and 1.0008926788965862\n",
      "Epoch [340/2000], Train Loss: 1.0004, Test Loss: 1.0004\n",
      "The metrics are: 1.0000503460566204, 1.0004069010416667, and 1.0008331537246704\n",
      "Epoch [341/2000], Train Loss: 1.0004, Test Loss: 1.0004\n",
      "The metrics are: 1.0000461339950562, 1.0003753900527954, and 1.000773509343465\n",
      "Epoch [342/2000], Train Loss: 1.0004, Test Loss: 1.0004\n",
      "The metrics are: 1.0000417232513428, 1.0003443161646526, and 1.0007143417994182\n",
      "Epoch [343/2000], Train Loss: 1.0003, Test Loss: 1.0003\n",
      "The metrics are: 1.0000375111897786, 1.0003132422765095, and 1.0006550947825115\n",
      "Epoch [344/2000], Train Loss: 1.0003, Test Loss: 1.0003\n",
      "The metrics are: 1.0000332196553547, 1.0002821286519368, and 1.0005959272384644\n",
      "Epoch [345/2000], Train Loss: 1.0003, Test Loss: 1.0003\n",
      "The metrics are: 1.000028928120931, 1.0002508163452148, and 1.0005366404851277\n",
      "Epoch [346/2000], Train Loss: 1.0003, Test Loss: 1.0002\n",
      "The metrics are: 1.0000246167182922, 1.0002195835113525, and 1.0004773537317913\n",
      "Epoch [347/2000], Train Loss: 1.0002, Test Loss: 1.0002\n",
      "The metrics are: 1.0000203649202983, 1.0001883506774902, and 1.0004177888234456\n",
      "Epoch [348/2000], Train Loss: 1.0002, Test Loss: 1.0002\n",
      "The metrics are: 1.0000161329905193, 1.0001572767893474, and 1.0003586610158284\n",
      "Epoch [349/2000], Train Loss: 1.0002, Test Loss: 1.0001\n",
      "The metrics are: 1.0000117619832356, 1.0001262029012044, and 1.0002997716267903\n",
      "Epoch [350/2000], Train Loss: 1.0001, Test Loss: 1.0001\n",
      "The metrics are: 1.0000074704488118, 1.000095049540202, and 1.0002403656641643\n",
      "Epoch [351/2000], Train Loss: 1.0001, Test Loss: 1.0001\n",
      "The metrics are: 1.0000032583872478, 1.000064214070638, and 1.0001819133758545\n",
      "Epoch [352/2000], Train Loss: 1.0001, Test Loss: 1.0001\n",
      "The metrics are: 0.999998927116394, 1.000033179918925, and 1.0001229047775269\n",
      "Epoch [353/2000], Train Loss: 1.0000, Test Loss: 1.0000\n",
      "The metrics are: 0.9999946753184, 1.0000022252400715, and 1.000063916047414\n",
      "Epoch [354/2000], Train Loss: 1.0000, Test Loss: 1.0000\n",
      "The metrics are: 0.9999904632568359, 0.9999709129333496, and 1.000004490216573\n",
      "Epoch [355/2000], Train Loss: 1.0000, Test Loss: 1.0000\n",
      "The metrics are: 0.9999860922495524, 0.9999397794405619, and 0.9999454021453857\n",
      "Epoch [356/2000], Train Loss: 0.9999, Test Loss: 0.9999\n",
      "The metrics are: 0.9999817808469137, 0.9999087055524191, and 0.9998861153920492\n",
      "Epoch [357/2000], Train Loss: 0.9999, Test Loss: 0.9999\n",
      "The metrics are: 0.9999774098396301, 0.9998775521914164, and 0.9998268882433573\n",
      "Epoch [358/2000], Train Loss: 0.9999, Test Loss: 0.9999\n",
      "The metrics are: 0.9999732772509257, 0.9998465379079183, and 0.9997678399085999\n",
      "Epoch [359/2000], Train Loss: 0.9999, Test Loss: 0.9998\n",
      "The metrics are: 0.9999687870343527, 0.9998151659965515, and 0.9997082153956095\n",
      "Epoch [360/2000], Train Loss: 0.9998, Test Loss: 0.9998\n",
      "The metrics are: 0.9999645551045736, 0.9997835954030355, and 0.9996484518051147\n",
      "Epoch [361/2000], Train Loss: 0.9998, Test Loss: 0.9998\n",
      "The metrics are: 0.9999601046244303, 0.9997521837552389, and 0.9995888471603394\n",
      "Epoch [362/2000], Train Loss: 0.9998, Test Loss: 0.9997\n",
      "The metrics are: 0.9999558130900065, 0.9997207522392273, and 0.9995288451512655\n",
      "Epoch [363/2000], Train Loss: 0.9997, Test Loss: 0.9997\n",
      "The metrics are: 0.9999515215555826, 0.9996892213821411, and 0.999468723932902\n",
      "Epoch [364/2000], Train Loss: 0.9997, Test Loss: 0.9997\n",
      "The metrics are: 0.9999470909436544, 0.999657412370046, and 0.9994082848230997\n",
      "Epoch [365/2000], Train Loss: 0.9997, Test Loss: 0.9996\n",
      "The metrics are: 0.9999425609906515, 0.9996251861254374, and 0.9993475476900736\n",
      "Epoch [366/2000], Train Loss: 0.9996, Test Loss: 0.9996\n",
      "The metrics are: 0.9999382495880127, 0.9995933572451273, and 0.9992869098981222\n",
      "Epoch [367/2000], Train Loss: 0.9996, Test Loss: 0.9996\n",
      "The metrics are: 0.9999337991078695, 0.9995614091555277, and 0.9992262323697408\n",
      "Epoch [368/2000], Train Loss: 0.9996, Test Loss: 0.9995\n",
      "The metrics are: 0.9999294877052307, 0.9995294213294983, and 0.9991655349731445\n",
      "Epoch [369/2000], Train Loss: 0.9995, Test Loss: 0.9995\n",
      "The metrics are: 0.9999250173568726, 0.9994972348213196, and 0.9991045395533243\n",
      "Epoch [370/2000], Train Loss: 0.9995, Test Loss: 0.9995\n",
      "The metrics are: 0.9999205072720846, 0.9994648893674215, and 0.9990431070327759\n",
      "Epoch [371/2000], Train Loss: 0.9995, Test Loss: 0.9995\n",
      "The metrics are: 0.9999160766601562, 0.9994325439135233, and 0.9989814956982931\n",
      "Epoch [372/2000], Train Loss: 0.9995, Test Loss: 0.9994\n",
      "The metrics are: 0.9999114076296488, 0.9993996818860372, and 0.9989189306894938\n",
      "Epoch [373/2000], Train Loss: 0.9994, Test Loss: 0.9994\n",
      "The metrics are: 0.9999069174130758, 0.9993667999903361, and 0.9988567431767782\n",
      "Epoch [374/2000], Train Loss: 0.9994, Test Loss: 0.9994\n",
      "The metrics are: 0.9999023079872131, 0.9993334809939066, and 0.9987936019897461\n",
      "Epoch [375/2000], Train Loss: 0.9993, Test Loss: 0.9993\n",
      "The metrics are: 0.9998977184295654, 0.9993004401524862, and 0.9987307588259379\n",
      "Epoch [376/2000], Train Loss: 0.9993, Test Loss: 0.9993\n",
      "The metrics are: 0.9998930891354879, 0.999267041683197, and 0.998667041460673\n",
      "Epoch [377/2000], Train Loss: 0.9993, Test Loss: 0.9993\n",
      "The metrics are: 0.9998883605003357, 0.9992332061131796, and 0.9986030459403992\n",
      "Epoch [378/2000], Train Loss: 0.9993, Test Loss: 0.9992\n",
      "The metrics are: 0.9998835523923238, 0.9991993109385172, and 0.998538613319397\n",
      "Epoch [379/2000], Train Loss: 0.9992, Test Loss: 0.9992\n",
      "The metrics are: 0.9998789032300314, 0.9991652170817057, and 0.9984739422798157\n",
      "Epoch [380/2000], Train Loss: 0.9992, Test Loss: 0.9992\n",
      "The metrics are: 0.9998741745948792, 0.99913090467453, and 0.9984087546666464\n",
      "Epoch [381/2000], Train Loss: 0.9992, Test Loss: 0.9991\n",
      "The metrics are: 0.9998694260915121, 0.99909641345342, and 0.9983434081077576\n",
      "Epoch [382/2000], Train Loss: 0.9991, Test Loss: 0.9991\n",
      "The metrics are: 0.9998645385106405, 0.9990615447362264, and 0.9982773462931315\n",
      "Epoch [383/2000], Train Loss: 0.9991, Test Loss: 0.9990\n",
      "The metrics are: 0.9998596707979838, 0.9990265170733134, and 0.9982104698816935\n",
      "Epoch [384/2000], Train Loss: 0.9990, Test Loss: 0.9990\n",
      "The metrics are: 0.9998546441396078, 0.9989909331003824, and 0.9981429775555929\n",
      "Epoch [385/2000], Train Loss: 0.9990, Test Loss: 0.9990\n",
      "The metrics are: 0.9998496770858765, 0.998954971631368, and 0.9980749090512594\n",
      "Epoch [386/2000], Train Loss: 0.9990, Test Loss: 0.9989\n",
      "The metrics are: 0.9998445908228556, 0.9989186525344849, and 0.9980062246322632\n",
      "Epoch [387/2000], Train Loss: 0.9989, Test Loss: 0.9989\n",
      "The metrics are: 0.9998395244280497, 0.9988826314608256, and 0.9979372223218282\n",
      "Epoch [388/2000], Train Loss: 0.9989, Test Loss: 0.9989\n",
      "The metrics are: 0.999834418296814, 0.9988453586896261, and 0.9978667497634888\n",
      "Epoch [389/2000], Train Loss: 0.9989, Test Loss: 0.9988\n",
      "The metrics are: 0.9998291532198588, 0.9988082846005758, and 0.9977964162826538\n",
      "Epoch [390/2000], Train Loss: 0.9989, Test Loss: 0.9988\n",
      "The metrics are: 0.999824066956838, 0.9987707336743673, and 0.9977255066235861\n",
      "Epoch [391/2000], Train Loss: 0.9988, Test Loss: 0.9988\n",
      "The metrics are: 0.9998187224070231, 0.9987326463063558, and 0.9976531267166138\n",
      "Epoch [392/2000], Train Loss: 0.9988, Test Loss: 0.9987\n",
      "The metrics are: 0.9998133182525635, 0.9986942013104757, and 0.9975800315539042\n",
      "Epoch [393/2000], Train Loss: 0.9987, Test Loss: 0.9987\n",
      "The metrics are: 0.9998078942298889, 0.9986552794774374, and 0.997506300608317\n",
      "Epoch [394/2000], Train Loss: 0.9987, Test Loss: 0.9986\n",
      "The metrics are: 0.999802311261495, 0.9986157218615214, and 0.9974311391512553\n",
      "Epoch [395/2000], Train Loss: 0.9986, Test Loss: 0.9986\n",
      "The metrics are: 0.9997967680295309, 0.9985753496487936, and 0.997354785601298\n",
      "Epoch [396/2000], Train Loss: 0.9986, Test Loss: 0.9986\n",
      "The metrics are: 0.9997910261154175, 0.9985349973042806, and 0.997278074423472\n",
      "Epoch [397/2000], Train Loss: 0.9986, Test Loss: 0.9985\n",
      "The metrics are: 0.9997853636741638, 0.9984936118125916, and 0.997200071811676\n",
      "Epoch [398/2000], Train Loss: 0.9985, Test Loss: 0.9985\n",
      "The metrics are: 0.9997795224189758, 0.9984524051348368, and 0.9971214334170023\n",
      "Epoch [399/2000], Train Loss: 0.9985, Test Loss: 0.9984\n",
      "The metrics are: 0.9997735818227133, 0.9984099070231119, and 0.9970409870147705\n",
      "Epoch [400/2000], Train Loss: 0.9984, Test Loss: 0.9984\n",
      "The metrics are: 0.9997675816218058, 0.9983668128649393, and 0.9969594875971476\n",
      "Epoch [401/2000], Train Loss: 0.9984, Test Loss: 0.9984\n",
      "The metrics are: 0.9997615019480387, 0.9983233213424683, and 0.996876855691274\n",
      "Epoch [402/2000], Train Loss: 0.9984, Test Loss: 0.9983\n",
      "The metrics are: 0.9997553825378418, 0.9982794523239136, and 0.9967935085296631\n",
      "Epoch [403/2000], Train Loss: 0.9983, Test Loss: 0.9983\n",
      "The metrics are: 0.999748945236206, 0.9982342521349589, and 0.9967078963915507\n",
      "Epoch [404/2000], Train Loss: 0.9983, Test Loss: 0.9982\n",
      "The metrics are: 0.9997425476710001, 0.9981883565584818, and 0.9966211716334025\n",
      "Epoch [405/2000], Train Loss: 0.9982, Test Loss: 0.9982\n",
      "The metrics are: 0.9997360110282898, 0.9981418053309122, and 0.9965325991312662\n",
      "Epoch [406/2000], Train Loss: 0.9982, Test Loss: 0.9981\n",
      "The metrics are: 0.9997293750445048, 0.9980942606925964, and 0.9964432120323181\n",
      "Epoch [407/2000], Train Loss: 0.9982, Test Loss: 0.9981\n",
      "The metrics are: 0.9997225602467855, 0.9980461001396179, and 0.9963515599568685\n",
      "Epoch [408/2000], Train Loss: 0.9981, Test Loss: 0.9980\n",
      "The metrics are: 0.9997156262397766, 0.9979963699976603, and 0.9962576429049174\n",
      "Epoch [409/2000], Train Loss: 0.9980, Test Loss: 0.9980\n",
      "The metrics are: 0.9997085134188334, 0.997946043809255, and 0.9961627523104349\n",
      "Epoch [410/2000], Train Loss: 0.9980, Test Loss: 0.9979\n",
      "The metrics are: 0.9997014204661051, 0.9978956778844198, and 0.9960667490959167\n",
      "Epoch [411/2000], Train Loss: 0.9979, Test Loss: 0.9979\n",
      "The metrics are: 0.9996941486994425, 0.9978435635566711, and 0.9959682822227478\n",
      "Epoch [412/2000], Train Loss: 0.9979, Test Loss: 0.9978\n",
      "The metrics are: 0.999686598777771, 0.9977906346321106, and 0.9958675305048624\n",
      "Epoch [413/2000], Train Loss: 0.9978, Test Loss: 0.9978\n",
      "The metrics are: 0.99967888991038, 0.9977356394131979, and 0.9957636793454488\n",
      "Epoch [414/2000], Train Loss: 0.9978, Test Loss: 0.9977\n",
      "The metrics are: 0.9996711214383444, 0.9976799488067627, and 0.995658278465271\n",
      "Epoch [415/2000], Train Loss: 0.9977, Test Loss: 0.9977\n",
      "The metrics are: 0.9996630350748698, 0.9976230263710022, and 0.9955504536628723\n",
      "Epoch [416/2000], Train Loss: 0.9977, Test Loss: 0.9976\n",
      "The metrics are: 0.9996547698974609, 0.9975642760594686, and 0.9954395492871603\n",
      "Epoch [417/2000], Train Loss: 0.9976, Test Loss: 0.9975\n",
      "The metrics are: 0.9996462464332581, 0.9975042740503947, and 0.9953258434931437\n",
      "Epoch [418/2000], Train Loss: 0.9975, Test Loss: 0.9975\n",
      "The metrics are: 0.999637504418691, 0.9974425037701925, and 0.9952089389165243\n",
      "Epoch [419/2000], Train Loss: 0.9975, Test Loss: 0.9974\n",
      "The metrics are: 0.9996285835901896, 0.997379461924235, and 0.9950896501541138\n",
      "Epoch [420/2000], Train Loss: 0.9975, Test Loss: 0.9974\n",
      "The metrics are: 0.9996193846066793, 0.9973141153653463, and 0.9949662685394287\n",
      "Epoch [421/2000], Train Loss: 0.9974, Test Loss: 0.9973\n",
      "The metrics are: 0.9996098677317301, 0.9972472786903381, and 0.9948398669560751\n",
      "Epoch [422/2000], Train Loss: 0.9973, Test Loss: 0.9972\n",
      "The metrics are: 0.9996001124382019, 0.9971782366434733, and 0.9947096506754557\n",
      "Epoch [423/2000], Train Loss: 0.9972, Test Loss: 0.9972\n",
      "The metrics are: 0.9995901385943095, 0.9971074461936951, and 0.9945757190386454\n",
      "Epoch [424/2000], Train Loss: 0.9972, Test Loss: 0.9971\n",
      "The metrics are: 0.9995796283086141, 0.9970340530077616, and 0.9944369594256083\n",
      "Epoch [425/2000], Train Loss: 0.9971, Test Loss: 0.9970\n",
      "The metrics are: 0.9995688796043396, 0.9969581564267477, and 0.9942934910456339\n",
      "Epoch [426/2000], Train Loss: 0.9970, Test Loss: 0.9969\n",
      "The metrics are: 0.9995577732721964, 0.9968800147374471, and 0.9941465258598328\n",
      "Epoch [427/2000], Train Loss: 0.9970, Test Loss: 0.9969\n",
      "The metrics are: 0.9995462695757548, 0.9967997272809347, and 0.9939944346745809\n",
      "Epoch [428/2000], Train Loss: 0.9969, Test Loss: 0.9968\n",
      "The metrics are: 0.9995344877243042, 0.9967170357704163, and 0.9938385089238485\n",
      "Epoch [429/2000], Train Loss: 0.9968, Test Loss: 0.9967\n",
      "The metrics are: 0.9995223085085551, 0.9966311852137247, and 0.9936765233675638\n",
      "Epoch [430/2000], Train Loss: 0.9967, Test Loss: 0.9966\n",
      "The metrics are: 0.9995095531145731, 0.9965410232543945, and 0.9935071070988973\n",
      "Epoch [431/2000], Train Loss: 0.9966, Test Loss: 0.9965\n",
      "The metrics are: 0.9994962016741434, 0.9964480996131897, and 0.9933313330014547\n",
      "Epoch [432/2000], Train Loss: 0.9965, Test Loss: 0.9964\n",
      "The metrics are: 0.9994824330012003, 0.9963515003522238, and 0.9931490222613016\n",
      "Epoch [433/2000], Train Loss: 0.9964, Test Loss: 0.9963\n",
      "The metrics are: 0.9994680285453796, 0.9962509274482727, and 0.9929587244987488\n",
      "Epoch [434/2000], Train Loss: 0.9963, Test Loss: 0.9962\n",
      "The metrics are: 0.9994529883066813, 0.9961460630098978, and 0.9927613536516825\n",
      "Epoch [435/2000], Train Loss: 0.9963, Test Loss: 0.9961\n",
      "The metrics are: 0.9994372725486755, 0.9960368871688843, and 0.992555558681488\n",
      "Epoch [436/2000], Train Loss: 0.9961, Test Loss: 0.9960\n",
      "The metrics are: 0.9994207620620728, 0.995921770731608, and 0.9923386772473654\n",
      "Epoch [437/2000], Train Loss: 0.9960, Test Loss: 0.9959\n",
      "The metrics are: 0.9994038343429565, 0.9958027998606364, and 0.9921139677365621\n",
      "Epoch [438/2000], Train Loss: 0.9959, Test Loss: 0.9958\n",
      "The metrics are: 0.9993858337402344, 0.9956774711608887, and 0.9918781916300455\n",
      "Epoch [439/2000], Train Loss: 0.9958, Test Loss: 0.9956\n",
      "The metrics are: 0.999366839726766, 0.9955456455548605, and 0.9916305144627889\n",
      "Epoch [440/2000], Train Loss: 0.9957, Test Loss: 0.9955\n",
      "The metrics are: 0.9993468920389811, 0.9954079786936442, and 0.9913709163665771\n",
      "Epoch [441/2000], Train Loss: 0.9955, Test Loss: 0.9954\n",
      "The metrics are: 0.9993258913358053, 0.995262602965037, and 0.9910967747370402\n",
      "Epoch [442/2000], Train Loss: 0.9954, Test Loss: 0.9952\n",
      "The metrics are: 0.9993034998575846, 0.9951083262761434, and 0.9908061822255453\n",
      "Epoch [443/2000], Train Loss: 0.9952, Test Loss: 0.9951\n",
      "The metrics are: 0.9992798765500387, 0.9949450890223185, and 0.9905001322428385\n",
      "Epoch [444/2000], Train Loss: 0.9951, Test Loss: 0.9949\n",
      "The metrics are: 0.9992546836535136, 0.9947718381881714, and 0.9901727040608724\n",
      "Epoch [445/2000], Train Loss: 0.9948, Test Loss: 0.9947\n",
      "The metrics are: 0.9992280205090841, 0.9945877989133199, and 0.9898280104001363\n",
      "Epoch [446/2000], Train Loss: 0.9948, Test Loss: 0.9945\n",
      "The metrics are: 0.999199390411377, 0.9943918387095133, and 0.9894601702690125\n",
      "Epoch [447/2000], Train Loss: 0.9946, Test Loss: 0.9943\n",
      "The metrics are: 0.9991687536239624, 0.9941821893056234, and 0.9890665610631307\n",
      "Epoch [448/2000], Train Loss: 0.9943, Test Loss: 0.9941\n",
      "The metrics are: 0.9991356531778971, 0.993957499663035, and 0.9886430303255717\n",
      "Epoch [449/2000], Train Loss: 0.9940, Test Loss: 0.9939\n",
      "The metrics are: 0.9990999698638916, 0.9937134981155396, and 0.9881867369016012\n",
      "Epoch [450/2000], Train Loss: 0.9939, Test Loss: 0.9936\n",
      "The metrics are: 0.9990617434183756, 0.9934531450271606, and 0.9876990715662638\n",
      "Epoch [451/2000], Train Loss: 0.9937, Test Loss: 0.9934\n",
      "The metrics are: 0.999019722143809, 0.9931690096855164, and 0.9871670405069987\n",
      "Epoch [452/2000], Train Loss: 0.9933, Test Loss: 0.9931\n",
      "The metrics are: 0.9989739656448364, 0.9928604364395142, and 0.986589233080546\n",
      "Epoch [453/2000], Train Loss: 0.9930, Test Loss: 0.9927\n",
      "The metrics are: 0.9989239772160848, 0.992524524529775, and 0.9859593113263448\n",
      "Epoch [454/2000], Train Loss: 0.9927, Test Loss: 0.9924\n",
      "The metrics are: 0.9988687038421631, 0.9921557505925497, and 0.9852708776791891\n",
      "Epoch [455/2000], Train Loss: 0.9925, Test Loss: 0.9920\n",
      "The metrics are: 0.9988072315851847, 0.9917458295822144, and 0.9845055143038431\n",
      "Epoch [456/2000], Train Loss: 0.9920, Test Loss: 0.9916\n",
      "The metrics are: 0.9987387657165527, 0.9912925759951273, and 0.9836583336194357\n",
      "Epoch [457/2000], Train Loss: 0.9916, Test Loss: 0.9911\n",
      "The metrics are: 0.9986616770426432, 0.9907850027084351, and 0.9827091892560323\n",
      "Epoch [458/2000], Train Loss: 0.9910, Test Loss: 0.9906\n",
      "The metrics are: 0.9985735813776652, 0.9902079701423645, and 0.981636106967926\n",
      "Epoch [459/2000], Train Loss: 0.9906, Test Loss: 0.9900\n",
      "The metrics are: 0.9984720349311829, 0.9895490209261576, and 0.9804097215334574\n",
      "Epoch [460/2000], Train Loss: 0.9898, Test Loss: 0.9893\n",
      "The metrics are: 0.998353918393453, 0.9887910087903341, and 0.9790010253588358\n",
      "Epoch [461/2000], Train Loss: 0.9892, Test Loss: 0.9885\n",
      "The metrics are: 0.9982137282689413, 0.9879007538159689, and 0.9773491024971008\n",
      "Epoch [462/2000], Train Loss: 0.9884, Test Loss: 0.9875\n",
      "The metrics are: 0.9980439941088358, 0.9868361751238505, and 0.9753714601198832\n",
      "Epoch [463/2000], Train Loss: 0.9873, Test Loss: 0.9864\n",
      "The metrics are: 0.997836192448934, 0.9855555295944214, and 0.9729933341344198\n",
      "Epoch [464/2000], Train Loss: 0.9863, Test Loss: 0.9850\n",
      "The metrics are: 0.9975719650586446, 0.9839557607968649, and 0.9700111150741577\n",
      "Epoch [465/2000], Train Loss: 0.9846, Test Loss: 0.9833\n",
      "The metrics are: 0.9972251454989115, 0.9818931221961975, and 0.9661908547083536\n",
      "Epoch [466/2000], Train Loss: 0.9832, Test Loss: 0.9810\n",
      "The metrics are: 0.9967426458994547, 0.9791039029757181, and 0.9609882831573486\n",
      "Epoch [467/2000], Train Loss: 0.9804, Test Loss: 0.9778\n",
      "The metrics are: 0.996023952960968, 0.9750915765762329, and 0.9534710049629211\n",
      "Epoch [468/2000], Train Loss: 0.9769, Test Loss: 0.9732\n",
      "The metrics are: 0.9948448141415914, 0.9688032269477844, and 0.9417003194491068\n",
      "Epoch [469/2000], Train Loss: 0.9716, Test Loss: 0.9657\n",
      "The metrics are: 0.9927260677019755, 0.9582261244455973, and 0.9221069614092509\n",
      "Epoch [470/2000], Train Loss: 0.9624, Test Loss: 0.9525\n",
      "The metrics are: 0.987949788570404, 0.9374162554740906, and 0.8865285714467367\n",
      "Epoch [471/2000], Train Loss: 0.9462, Test Loss: 0.9247\n",
      "The metrics are: 0.9728161096572876, 0.8942703207333883, and 0.8373696406682333\n",
      "Epoch [472/2000], Train Loss: 0.9112, Test Loss: 0.8758\n",
      "The metrics are: 0.9491493900616964, 0.8421400586764017, and 0.7774895429611206\n",
      "Epoch [473/2000], Train Loss: 0.8600, Test Loss: 0.8210\n",
      "The metrics are: 0.917780856291453, 0.7850098411242167, and 0.7207673986752828\n",
      "Epoch [474/2000], Train Loss: 0.8061, Test Loss: 0.7637\n",
      "The metrics are: 0.8788358569145203, 0.7267828981081644, and 0.6696986158688863\n",
      "Epoch [475/2000], Train Loss: 0.7493, Test Loss: 0.7095\n",
      "The metrics are: 0.8365538716316223, 0.6771353681882223, and 0.632117748260498\n",
      "Epoch [476/2000], Train Loss: 0.6948, Test Loss: 0.6675\n",
      "The metrics are: 0.7640904386838278, 0.6258991758028666, and 0.5726930697758993\n",
      "Epoch [477/2000], Train Loss: 0.6511, Test Loss: 0.5838\n",
      "The metrics are: 0.5980708996454874, 0.4644884467124939, and 0.4462483028570811\n",
      "Epoch [478/2000], Train Loss: 0.5336, Test Loss: 0.4548\n",
      "The metrics are: 0.6305468678474426, 0.3608573377132416, and 0.366614709297816\n",
      "Epoch [479/2000], Train Loss: 0.4072, Test Loss: 0.3892\n",
      "The metrics are: 0.6167671283086141, 0.3023349344730377, and 0.3067399362723033\n",
      "Epoch [480/2000], Train Loss: 0.3572, Test Loss: 0.3125\n",
      "The metrics are: 0.5459282795588175, 0.26260994871457416, and 0.27574090162913006\n",
      "Epoch [481/2000], Train Loss: 0.3010, Test Loss: 0.2849\n",
      "The metrics are: 0.49062352379163104, 0.2342155526081721, and 0.24961894750595093\n",
      "Epoch [482/2000], Train Loss: 0.2744, Test Loss: 0.2578\n",
      "The metrics are: 0.4447389344374339, 0.2123789538939794, and 0.22738995651404062\n",
      "Epoch [483/2000], Train Loss: 0.2519, Test Loss: 0.2335\n",
      "The metrics are: 0.3964482247829437, 0.19366043309370676, and 0.20958635210990906\n",
      "Epoch [484/2000], Train Loss: 0.2303, Test Loss: 0.2143\n",
      "The metrics are: 0.3576727608839671, 0.177713672320048, and 0.19308308760325113\n",
      "Epoch [485/2000], Train Loss: 0.2105, Test Loss: 0.1959\n",
      "The metrics are: 0.3336702585220337, 0.16412719090779623, and 0.17863173286120096\n",
      "Epoch [486/2000], Train Loss: 0.1912, Test Loss: 0.1805\n",
      "The metrics are: 0.30160627762476605, 0.1512159804503123, and 0.16512824594974518\n",
      "Epoch [487/2000], Train Loss: 0.1784, Test Loss: 0.1644\n",
      "The metrics are: 0.28042744596799213, 0.14022455116113028, and 0.1536937008301417\n",
      "Epoch [488/2000], Train Loss: 0.1631, Test Loss: 0.1519\n",
      "The metrics are: 0.2621539731820424, 0.12968046218156815, and 0.14247089127699533\n",
      "Epoch [489/2000], Train Loss: 0.1497, Test Loss: 0.1386\n",
      "The metrics are: 0.24087046086788177, 0.11990679800510406, and 0.1325706640879313\n",
      "Epoch [490/2000], Train Loss: 0.1378, Test Loss: 0.1266\n",
      "The metrics are: 0.22067533930142721, 0.11078934371471405, and 0.12353199223677318\n",
      "Epoch [491/2000], Train Loss: 0.1258, Test Loss: 0.1153\n",
      "The metrics are: 0.2067631334066391, 0.1026873563726743, and 0.11573276420434316\n",
      "Epoch [492/2000], Train Loss: 0.1158, Test Loss: 0.1065\n",
      "The metrics are: 0.19362646341323853, 0.09526746720075607, and 0.10797601689894994\n",
      "Epoch [493/2000], Train Loss: 0.1074, Test Loss: 0.0975\n",
      "The metrics are: 0.18106074631214142, 0.0884929969906807, and 0.10154059280951817\n",
      "Epoch [494/2000], Train Loss: 0.0993, Test Loss: 0.0897\n",
      "The metrics are: 0.1710179845492045, 0.08247313400109609, and 0.09561140835285187\n",
      "Epoch [495/2000], Train Loss: 0.0915, Test Loss: 0.0828\n",
      "The metrics are: 0.16310007870197296, 0.07693664729595184, and 0.09013936420281728\n",
      "Epoch [496/2000], Train Loss: 0.0845, Test Loss: 0.0767\n",
      "The metrics are: 0.15518751243750253, 0.07161540538072586, and 0.08468015243609746\n",
      "Epoch [497/2000], Train Loss: 0.0787, Test Loss: 0.0705\n",
      "The metrics are: 0.14955973128477731, 0.0665813038746516, and 0.08037499090035756\n",
      "Epoch [498/2000], Train Loss: 0.0728, Test Loss: 0.0654\n",
      "The metrics are: 0.1434834102789561, 0.061824411153793335, and 0.07544439782698949\n",
      "Epoch [499/2000], Train Loss: 0.0670, Test Loss: 0.0601\n",
      "The metrics are: 0.13960580031077066, 0.05727465823292732, and 0.07148779183626175\n",
      "Epoch [500/2000], Train Loss: 0.0632, Test Loss: 0.0560\n",
      "The metrics are: 0.1363251805305481, 0.05348339552680651, and 0.06752423942089081\n",
      "Epoch [501/2000], Train Loss: 0.0580, Test Loss: 0.0529\n",
      "The metrics are: 0.13599707186222076, 0.05056307837367058, and 0.06478588158885638\n",
      "Epoch [502/2000], Train Loss: 0.0551, Test Loss: 0.0514\n",
      "The metrics are: 0.1368493288755417, 0.04861705501874288, and 0.06261260434985161\n",
      "Epoch [503/2000], Train Loss: 0.0536, Test Loss: 0.0511\n",
      "The metrics are: 0.1380299081405004, 0.04701943571368853, and 0.06020506098866463\n",
      "Epoch [504/2000], Train Loss: 0.0515, Test Loss: 0.0507\n",
      "The metrics are: 0.1397334635257721, 0.04553427423040072, and 0.058889105916023254\n",
      "Epoch [505/2000], Train Loss: 0.0512, Test Loss: 0.0509\n",
      "The metrics are: 0.14221655825773874, 0.04444852098822594, and 0.05728574345509211\n",
      "Epoch [506/2000], Train Loss: 0.0510, Test Loss: 0.0511\n",
      "The metrics are: 0.144803653160731, 0.04340551421046257, and 0.05596957976619402\n",
      "Epoch [507/2000], Train Loss: 0.0509, Test Loss: 0.0513\n",
      "The metrics are: 0.1463490923245748, 0.0424090214073658, and 0.05397808055082957\n",
      "Epoch [508/2000], Train Loss: 0.0515, Test Loss: 0.0501\n",
      "The metrics are: 0.14691029489040375, 0.04132820541659991, and 0.0530619149406751\n",
      "Epoch [509/2000], Train Loss: 0.0505, Test Loss: 0.0498\n",
      "The metrics are: 0.14605486392974854, 0.04014567161599795, and 0.05130173886815707\n",
      "Epoch [510/2000], Train Loss: 0.0498, Test Loss: 0.0477\n",
      "The metrics are: 0.14403371016184488, 0.03888895114262899, and 0.05012631043791771\n",
      "Epoch [511/2000], Train Loss: 0.0489, Test Loss: 0.0461\n",
      "The metrics are: 0.14301306009292603, 0.038083095103502274, and 0.048927893241246544\n",
      "Epoch [512/2000], Train Loss: 0.0471, Test Loss: 0.0450\n",
      "The metrics are: 0.13970206181208292, 0.036918806533018746, and 0.0473481814066569\n",
      "Epoch [513/2000], Train Loss: 0.0453, Test Loss: 0.0428\n",
      "The metrics are: 0.13834831615289053, 0.03601669271787008, and 0.046637844294309616\n",
      "Epoch [514/2000], Train Loss: 0.0438, Test Loss: 0.0419\n",
      "The metrics are: 0.13674152145783106, 0.03530095765988032, and 0.04563235988219579\n",
      "Epoch [515/2000], Train Loss: 0.0426, Test Loss: 0.0409\n",
      "The metrics are: 0.13552197813987732, 0.03447821425894896, and 0.044590067118406296\n",
      "Epoch [516/2000], Train Loss: 0.0423, Test Loss: 0.0398\n",
      "The metrics are: 0.1353020817041397, 0.033958740532398224, and 0.04366607094804446\n",
      "Epoch [517/2000], Train Loss: 0.0406, Test Loss: 0.0393\n",
      "The metrics are: 0.1342261160413424, 0.033252072830994926, and 0.04290053993463516\n",
      "Epoch [518/2000], Train Loss: 0.0405, Test Loss: 0.0386\n",
      "The metrics are: 0.1341644749045372, 0.03274864082535108, and 0.042414688815673195\n",
      "Epoch [519/2000], Train Loss: 0.0395, Test Loss: 0.0385\n",
      "The metrics are: 0.13351004074017206, 0.03230656869709492, and 0.041424866765737534\n",
      "Epoch [520/2000], Train Loss: 0.0394, Test Loss: 0.0378\n",
      "The metrics are: 0.1336818610628446, 0.031757356598973274, and 0.040891471008459725\n",
      "Epoch [521/2000], Train Loss: 0.0388, Test Loss: 0.0376\n",
      "The metrics are: 0.13412137577931085, 0.031405385583639145, and 0.04050268356998762\n",
      "Epoch [522/2000], Train Loss: 0.0385, Test Loss: 0.0376\n",
      "The metrics are: 0.13318880399068198, 0.030949097126722336, and 0.03944821779926618\n",
      "Epoch [523/2000], Train Loss: 0.0384, Test Loss: 0.0367\n",
      "The metrics are: 0.13212141891320547, 0.030320164437095325, and 0.03897063061594963\n",
      "Epoch [524/2000], Train Loss: 0.0375, Test Loss: 0.0359\n",
      "The metrics are: 0.1311753143866857, 0.029996878157059353, and 0.03829775874813398\n",
      "Epoch [525/2000], Train Loss: 0.0369, Test Loss: 0.0354\n",
      "The metrics are: 0.13022095213333765, 0.029474375148614246, and 0.03781100052098433\n",
      "Epoch [526/2000], Train Loss: 0.0361, Test Loss: 0.0350\n",
      "The metrics are: 0.1303126315275828, 0.02929919088880221, and 0.037676615019639335\n",
      "Epoch [527/2000], Train Loss: 0.0360, Test Loss: 0.0353\n",
      "The metrics are: 0.12941535313924155, 0.028884931777914364, and 0.036645193273822464\n",
      "Epoch [528/2000], Train Loss: 0.0361, Test Loss: 0.0343\n",
      "The metrics are: 0.1284598931670189, 0.028442078580458958, and 0.03613385992745558\n",
      "Epoch [529/2000], Train Loss: 0.0348, Test Loss: 0.0337\n",
      "The metrics are: 0.1279547686378161, 0.028082558264334995, and 0.03576741926372051\n",
      "Epoch [530/2000], Train Loss: 0.0348, Test Loss: 0.0335\n",
      "The metrics are: 0.12746664136648178, 0.027774177491664886, and 0.03538543048004309\n",
      "Epoch [531/2000], Train Loss: 0.0338, Test Loss: 0.0333\n",
      "The metrics are: 0.12871777762969336, 0.02771284741659959, and 0.03537291722993056\n",
      "Epoch [532/2000], Train Loss: 0.0339, Test Loss: 0.0340\n",
      "The metrics are: 0.1278319110472997, 0.027333964904149372, and 0.03446144921084245\n",
      "Epoch [533/2000], Train Loss: 0.0343, Test Loss: 0.0330\n",
      "The metrics are: 0.12758819013834, 0.027053728078802425, and 0.03423604120810827\n",
      "Epoch [534/2000], Train Loss: 0.0343, Test Loss: 0.0329\n",
      "The metrics are: 0.12619720151027045, 0.026760753865043323, and 0.03356816495458285\n",
      "Epoch [535/2000], Train Loss: 0.0336, Test Loss: 0.0322\n",
      "The metrics are: 0.12653379638989767, 0.026481693610548973, and 0.03352116234600544\n",
      "Epoch [536/2000], Train Loss: 0.0332, Test Loss: 0.0322\n",
      "The metrics are: 0.12687940647204718, 0.026416504755616188, and 0.033350083976984024\n",
      "Epoch [537/2000], Train Loss: 0.0328, Test Loss: 0.0326\n",
      "The metrics are: 0.12554082522789636, 0.025992852325240772, and 0.0325839693347613\n",
      "Epoch [538/2000], Train Loss: 0.0331, Test Loss: 0.0316\n",
      "The metrics are: 0.12497775256633759, 0.025761382033427555, and 0.03249805110196272\n",
      "Epoch [539/2000], Train Loss: 0.0323, Test Loss: 0.0315\n",
      "The metrics are: 0.12379300594329834, 0.02550889365375042, and 0.031942360724012055\n",
      "Epoch [540/2000], Train Loss: 0.0322, Test Loss: 0.0309\n",
      "The metrics are: 0.12332019458214442, 0.025244762500127155, and 0.0318109088887771\n",
      "Epoch [541/2000], Train Loss: 0.0322, Test Loss: 0.0309\n",
      "The metrics are: 0.12261094897985458, 0.02505208117266496, and 0.031340498477220535\n",
      "Epoch [542/2000], Train Loss: 0.0315, Test Loss: 0.0304\n",
      "The metrics are: 0.1230522816379865, 0.024903707206249237, and 0.03129540073374907\n",
      "Epoch [543/2000], Train Loss: 0.0312, Test Loss: 0.0307\n",
      "The metrics are: 0.12221064915259679, 0.02468147749702136, and 0.03076635052760442\n",
      "Epoch [544/2000], Train Loss: 0.0312, Test Loss: 0.0301\n",
      "The metrics are: 0.1218482106924057, 0.024428497379024822, and 0.03057108384867509\n",
      "Epoch [545/2000], Train Loss: 0.0310, Test Loss: 0.0300\n",
      "The metrics are: 0.1220767895380656, 0.02436850219964981, and 0.030328797176480293\n",
      "Epoch [546/2000], Train Loss: 0.0306, Test Loss: 0.0301\n",
      "The metrics are: 0.12066784997781117, 0.02406196730832259, and 0.02987228271861871\n",
      "Epoch [547/2000], Train Loss: 0.0305, Test Loss: 0.0295\n",
      "The metrics are: 0.12087734043598175, 0.023885565499464672, and 0.029951024800539017\n",
      "Epoch [548/2000], Train Loss: 0.0293, Test Loss: 0.0297\n",
      "The metrics are: 0.120496799548467, 0.023791364083687466, and 0.029637389505902927\n",
      "Epoch [549/2000], Train Loss: 0.0305, Test Loss: 0.0296\n",
      "The metrics are: 0.11992766956488292, 0.02358716105421384, and 0.02937459635237853\n",
      "Epoch [550/2000], Train Loss: 0.0296, Test Loss: 0.0295\n",
      "The metrics are: 0.1199338436126709, 0.023413873588045437, and 0.029220422729849815\n",
      "Epoch [551/2000], Train Loss: 0.0300, Test Loss: 0.0294\n",
      "The metrics are: 0.11909588674704234, 0.023209167644381523, and 0.02878422476351261\n",
      "Epoch [552/2000], Train Loss: 0.0302, Test Loss: 0.0290\n",
      "The metrics are: 0.11820956319570541, 0.022969369466106098, and 0.028578974927465122\n",
      "Epoch [553/2000], Train Loss: 0.0298, Test Loss: 0.0286\n",
      "The metrics are: 0.11815011501312256, 0.022873833775520325, and 0.028476467356085777\n",
      "Epoch [554/2000], Train Loss: 0.0286, Test Loss: 0.0288\n",
      "The metrics are: 0.11756531149148941, 0.022763875002662342, and 0.028251803169647854\n",
      "Epoch [555/2000], Train Loss: 0.0286, Test Loss: 0.0286\n",
      "The metrics are: 0.1169297347466151, 0.02251337592800458, and 0.02792055221895377\n",
      "Epoch [556/2000], Train Loss: 0.0289, Test Loss: 0.0283\n",
      "The metrics are: 0.11672927190860112, 0.022408348818620045, and 0.027928161745270092\n",
      "Epoch [557/2000], Train Loss: 0.0287, Test Loss: 0.0284\n",
      "The metrics are: 0.1161663184563319, 0.02225357045729955, and 0.02763206511735916\n",
      "Epoch [558/2000], Train Loss: 0.0288, Test Loss: 0.0282\n",
      "The metrics are: 0.11500279357035954, 0.021978455906112988, and 0.02730076697965463\n",
      "Epoch [559/2000], Train Loss: 0.0286, Test Loss: 0.0276\n",
      "The metrics are: 0.11456256608168285, 0.02182970568537712, and 0.027195860321323078\n",
      "Epoch [560/2000], Train Loss: 0.0276, Test Loss: 0.0276\n",
      "The metrics are: 0.11467488358418147, 0.021793507039546967, and 0.027196370686093967\n",
      "Epoch [561/2000], Train Loss: 0.0280, Test Loss: 0.0279\n",
      "The metrics are: 0.1142048289378484, 0.02165111154317856, and 0.026817220573623974\n",
      "Epoch [562/2000], Train Loss: 0.0281, Test Loss: 0.0277\n",
      "The metrics are: 0.11354148884614308, 0.021424478540817898, and 0.02674906390408675\n",
      "Epoch [563/2000], Train Loss: 0.0278, Test Loss: 0.0275\n",
      "The metrics are: 0.11480405926704407, 0.021509970848759014, and 0.026861701160669327\n",
      "Epoch [564/2000], Train Loss: 0.0276, Test Loss: 0.0283\n",
      "The metrics are: 0.11488677809635799, 0.021421557292342186, and 0.026591528827945392\n",
      "Epoch [565/2000], Train Loss: 0.0283, Test Loss: 0.0283\n",
      "The metrics are: 0.11417979747056961, 0.021291781837741535, and 0.026411990945537884\n",
      "Epoch [566/2000], Train Loss: 0.0284, Test Loss: 0.0281\n",
      "The metrics are: 0.11245144158601761, 0.02092025491098563, and 0.02592024641732375\n",
      "Epoch [567/2000], Train Loss: 0.0283, Test Loss: 0.0271\n",
      "The metrics are: 0.11186147232850392, 0.0207582072665294, and 0.02591590831677119\n",
      "Epoch [568/2000], Train Loss: 0.0275, Test Loss: 0.0271\n",
      "The metrics are: 0.11200755089521408, 0.020740669841567676, and 0.02591802490254243\n",
      "Epoch [569/2000], Train Loss: 0.0276, Test Loss: 0.0273\n",
      "The metrics are: 0.11209593961636226, 0.020697633425394695, and 0.025829126437505085\n",
      "Epoch [570/2000], Train Loss: 0.0278, Test Loss: 0.0276\n",
      "The metrics are: 0.11133020867904027, 0.020457095156113308, and 0.025523942584792774\n",
      "Epoch [571/2000], Train Loss: 0.0277, Test Loss: 0.0271\n",
      "The metrics are: 0.11095942556858063, 0.02039795182645321, and 0.025500612954298656\n",
      "Epoch [572/2000], Train Loss: 0.0275, Test Loss: 0.0273\n",
      "The metrics are: 0.10957414905230205, 0.020095907151699066, and 0.025206441680590313\n",
      "Epoch [573/2000], Train Loss: 0.0272, Test Loss: 0.0267\n",
      "The metrics are: 0.10887518028418224, 0.019936489562193554, and 0.025027549515167873\n",
      "Epoch [574/2000], Train Loss: 0.0266, Test Loss: 0.0264\n",
      "The metrics are: 0.1077489232023557, 0.019738363102078438, and 0.024780886868635815\n",
      "Epoch [575/2000], Train Loss: 0.0264, Test Loss: 0.0259\n",
      "The metrics are: 0.10686208804448445, 0.019541633625825245, and 0.02460523198048274\n",
      "Epoch [576/2000], Train Loss: 0.0261, Test Loss: 0.0257\n",
      "The metrics are: 0.10631074756383896, 0.019484602535764377, and 0.02470606875916322\n",
      "Epoch [577/2000], Train Loss: 0.0256, Test Loss: 0.0261\n",
      "The metrics are: 0.1065051903327306, 0.01938512735068798, and 0.024597730487585068\n",
      "Epoch [578/2000], Train Loss: 0.0263, Test Loss: 0.0261\n",
      "The metrics are: 0.10600791126489639, 0.01922609532872836, and 0.02432570606470108\n",
      "Epoch [579/2000], Train Loss: 0.0264, Test Loss: 0.0259\n",
      "The metrics are: 0.105101078748703, 0.019071225076913834, and 0.024198974172274273\n",
      "Epoch [580/2000], Train Loss: 0.0262, Test Loss: 0.0257\n",
      "The metrics are: 0.10383468121290207, 0.018810703108708065, and 0.024011386558413506\n",
      "Epoch [581/2000], Train Loss: 0.0258, Test Loss: 0.0253\n",
      "The metrics are: 0.10331203043460846, 0.018647552157441776, and 0.02388782302538554\n",
      "Epoch [582/2000], Train Loss: 0.0259, Test Loss: 0.0251\n",
      "The metrics are: 0.1034710481762886, 0.018640296533703804, and 0.023826733231544495\n",
      "Epoch [583/2000], Train Loss: 0.0258, Test Loss: 0.0254\n",
      "The metrics are: 0.10268601278464, 0.018477020785212517, and 0.023686350633700688\n",
      "Epoch [584/2000], Train Loss: 0.0261, Test Loss: 0.0253\n",
      "The metrics are: 0.10108496248722076, 0.0182198869685332, and 0.023418569316466648\n",
      "Epoch [585/2000], Train Loss: 0.0254, Test Loss: 0.0247\n",
      "The metrics are: 0.10033209373553593, 0.018051764617363613, and 0.023345242564876873\n",
      "Epoch [586/2000], Train Loss: 0.0252, Test Loss: 0.0245\n",
      "The metrics are: 0.10033274441957474, 0.018074151128530502, and 0.02348885623117288\n",
      "Epoch [587/2000], Train Loss: 0.0247, Test Loss: 0.0250\n",
      "The metrics are: 0.10133365293343861, 0.018085379153490067, and 0.02346978212396304\n",
      "Epoch [588/2000], Train Loss: 0.0248, Test Loss: 0.0255\n",
      "The metrics are: 0.10161468635002772, 0.018065357580780983, and 0.023414460942149162\n",
      "Epoch [589/2000], Train Loss: 0.0259, Test Loss: 0.0258\n",
      "The metrics are: 0.10023371875286102, 0.017705772072076797, and 0.022948462516069412\n",
      "Epoch [590/2000], Train Loss: 0.0256, Test Loss: 0.0249\n",
      "The metrics are: 0.09938509513934453, 0.01758435865243276, and 0.022899872312943142\n",
      "Epoch [591/2000], Train Loss: 0.0249, Test Loss: 0.0247\n",
      "The metrics are: 0.09754953036705653, 0.017311508456865948, and 0.022694331283370655\n",
      "Epoch [592/2000], Train Loss: 0.0248, Test Loss: 0.0242\n",
      "The metrics are: 0.09634951253732045, 0.017118744552135468, and 0.022574707865715027\n",
      "Epoch [593/2000], Train Loss: 0.0242, Test Loss: 0.0238\n",
      "The metrics are: 0.09576595077912013, 0.017046496582527954, and 0.02251162255803744\n",
      "Epoch [594/2000], Train Loss: 0.0238, Test Loss: 0.0239\n",
      "The metrics are: 0.0955346350868543, 0.016910742036998272, and 0.022437231615185738\n",
      "Epoch [595/2000], Train Loss: 0.0239, Test Loss: 0.0239\n",
      "The metrics are: 0.09625473618507385, 0.01693487943460544, and 0.02252529188990593\n",
      "Epoch [596/2000], Train Loss: 0.0242, Test Loss: 0.0244\n",
      "The metrics are: 0.09473241120576859, 0.016698686716457207, and 0.022146230563521385\n",
      "Epoch [597/2000], Train Loss: 0.0242, Test Loss: 0.0237\n",
      "The metrics are: 0.09322308997313182, 0.016428066417574883, and 0.02195392611126105\n",
      "Epoch [598/2000], Train Loss: 0.0239, Test Loss: 0.0231\n",
      "The metrics are: 0.09358864277601242, 0.016481046254436176, and 0.022090774029493332\n",
      "Epoch [599/2000], Train Loss: 0.0237, Test Loss: 0.0237\n",
      "The metrics are: 0.09288803736368816, 0.016346036766966183, and 0.02197950581709544\n",
      "Epoch [600/2000], Train Loss: 0.0239, Test Loss: 0.0237\n",
      "The metrics are: 0.09289000431696574, 0.01622601505368948, and 0.021846857542792957\n",
      "Epoch [601/2000], Train Loss: 0.0236, Test Loss: 0.0236\n",
      "The metrics are: 0.0908321167031924, 0.01603555865585804, and 0.021710167949398358\n",
      "Epoch [602/2000], Train Loss: 0.0235, Test Loss: 0.0231\n",
      "The metrics are: 0.09142011404037476, 0.015928789662818115, and 0.021645227447152138\n",
      "Epoch [603/2000], Train Loss: 0.0234, Test Loss: 0.0232\n",
      "The metrics are: 0.08996545523405075, 0.015774807582298916, and 0.021540351832906406\n",
      "Epoch [604/2000], Train Loss: 0.0232, Test Loss: 0.0230\n",
      "The metrics are: 0.08964589983224869, 0.015709772085150082, and 0.021503932153185207\n",
      "Epoch [605/2000], Train Loss: 0.0229, Test Loss: 0.0231\n",
      "The metrics are: 0.08954345683256786, 0.015570158759752909, and 0.021379262829820316\n",
      "Epoch [606/2000], Train Loss: 0.0231, Test Loss: 0.0229\n",
      "The metrics are: 0.08838456869125366, 0.015453452865282694, and 0.021193724125623703\n",
      "Epoch [607/2000], Train Loss: 0.0226, Test Loss: 0.0227\n",
      "The metrics are: 0.08853469540675481, 0.015409621720512709, and 0.02128150872886181\n",
      "Epoch [608/2000], Train Loss: 0.0227, Test Loss: 0.0229\n",
      "The metrics are: 0.08810203522443771, 0.015313178300857544, and 0.02109961211681366\n",
      "Epoch [609/2000], Train Loss: 0.0226, Test Loss: 0.0229\n",
      "The metrics are: 0.0880791296561559, 0.0151963389168183, and 0.021031117687622707\n",
      "Epoch [610/2000], Train Loss: 0.0228, Test Loss: 0.0228\n",
      "The metrics are: 0.08676176269849141, 0.014933240289489428, and 0.0207026448721687\n",
      "Epoch [611/2000], Train Loss: 0.0225, Test Loss: 0.0220\n",
      "The metrics are: 0.08613379051287968, 0.014983240514993668, and 0.020875164307653904\n",
      "Epoch [612/2000], Train Loss: 0.0222, Test Loss: 0.0225\n",
      "The metrics are: 0.08530774712562561, 0.01471195990840594, and 0.020590273663401604\n",
      "Epoch [613/2000], Train Loss: 0.0225, Test Loss: 0.0218\n",
      "The metrics are: 0.08504958202441533, 0.01469395961612463, and 0.020618668136497337\n",
      "Epoch [614/2000], Train Loss: 0.0220, Test Loss: 0.0220\n",
      "The metrics are: 0.08419997493426006, 0.014589006081223488, and 0.0205083725353082\n",
      "Epoch [615/2000], Train Loss: 0.0221, Test Loss: 0.0219\n",
      "The metrics are: 0.08294300734996796, 0.01438918492446343, and 0.020290403937300045\n",
      "Epoch [616/2000], Train Loss: 0.0218, Test Loss: 0.0214\n",
      "The metrics are: 0.08243640512228012, 0.014296629466116428, and 0.02026329779376586\n",
      "Epoch [617/2000], Train Loss: 0.0213, Test Loss: 0.0214\n",
      "The metrics are: 0.08168498923381169, 0.014190968126058578, and 0.020187544636428356\n",
      "Epoch [618/2000], Train Loss: 0.0208, Test Loss: 0.0213\n",
      "The metrics are: 0.08246390024820964, 0.014250683598220348, and 0.02032652993996938\n",
      "Epoch [619/2000], Train Loss: 0.0211, Test Loss: 0.0217\n",
      "The metrics are: 0.083063838382562, 0.01426671165972948, and 0.020292476750910282\n",
      "Epoch [620/2000], Train Loss: 0.0215, Test Loss: 0.0221\n",
      "The metrics are: 0.08359694232543309, 0.014230391010642052, and 0.020210125173131626\n",
      "Epoch [621/2000], Train Loss: 0.0220, Test Loss: 0.0223\n",
      "The metrics are: 0.08329533040523529, 0.014130541744331518, and 0.02010146590570609\n",
      "Epoch [622/2000], Train Loss: 0.0222, Test Loss: 0.0221\n",
      "The metrics are: 0.08186673124631245, 0.013964475132524967, and 0.01991839489589135\n",
      "Epoch [623/2000], Train Loss: 0.0220, Test Loss: 0.0217\n",
      "The metrics are: 0.0819375067949295, 0.014022118411958218, and 0.019999800249934196\n",
      "Epoch [624/2000], Train Loss: 0.0216, Test Loss: 0.0221\n",
      "The metrics are: 0.08276551465193431, 0.014021162564555803, and 0.020034111104905605\n",
      "Epoch [625/2000], Train Loss: 0.0220, Test Loss: 0.0223\n",
      "The metrics are: 0.08039985100428264, 0.013714663684368134, and 0.01966524093101422\n",
      "Epoch [626/2000], Train Loss: 0.0216, Test Loss: 0.0213\n",
      "The metrics are: 0.07975303133328755, 0.013630276545882225, and 0.019613403206070263\n",
      "Epoch [627/2000], Train Loss: 0.0213, Test Loss: 0.0212\n",
      "The metrics are: 0.08090666681528091, 0.013765856934090456, and 0.019773481724162895\n",
      "Epoch [628/2000], Train Loss: 0.0210, Test Loss: 0.0220\n",
      "The metrics are: 0.08130446821451187, 0.01377115398645401, and 0.019779762874046963\n",
      "Epoch [629/2000], Train Loss: 0.0219, Test Loss: 0.0222\n",
      "The metrics are: 0.08081352959076564, 0.013620112712184588, and 0.01956344364831845\n",
      "Epoch [630/2000], Train Loss: 0.0221, Test Loss: 0.0218\n",
      "The metrics are: 0.07843517015377681, 0.013339769095182419, and 0.01926275435835123\n",
      "Epoch [631/2000], Train Loss: 0.0211, Test Loss: 0.0209\n",
      "The metrics are: 0.07905208319425583, 0.013356322422623634, and 0.019361489141980808\n",
      "Epoch [632/2000], Train Loss: 0.0207, Test Loss: 0.0212\n",
      "The metrics are: 0.07807573179403941, 0.013259608608980974, and 0.019252948462963104\n",
      "Epoch [633/2000], Train Loss: 0.0209, Test Loss: 0.0210\n",
      "The metrics are: 0.07811298469702403, 0.013229803803066412, and 0.019235421903431416\n",
      "Epoch [634/2000], Train Loss: 0.0208, Test Loss: 0.0211\n",
      "The metrics are: 0.07703022410472234, 0.013044698163866997, and 0.019026441189150017\n",
      "Epoch [635/2000], Train Loss: 0.0208, Test Loss: 0.0205\n",
      "The metrics are: 0.07607227563858032, 0.012910173274576664, and 0.01886780249575774\n",
      "Epoch [636/2000], Train Loss: 0.0203, Test Loss: 0.0202\n",
      "The metrics are: 0.07519797484079997, 0.012864790856838226, and 0.018839843571186066\n",
      "Epoch [637/2000], Train Loss: 0.0203, Test Loss: 0.0201\n",
      "The metrics are: 0.07587001224358876, 0.012831906788051128, and 0.018815988364319008\n",
      "Epoch [638/2000], Train Loss: 0.0201, Test Loss: 0.0203\n",
      "The metrics are: 0.07647023101647694, 0.012930255693693956, and 0.01891552284359932\n",
      "Epoch [639/2000], Train Loss: 0.0204, Test Loss: 0.0207\n",
      "The metrics are: 0.07630372792482376, 0.012900706380605698, and 0.01883598417043686\n",
      "Epoch [640/2000], Train Loss: 0.0202, Test Loss: 0.0209\n",
      "The metrics are: 0.07635846982399623, 0.012834716588258743, and 0.01875985786318779\n",
      "Epoch [641/2000], Train Loss: 0.0204, Test Loss: 0.0208\n",
      "The metrics are: 0.07617942740519841, 0.01282712041089932, and 0.018750878050923347\n",
      "Epoch [642/2000], Train Loss: 0.0211, Test Loss: 0.0210\n",
      "The metrics are: 0.07671285420656204, 0.013076167243222395, and 0.01895993109792471\n",
      "Epoch [643/2000], Train Loss: 0.0203, Test Loss: 0.0217\n",
      "The metrics are: 0.0771167774995168, 0.012744180237253508, and 0.018592507888873417\n",
      "Epoch [644/2000], Train Loss: 0.0212, Test Loss: 0.0211\n",
      "The metrics are: 0.07533057779073715, 0.012605747828880945, and 0.018519931472837925\n",
      "Epoch [645/2000], Train Loss: 0.0210, Test Loss: 0.0205\n",
      "The metrics are: 0.07385769486427307, 0.012453543022274971, and 0.018318678873280685\n",
      "Epoch [646/2000], Train Loss: 0.0202, Test Loss: 0.0201\n",
      "The metrics are: 0.07363610217968623, 0.012414054324229559, and 0.01831846497952938\n",
      "Epoch [647/2000], Train Loss: 0.0198, Test Loss: 0.0201\n",
      "The metrics are: 0.07411136105656624, 0.012467370058099428, and 0.01834250707179308\n",
      "Epoch [648/2000], Train Loss: 0.0199, Test Loss: 0.0205\n",
      "The metrics are: 0.07505271087090175, 0.012580055433015028, and 0.01844378188252449\n",
      "Epoch [649/2000], Train Loss: 0.0202, Test Loss: 0.0210\n",
      "The metrics are: 0.07414755721886952, 0.01236833973477284, and 0.01820655105014642\n",
      "Epoch [650/2000], Train Loss: 0.0205, Test Loss: 0.0204\n",
      "The metrics are: 0.07428202778100967, 0.012407490673164526, and 0.018237652567525704\n",
      "Epoch [651/2000], Train Loss: 0.0204, Test Loss: 0.0207\n",
      "The metrics are: 0.07274961347381274, 0.012128142639994621, and 0.017915005795657635\n",
      "Epoch [652/2000], Train Loss: 0.0201, Test Loss: 0.0198\n",
      "The metrics are: 0.07218071942528088, 0.012165413238108158, and 0.017974404928584892\n",
      "Epoch [653/2000], Train Loss: 0.0195, Test Loss: 0.0200\n",
      "The metrics are: 0.07054706662893295, 0.011896816703180471, and 0.017696579918265343\n",
      "Epoch [654/2000], Train Loss: 0.0193, Test Loss: 0.0191\n",
      "The metrics are: 0.07038791477680206, 0.012006272251407305, and 0.01781342861553033\n",
      "Epoch [655/2000], Train Loss: 0.0191, Test Loss: 0.0196\n",
      "The metrics are: 0.07132673884431522, 0.011972002374629179, and 0.017799837204317253\n",
      "Epoch [656/2000], Train Loss: 0.0195, Test Loss: 0.0198\n",
      "The metrics are: 0.07285211607813835, 0.012108661234378815, and 0.017956388803819816\n",
      "Epoch [657/2000], Train Loss: 0.0199, Test Loss: 0.0205\n",
      "The metrics are: 0.07225225369135539, 0.01211583831657966, and 0.017854233272373676\n",
      "Epoch [658/2000], Train Loss: 0.0201, Test Loss: 0.0205\n",
      "The metrics are: 0.07242636879285176, 0.01206748994688193, and 0.01782485656440258\n",
      "Epoch [659/2000], Train Loss: 0.0200, Test Loss: 0.0205\n",
      "The metrics are: 0.0714532695710659, 0.011872057492534319, and 0.017624027095735073\n",
      "Epoch [660/2000], Train Loss: 0.0201, Test Loss: 0.0200\n",
      "The metrics are: 0.07067368427912395, 0.011827145703136921, and 0.017585172938803833\n",
      "Epoch [661/2000], Train Loss: 0.0198, Test Loss: 0.0199\n",
      "The metrics are: 0.07133764525254567, 0.011928941744069258, and 0.01765966818978389\n",
      "Epoch [662/2000], Train Loss: 0.0197, Test Loss: 0.0204\n",
      "The metrics are: 0.07131543507178624, 0.011853955065210661, and 0.01759729441255331\n",
      "Epoch [663/2000], Train Loss: 0.0200, Test Loss: 0.0202\n",
      "The metrics are: 0.07074103131890297, 0.01166886060188214, and 0.017357582847277325\n",
      "Epoch [664/2000], Train Loss: 0.0198, Test Loss: 0.0197\n",
      "The metrics are: 0.06933920706311862, 0.011543463294704756, and 0.01724025420844555\n",
      "Epoch [665/2000], Train Loss: 0.0195, Test Loss: 0.0193\n",
      "The metrics are: 0.06937110424041748, 0.011623262738188108, and 0.017314983221391838\n",
      "Epoch [666/2000], Train Loss: 0.0189, Test Loss: 0.0197\n",
      "The metrics are: 0.06884689629077911, 0.011450500848392645, and 0.0171671857436498\n",
      "Epoch [667/2000], Train Loss: 0.0190, Test Loss: 0.0192\n",
      "The metrics are: 0.0694659228126208, 0.011547629721462727, and 0.017257612198591232\n",
      "Epoch [668/2000], Train Loss: 0.0191, Test Loss: 0.0197\n",
      "The metrics are: 0.06952797497312228, 0.011635883090396723, and 0.017292868656416733\n",
      "Epoch [669/2000], Train Loss: 0.0194, Test Loss: 0.0201\n",
      "The metrics are: 0.06917387122909228, 0.011406307419141134, and 0.017059287056326866\n",
      "Epoch [670/2000], Train Loss: 0.0196, Test Loss: 0.0195\n",
      "The metrics are: 0.06937790289521217, 0.011543061894675096, and 0.017177042240897816\n",
      "Epoch [671/2000], Train Loss: 0.0193, Test Loss: 0.0200\n",
      "The metrics are: 0.06916620830694835, 0.01137573861827453, and 0.017019936504463356\n",
      "Epoch [672/2000], Train Loss: 0.0193, Test Loss: 0.0196\n",
      "The metrics are: 0.06892345721522967, 0.011494241344432036, and 0.017124202723304432\n",
      "Epoch [673/2000], Train Loss: 0.0190, Test Loss: 0.0199\n",
      "The metrics are: 0.067948413391908, 0.01120508120705684, and 0.016840141577025253\n",
      "Epoch [674/2000], Train Loss: 0.0193, Test Loss: 0.0192\n",
      "The metrics are: 0.06683546553055446, 0.011191586342950663, and 0.01683275184283654\n",
      "Epoch [675/2000], Train Loss: 0.0187, Test Loss: 0.0191\n",
      "The metrics are: 0.06778484707077344, 0.01120063103735447, and 0.016852818119029205\n",
      "Epoch [676/2000], Train Loss: 0.0187, Test Loss: 0.0194\n",
      "The metrics are: 0.06672639275590579, 0.011084171322484812, and 0.016722272771100204\n",
      "Epoch [677/2000], Train Loss: 0.0188, Test Loss: 0.0191\n",
      "The metrics are: 0.06605931743979454, 0.011041992343962193, and 0.01667028230925401\n",
      "Epoch [678/2000], Train Loss: 0.0184, Test Loss: 0.0191\n",
      "The metrics are: 0.06651104986667633, 0.011151117272675037, and 0.01674590011437734\n",
      "Epoch [679/2000], Train Loss: 0.0182, Test Loss: 0.0195\n",
      "The metrics are: 0.06711389621098836, 0.011175638375182947, and 0.01678164613743623\n",
      "Epoch [680/2000], Train Loss: 0.0188, Test Loss: 0.0198\n",
      "The metrics are: 0.06792094310124715, 0.011146933150788149, and 0.016747569975753624\n",
      "Epoch [681/2000], Train Loss: 0.0191, Test Loss: 0.0199\n",
      "The metrics are: 0.06683795774976413, 0.010973146185278893, and 0.016538092245658238\n",
      "Epoch [682/2000], Train Loss: 0.0191, Test Loss: 0.0194\n",
      "The metrics are: 0.06751775865753491, 0.011061618104577065, and 0.016635225775341194\n",
      "Epoch [683/2000], Train Loss: 0.0192, Test Loss: 0.0198\n",
      "The metrics are: 0.06561492756009102, 0.010867340800662836, and 0.016440711294611294\n",
      "Epoch [684/2000], Train Loss: 0.0190, Test Loss: 0.0191\n",
      "The metrics are: 0.06626386071244876, 0.010880501009523869, and 0.016450474970042706\n",
      "Epoch [685/2000], Train Loss: 0.0188, Test Loss: 0.0194\n",
      "The metrics are: 0.06595663850506146, 0.010794328836103281, and 0.01636312808841467\n",
      "Epoch [686/2000], Train Loss: 0.0191, Test Loss: 0.0192\n",
      "The metrics are: 0.06517554447054863, 0.010673610493540764, and 0.016232586776216824\n",
      "Epoch [687/2000], Train Loss: 0.0188, Test Loss: 0.0189\n",
      "The metrics are: 0.06498524670799573, 0.01072997817148765, and 0.016267810637752216\n",
      "Epoch [688/2000], Train Loss: 0.0182, Test Loss: 0.0191\n",
      "The metrics are: 0.06572350487112999, 0.010784446572264036, and 0.016297586572666962\n",
      "Epoch [689/2000], Train Loss: 0.0184, Test Loss: 0.0194\n",
      "The metrics are: 0.06394170721371968, 0.01051961382230123, and 0.016044532880187035\n",
      "Epoch [690/2000], Train Loss: 0.0183, Test Loss: 0.0185\n",
      "The metrics are: 0.06361536060770352, 0.010533113032579422, and 0.01606759304801623\n",
      "Epoch [691/2000], Train Loss: 0.0180, Test Loss: 0.0186\n",
      "The metrics are: 0.06424202273289363, 0.010496251595517, and 0.016033741955955822\n",
      "Epoch [692/2000], Train Loss: 0.0182, Test Loss: 0.0187\n",
      "The metrics are: 0.0635008675356706, 0.010405216055611769, and 0.015918726411958534\n",
      "Epoch [693/2000], Train Loss: 0.0181, Test Loss: 0.0185\n",
      "The metrics are: 0.06393125156561534, 0.01071104904015859, and 0.01615052701284488\n",
      "Epoch [694/2000], Train Loss: 0.0179, Test Loss: 0.0194\n",
      "The metrics are: 0.06584375972549121, 0.010714605761071047, and 0.016123867593705654\n",
      "Epoch [695/2000], Train Loss: 0.0188, Test Loss: 0.0198\n",
      "The metrics are: 0.06374602143963178, 0.01046195812523365, and 0.01590247234950463\n",
      "Epoch [696/2000], Train Loss: 0.0187, Test Loss: 0.0188\n",
      "The metrics are: 0.062379103153944016, 0.010290184368689856, and 0.015747416764497757\n",
      "Epoch [697/2000], Train Loss: 0.0181, Test Loss: 0.0183\n",
      "The metrics are: 0.06253036856651306, 0.010440581167737642, and 0.015903670340776443\n",
      "Epoch [698/2000], Train Loss: 0.0175, Test Loss: 0.0188\n",
      "The metrics are: 0.06263744706908862, 0.0102667814741532, and 0.01573805883526802\n",
      "Epoch [699/2000], Train Loss: 0.0180, Test Loss: 0.0185\n",
      "The metrics are: 0.06227340797583262, 0.010187512884537378, and 0.015679216322799523\n",
      "Epoch [700/2000], Train Loss: 0.0179, Test Loss: 0.0183\n",
      "The metrics are: 0.06220936278502146, 0.010299798722068468, and 0.015737317502498627\n",
      "Epoch [701/2000], Train Loss: 0.0177, Test Loss: 0.0187\n",
      "The metrics are: 0.06017764906088511, 0.009959633462131023, and 0.015447028912603855\n",
      "Epoch [702/2000], Train Loss: 0.0177, Test Loss: 0.0175\n",
      "The metrics are: 0.05986439188321432, 0.009875595880051454, and 0.015374807640910149\n",
      "Epoch [703/2000], Train Loss: 0.0171, Test Loss: 0.0174\n",
      "The metrics are: 0.06005537137389183, 0.00994516226152579, and 0.015457325614988804\n",
      "Epoch [704/2000], Train Loss: 0.0171, Test Loss: 0.0178\n",
      "The metrics are: 0.06002584844827652, 0.009975647553801537, and 0.015463737770915031\n",
      "Epoch [705/2000], Train Loss: 0.0172, Test Loss: 0.0180\n",
      "The metrics are: 0.05926193421085676, 0.009821466480692228, and 0.015307799292107424\n",
      "Epoch [706/2000], Train Loss: 0.0172, Test Loss: 0.0176\n",
      "The metrics are: 0.05935089538494746, 0.00989636437346538, and 0.015366194148858389\n",
      "Epoch [707/2000], Train Loss: 0.0169, Test Loss: 0.0180\n",
      "The metrics are: 0.060259249061346054, 0.009911678110559782, and 0.015378777558604876\n",
      "Epoch [708/2000], Train Loss: 0.0172, Test Loss: 0.0182\n",
      "The metrics are: 0.061104794343312584, 0.009973206867774328, and 0.015409549387792746\n",
      "Epoch [709/2000], Train Loss: 0.0178, Test Loss: 0.0187\n",
      "The metrics are: 0.05854850386579832, 0.009708171710371971, and 0.015167683362960815\n",
      "Epoch [710/2000], Train Loss: 0.0176, Test Loss: 0.0176\n",
      "The metrics are: 0.05818274865547816, 0.009668220455447832, and 0.015132181656857332\n",
      "Epoch [711/2000], Train Loss: 0.0169, Test Loss: 0.0175\n",
      "The metrics are: 0.05900881687800089, 0.009708313892285029, and 0.015168985351920128\n",
      "Epoch [712/2000], Train Loss: 0.0166, Test Loss: 0.0179\n",
      "The metrics are: 0.05698004240791003, 0.009464641101658344, and 0.014939557450513044\n",
      "Epoch [713/2000], Train Loss: 0.0169, Test Loss: 0.0170\n",
      "The metrics are: 0.05643017962574959, 0.00942680798470974, and 0.014914959979554018\n",
      "Epoch [714/2000], Train Loss: 0.0163, Test Loss: 0.0170\n",
      "The metrics are: 0.0579954187075297, 0.009652980603277683, and 0.015109515438477198\n",
      "Epoch [715/2000], Train Loss: 0.0164, Test Loss: 0.0180\n",
      "The metrics are: 0.05855043977499008, 0.00963564527531465, and 0.015084144348899523\n",
      "Epoch [716/2000], Train Loss: 0.0170, Test Loss: 0.0180\n",
      "The metrics are: 0.05985998113950094, 0.00980771208802859, and 0.015205622650682926\n",
      "Epoch [717/2000], Train Loss: 0.0174, Test Loss: 0.0188\n",
      "The metrics are: 0.05946886291106542, 0.009782733085254828, and 0.015147969437142214\n",
      "Epoch [718/2000], Train Loss: 0.0178, Test Loss: 0.0187\n",
      "The metrics are: 0.05897355576356252, 0.009585374345382055, and 0.014958338811993599\n",
      "Epoch [719/2000], Train Loss: 0.0179, Test Loss: 0.0182\n",
      "The metrics are: 0.057298023253679276, 0.009463700465857983, and 0.014851915650069714\n",
      "Epoch [720/2000], Train Loss: 0.0172, Test Loss: 0.0177\n",
      "The metrics are: 0.056598685681819916, 0.00925678356240193, and 0.014674716318647066\n",
      "Epoch [721/2000], Train Loss: 0.0169, Test Loss: 0.0171\n",
      "The metrics are: 0.05617412055532137, 0.009353194385766983, and 0.014767441588143507\n",
      "Epoch [722/2000], Train Loss: 0.0165, Test Loss: 0.0174\n",
      "The metrics are: 0.05666713540752729, 0.009275636946161589, and 0.01467011837909619\n",
      "Epoch [723/2000], Train Loss: 0.0167, Test Loss: 0.0174\n",
      "The metrics are: 0.055216519782940544, 0.009277505800127983, and 0.014675367313126722\n",
      "Epoch [724/2000], Train Loss: 0.0166, Test Loss: 0.0172\n",
      "The metrics are: 0.0546732135117054, 0.009087104971210161, and 0.014515382858614126\n",
      "Epoch [725/2000], Train Loss: 0.0162, Test Loss: 0.0167\n",
      "The metrics are: 0.05523058275381724, 0.009235825079182783, and 0.014648460783064365\n",
      "Epoch [726/2000], Train Loss: 0.0162, Test Loss: 0.0173\n",
      "The metrics are: 0.05519828945398331, 0.009157221764326096, and 0.014577916512886683\n",
      "Epoch [727/2000], Train Loss: 0.0165, Test Loss: 0.0173\n",
      "The metrics are: 0.05515016739567121, 0.009114994357029596, and 0.014546391554176807\n",
      "Epoch [728/2000], Train Loss: 0.0165, Test Loss: 0.0171\n",
      "The metrics are: 0.054247873524824776, 0.009025014005601406, and 0.014467674928406874\n",
      "Epoch [729/2000], Train Loss: 0.0163, Test Loss: 0.0169\n",
      "The metrics are: 0.05375718201200167, 0.009076127161582312, and 0.014488470119734606\n",
      "Epoch [730/2000], Train Loss: 0.0162, Test Loss: 0.0170\n",
      "The metrics are: 0.05338356147209803, 0.008858596595625082, and 0.01432321189592282\n",
      "Epoch [731/2000], Train Loss: 0.0160, Test Loss: 0.0165\n",
      "The metrics are: 0.05298577000697454, 0.008928426541388035, and 0.01438063041617473\n",
      "Epoch [732/2000], Train Loss: 0.0157, Test Loss: 0.0167\n",
      "The metrics are: 0.053409967571496964, 0.00909234769642353, and 0.014525102141002813\n",
      "Epoch [733/2000], Train Loss: 0.0158, Test Loss: 0.0174\n",
      "The metrics are: 0.0544257697959741, 0.00901744638880094, and 0.014499044977128506\n",
      "Epoch [734/2000], Train Loss: 0.0165, Test Loss: 0.0173\n",
      "The metrics are: 0.0543865313132604, 0.009020807842413584, and 0.014497574108342329\n",
      "Epoch [735/2000], Train Loss: 0.0166, Test Loss: 0.0175\n",
      "The metrics are: 0.05409731095035871, 0.00889017836501201, and 0.01440661462644736\n",
      "Epoch [736/2000], Train Loss: 0.0166, Test Loss: 0.0172\n",
      "The metrics are: 0.052449254939953484, 0.008713862237830957, and 0.014246473709742228\n",
      "Epoch [737/2000], Train Loss: 0.0161, Test Loss: 0.0166\n",
      "The metrics are: 0.05119317521651586, 0.008617799108227095, and 0.014168718829751015\n",
      "Epoch [738/2000], Train Loss: 0.0158, Test Loss: 0.0162\n",
      "The metrics are: 0.05087456852197647, 0.008551701282461485, and 0.014108075139423212\n",
      "Epoch [739/2000], Train Loss: 0.0154, Test Loss: 0.0161\n",
      "The metrics are: 0.051032908260822296, 0.008782821086545786, and 0.014310968108475208\n",
      "Epoch [740/2000], Train Loss: 0.0148, Test Loss: 0.0168\n",
      "The metrics are: 0.052324203153451286, 0.00867780235906442, and 0.01422908529639244\n",
      "Epoch [741/2000], Train Loss: 0.0159, Test Loss: 0.0169\n",
      "The metrics are: 0.05175093188881874, 0.008705815921227137, and 0.014244760076204935\n",
      "Epoch [742/2000], Train Loss: 0.0159, Test Loss: 0.0170\n",
      "The metrics are: 0.0520861508945624, 0.008801867564519247, and 0.014311258681118488\n",
      "Epoch [743/2000], Train Loss: 0.0158, Test Loss: 0.0174\n",
      "The metrics are: 0.0539745365579923, 0.008934984914958477, and 0.014408557675778866\n",
      "Epoch [744/2000], Train Loss: 0.0164, Test Loss: 0.0181\n",
      "The metrics are: 0.05383021260301272, 0.009067319643994173, and 0.014423143739501635\n",
      "Epoch [745/2000], Train Loss: 0.0168, Test Loss: 0.0184\n",
      "The metrics are: 0.05432650695244471, 0.008991279328862825, and 0.014366476175685724\n",
      "Epoch [746/2000], Train Loss: 0.0171, Test Loss: 0.0182\n",
      "The metrics are: 0.05406730125347773, 0.00877352679769198, and 0.01417771199097236\n",
      "Epoch [747/2000], Train Loss: 0.0173, Test Loss: 0.0175\n",
      "The metrics are: 0.05129237100481987, 0.00847051665186882, and 0.01392367109656334\n",
      "Epoch [748/2000], Train Loss: 0.0163, Test Loss: 0.0165\n",
      "The metrics are: 0.049450734009345375, 0.008249312949677309, and 0.013759996431569258\n",
      "Epoch [749/2000], Train Loss: 0.0155, Test Loss: 0.0157\n",
      "The metrics are: 0.05006867398818334, 0.008438031810025374, and 0.01393226565172275\n",
      "Epoch [750/2000], Train Loss: 0.0149, Test Loss: 0.0165\n",
      "The metrics are: 0.05093963878850142, 0.00851568424453338, and 0.014001367303232351\n",
      "Epoch [751/2000], Train Loss: 0.0156, Test Loss: 0.0169\n",
      "The metrics are: 0.05176338367164135, 0.008433520793914795, and 0.013910206655661264\n",
      "Epoch [752/2000], Train Loss: 0.0163, Test Loss: 0.0169\n",
      "The metrics are: 0.05068474200864633, 0.00833829709639152, and 0.01380344262967507\n",
      "Epoch [753/2000], Train Loss: 0.0161, Test Loss: 0.0165\n",
      "The metrics are: 0.049030050014456115, 0.008200744787851969, and 0.0136667275801301\n",
      "Epoch [754/2000], Train Loss: 0.0154, Test Loss: 0.0159\n",
      "The metrics are: 0.049375789860884346, 0.008238212981571754, and 0.013715404085814953\n",
      "Epoch [755/2000], Train Loss: 0.0150, Test Loss: 0.0162\n",
      "The metrics are: 0.0495746216426293, 0.008408188509444395, and 0.013831598063309988\n",
      "Epoch [756/2000], Train Loss: 0.0153, Test Loss: 0.0168\n",
      "The metrics are: 0.04809463582932949, 0.008748356873790422, and 0.013916754784683386\n",
      "Epoch [757/2000], Train Loss: 0.0154, Test Loss: 0.0167\n",
      "The metrics are: 0.049794258549809456, 0.008399628413220247, and 0.013792243165274462\n",
      "Epoch [758/2000], Train Loss: 0.0151, Test Loss: 0.0171\n",
      "The metrics are: 0.05030712236960729, 0.008331496889392534, and 0.013724430774648985\n",
      "Epoch [759/2000], Train Loss: 0.0159, Test Loss: 0.0170\n",
      "The metrics are: 0.05032483426233133, 0.008257496015479168, and 0.013647357312341532\n",
      "Epoch [760/2000], Train Loss: 0.0160, Test Loss: 0.0169\n",
      "The metrics are: 0.049134056394298874, 0.008165010095884403, and 0.013573858266075453\n",
      "Epoch [761/2000], Train Loss: 0.0156, Test Loss: 0.0165\n",
      "The metrics are: 0.04922520617643992, 0.00814657456551989, and 0.013545386493206024\n",
      "Epoch [762/2000], Train Loss: 0.0156, Test Loss: 0.0165\n",
      "The metrics are: 0.04869253374636173, 0.008016081061214209, and 0.013407091920574507\n",
      "Epoch [763/2000], Train Loss: 0.0156, Test Loss: 0.0161\n",
      "The metrics are: 0.04970897982517878, 0.008302110557754835, and 0.013625394242505232\n",
      "Epoch [764/2000], Train Loss: 0.0152, Test Loss: 0.0170\n",
      "The metrics are: 0.049127466355760895, 0.00805298580477635, and 0.01341424509882927\n",
      "Epoch [765/2000], Train Loss: 0.0157, Test Loss: 0.0164\n",
      "The metrics are: 0.048799420396486916, 0.008092884284754595, and 0.013439579866826534\n",
      "Epoch [766/2000], Train Loss: 0.0156, Test Loss: 0.0165\n",
      "The metrics are: 0.04867138403157393, 0.008049704600125551, and 0.013387179312606653\n",
      "Epoch [767/2000], Train Loss: 0.0153, Test Loss: 0.0165\n",
      "The metrics are: 0.04773288841048876, 0.007900389687468609, and 0.013263699598610401\n",
      "Epoch [768/2000], Train Loss: 0.0152, Test Loss: 0.0159\n",
      "The metrics are: 0.047426779444019, 0.007935676258057356, and 0.01328718289732933\n",
      "Epoch [769/2000], Train Loss: 0.0148, Test Loss: 0.0161\n",
      "The metrics are: 0.04796953126788139, 0.008046654829134544, and 0.013366088581581911\n",
      "Epoch [770/2000], Train Loss: 0.0148, Test Loss: 0.0167\n",
      "The metrics are: 0.04842991133530935, 0.007908998678127924, and 0.013270004652440548\n",
      "Epoch [771/2000], Train Loss: 0.0155, Test Loss: 0.0165\n",
      "The metrics are: 0.047597769647836685, 0.00782618640611569, and 0.013160236179828644\n",
      "Epoch [772/2000], Train Loss: 0.0153, Test Loss: 0.0161\n",
      "The metrics are: 0.04809385724365711, 0.007850940028826395, and 0.013171746085087458\n",
      "Epoch [773/2000], Train Loss: 0.0152, Test Loss: 0.0163\n",
      "The metrics are: 0.04768480360507965, 0.008023744138578573, and 0.013272540954252085\n",
      "Epoch [774/2000], Train Loss: 0.0152, Test Loss: 0.0167\n",
      "The metrics are: 0.04941611737012863, 0.008157105340311924, and 0.013365119385222593\n",
      "Epoch [775/2000], Train Loss: 0.0155, Test Loss: 0.0175\n",
      "The metrics are: 0.04909138816098372, 0.00809621795391043, and 0.013294762000441551\n",
      "Epoch [776/2000], Train Loss: 0.0162, Test Loss: 0.0171\n",
      "The metrics are: 0.05006285632650057, 0.008287900282690922, and 0.013404466522236666\n",
      "Epoch [777/2000], Train Loss: 0.0161, Test Loss: 0.0179\n",
      "The metrics are: 0.048749446868896484, 0.007931880187243223, and 0.013121369294822216\n",
      "Epoch [778/2000], Train Loss: 0.0164, Test Loss: 0.0168\n",
      "The metrics are: 0.04763086140155792, 0.007756577028582494, and 0.012981588020920753\n",
      "Epoch [779/2000], Train Loss: 0.0157, Test Loss: 0.0162\n",
      "The metrics are: 0.046485159546136856, 0.007567175664007664, and 0.012858485182126364\n",
      "Epoch [780/2000], Train Loss: 0.0150, Test Loss: 0.0156\n",
      "The metrics are: 0.045134227722883224, 0.007444435264915228, and 0.012735017264882723\n",
      "Epoch [781/2000], Train Loss: 0.0147, Test Loss: 0.0151\n",
      "The metrics are: 0.04655189750095209, 0.007763665324697892, and 0.012982091555992762\n",
      "Epoch [782/2000], Train Loss: 0.0145, Test Loss: 0.0162\n",
      "The metrics are: 0.04478579697509607, 0.007665484212338924, and 0.012874036406477293\n",
      "Epoch [783/2000], Train Loss: 0.0147, Test Loss: 0.0159\n",
      "The metrics are: 0.045836047579844795, 0.007559981818000476, and 0.012787312890092531\n",
      "Epoch [784/2000], Train Loss: 0.0147, Test Loss: 0.0159\n",
      "The metrics are: 0.04605603776872158, 0.007613175082951784, and 0.012800551019608974\n",
      "Epoch [785/2000], Train Loss: 0.0148, Test Loss: 0.0161\n",
      "The metrics are: 0.04597651275495688, 0.007501803648968537, and 0.012717425202329954\n",
      "Epoch [786/2000], Train Loss: 0.0150, Test Loss: 0.0158\n",
      "The metrics are: 0.046026138588786125, 0.007422818181415399, and 0.012658567167818546\n",
      "Epoch [787/2000], Train Loss: 0.0150, Test Loss: 0.0158\n",
      "The metrics are: 0.045446171735723816, 0.007414201119293769, and 0.012640867692728838\n",
      "Epoch [788/2000], Train Loss: 0.0151, Test Loss: 0.0156\n",
      "The metrics are: 0.04537601148088773, 0.007509528348843257, and 0.01268353189031283\n",
      "Epoch [789/2000], Train Loss: 0.0147, Test Loss: 0.0160\n",
      "The metrics are: 0.0443266537040472, 0.007389241053412358, and 0.012592018581926823\n",
      "Epoch [790/2000], Train Loss: 0.0146, Test Loss: 0.0156\n",
      "The metrics are: 0.043698602666457496, 0.007334906607866287, and 0.012537481573720774\n",
      "Epoch [791/2000], Train Loss: 0.0144, Test Loss: 0.0154\n",
      "The metrics are: 0.043782527868946396, 0.007458538593103488, and 0.01259604375809431\n",
      "Epoch [792/2000], Train Loss: 0.0144, Test Loss: 0.0158\n",
      "The metrics are: 0.04516197554767132, 0.007429989520460367, and 0.012578734507163366\n",
      "Epoch [793/2000], Train Loss: 0.0144, Test Loss: 0.0161\n",
      "The metrics are: 0.04438494021693865, 0.007337698092063268, and 0.0124824537585179\n",
      "Epoch [794/2000], Train Loss: 0.0148, Test Loss: 0.0158\n",
      "The metrics are: 0.044074314335982, 0.007346846784154574, and 0.012477942742407322\n",
      "Epoch [795/2000], Train Loss: 0.0145, Test Loss: 0.0159\n",
      "The metrics are: 0.04477201588451862, 0.007424667788048585, and 0.01250750757753849\n",
      "Epoch [796/2000], Train Loss: 0.0145, Test Loss: 0.0163\n",
      "The metrics are: 0.044717405612270035, 0.007412743133803208, and 0.012486014204720655\n",
      "Epoch [797/2000], Train Loss: 0.0150, Test Loss: 0.0163\n",
      "The metrics are: 0.04473791519800822, 0.007266465264062087, and 0.01238622268040975\n",
      "Epoch [798/2000], Train Loss: 0.0149, Test Loss: 0.0159\n",
      "The metrics are: 0.044145671650767326, 0.007287097784380118, and 0.012372510197261969\n",
      "Epoch [799/2000], Train Loss: 0.0147, Test Loss: 0.0160\n",
      "The metrics are: 0.04547171667218208, 0.007517840247601271, and 0.012538387750585874\n",
      "Epoch [800/2000], Train Loss: 0.0148, Test Loss: 0.0168\n",
      "The metrics are: 0.04393372250099977, 0.00721094540009896, and 0.012276620914538702\n",
      "Epoch [801/2000], Train Loss: 0.0153, Test Loss: 0.0159\n",
      "The metrics are: 0.04324960149824619, 0.007138712486873071, and 0.012212810727457205\n",
      "Epoch [802/2000], Train Loss: 0.0147, Test Loss: 0.0154\n",
      "The metrics are: 0.04235881629089514, 0.006930102749417226, and 0.012040645504991213\n",
      "Epoch [803/2000], Train Loss: 0.0142, Test Loss: 0.0150\n",
      "The metrics are: 0.04148616331319014, 0.0069017152612408, and 0.012013452127575874\n",
      "Epoch [804/2000], Train Loss: 0.0139, Test Loss: 0.0149\n",
      "The metrics are: 0.04190995482107004, 0.006916462909430265, and 0.012033386466403803\n",
      "Epoch [805/2000], Train Loss: 0.0137, Test Loss: 0.0150\n",
      "The metrics are: 0.0423541609197855, 0.007023286074399948, and 0.012089851622780165\n",
      "Epoch [806/2000], Train Loss: 0.0139, Test Loss: 0.0156\n",
      "The metrics are: 0.0431426540017128, 0.007210803218185902, and 0.01221670334537824\n",
      "Epoch [807/2000], Train Loss: 0.0141, Test Loss: 0.0161\n",
      "The metrics are: 0.042761881525317826, 0.007099407259374857, and 0.012115645222365856\n",
      "Epoch [808/2000], Train Loss: 0.0146, Test Loss: 0.0158\n",
      "The metrics are: 0.042341157173117004, 0.006975453191747268, and 0.012007967258493105\n",
      "Epoch [809/2000], Train Loss: 0.0145, Test Loss: 0.0155\n",
      "The metrics are: 0.041942122081915535, 0.006807227153331041, and 0.011885900981724262\n",
      "Epoch [810/2000], Train Loss: 0.0141, Test Loss: 0.0150\n",
      "The metrics are: 0.04147091445823511, 0.006861176962653796, and 0.01190154409656922\n",
      "Epoch [811/2000], Train Loss: 0.0140, Test Loss: 0.0153\n",
      "The metrics are: 0.04129311814904213, 0.006707986816763878, and 0.011773725971579552\n",
      "Epoch [812/2000], Train Loss: 0.0140, Test Loss: 0.0149\n",
      "The metrics are: 0.03995750658214092, 0.006618928785125415, and 0.011673361683885256\n",
      "Epoch [813/2000], Train Loss: 0.0136, Test Loss: 0.0144\n",
      "The metrics are: 0.03924869249264399, 0.006499486199269692, and 0.01157783716917038\n",
      "Epoch [814/2000], Train Loss: 0.0132, Test Loss: 0.0140\n",
      "The metrics are: 0.038886925826470055, 0.006612296837071578, and 0.011639920063316822\n",
      "Epoch [815/2000], Train Loss: 0.0130, Test Loss: 0.0144\n",
      "The metrics are: 0.040457584584752716, 0.0067277221630016966, and 0.011714696263273558\n",
      "Epoch [816/2000], Train Loss: 0.0133, Test Loss: 0.0153\n",
      "The metrics are: 0.04063239755729834, 0.006803134921938181, and 0.011764321165780226\n",
      "Epoch [817/2000], Train Loss: 0.0137, Test Loss: 0.0155\n",
      "The metrics are: 0.04110311344265938, 0.006882358031968276, and 0.011784058685104052\n",
      "Epoch [818/2000], Train Loss: 0.0140, Test Loss: 0.0157\n",
      "The metrics are: 0.0421274850765864, 0.006995491062601407, and 0.011846884153783321\n",
      "Epoch [819/2000], Train Loss: 0.0143, Test Loss: 0.0163\n",
      "The metrics are: 0.04083040853341421, 0.0066674404467145605, and 0.01159074685225884\n",
      "Epoch [820/2000], Train Loss: 0.0145, Test Loss: 0.0153\n",
      "The metrics are: 0.040149375796318054, 0.00661570035542051, and 0.011558314940581719\n",
      "Epoch [821/2000], Train Loss: 0.0139, Test Loss: 0.0150\n",
      "The metrics are: 0.04039867656926314, 0.006551576778292656, and 0.011504304750512043\n",
      "Epoch [822/2000], Train Loss: 0.0139, Test Loss: 0.0148\n",
      "The metrics are: 0.038659763832887016, 0.006497536941121022, and 0.011431418669720491\n",
      "Epoch [823/2000], Train Loss: 0.0135, Test Loss: 0.0145\n",
      "The metrics are: 0.038153604293862976, 0.006408103120823701, and 0.011377300756673018\n",
      "Epoch [824/2000], Train Loss: 0.0130, Test Loss: 0.0143\n",
      "The metrics are: 0.037871584917108216, 0.006310690349588792, and 0.011329980256656805\n",
      "Epoch [825/2000], Train Loss: 0.0129, Test Loss: 0.0142\n",
      "The metrics are: 0.038071432461341224, 0.006329866436620553, and 0.01130234713976582\n",
      "Epoch [826/2000], Train Loss: 0.0130, Test Loss: 0.0142\n",
      "The metrics are: 0.038474769641955696, 0.006403868707517783, and 0.011359384749084711\n",
      "Epoch [827/2000], Train Loss: 0.0130, Test Loss: 0.0147\n",
      "The metrics are: 0.03781499216953913, 0.006417516463746627, and 0.011329430931558212\n",
      "Epoch [828/2000], Train Loss: 0.0132, Test Loss: 0.0146\n",
      "The metrics are: 0.03797929920256138, 0.006516655907034874, and 0.011371999668578306\n",
      "Epoch [829/2000], Train Loss: 0.0130, Test Loss: 0.0151\n",
      "The metrics are: 0.03862494726975759, 0.0065335920080542564, and 0.011357944924384356\n",
      "Epoch [830/2000], Train Loss: 0.0134, Test Loss: 0.0152\n",
      "The metrics are: 0.040291316186388336, 0.006567510465780894, and 0.011375948165853819\n",
      "Epoch [831/2000], Train Loss: 0.0137, Test Loss: 0.0157\n",
      "The metrics are: 0.040190468852718673, 0.006716772603491942, and 0.011444175460686287\n",
      "Epoch [832/2000], Train Loss: 0.0142, Test Loss: 0.0158\n",
      "The metrics are: 0.04013512283563614, 0.006454861567666133, and 0.011241751567771038\n",
      "Epoch [833/2000], Train Loss: 0.0144, Test Loss: 0.0153\n",
      "The metrics are: 0.04195586716135343, 0.006809072724233071, and 0.01145586185157299\n",
      "Epoch [834/2000], Train Loss: 0.0144, Test Loss: 0.0166\n",
      "The metrics are: 0.04096719187994798, 0.0066218930296599865, and 0.011273752432316542\n",
      "Epoch [835/2000], Train Loss: 0.0152, Test Loss: 0.0158\n",
      "The metrics are: 0.039785810435811676, 0.00640961853787303, and 0.011120266591509184\n",
      "Epoch [836/2000], Train Loss: 0.0145, Test Loss: 0.0152\n",
      "The metrics are: 0.03948226943612099, 0.006463055654118459, and 0.011129251991709074\n",
      "Epoch [837/2000], Train Loss: 0.0140, Test Loss: 0.0151\n",
      "The metrics are: 0.03733717153469721, 0.006071322908004125, and 0.010836781778683266\n",
      "Epoch [838/2000], Train Loss: 0.0137, Test Loss: 0.0139\n",
      "The metrics are: 0.036527895679076515, 0.005998663449039062, and 0.010751278915752968\n",
      "Epoch [839/2000], Train Loss: 0.0129, Test Loss: 0.0135\n",
      "The metrics are: 0.035750823095440865, 0.00597253767773509, and 0.010702742418895165\n",
      "Epoch [840/2000], Train Loss: 0.0125, Test Loss: 0.0135\n",
      "The metrics are: 0.03511070522169272, 0.00601346946010987, and 0.010698951625575623\n",
      "Epoch [841/2000], Train Loss: 0.0124, Test Loss: 0.0135\n",
      "The metrics are: 0.035464019825061165, 0.00595840144281586, and 0.010662974013636509\n",
      "Epoch [842/2000], Train Loss: 0.0122, Test Loss: 0.0136\n",
      "The metrics are: 0.034997797260681786, 0.0059629289122919244, and 0.010658743946502605\n",
      "Epoch [843/2000], Train Loss: 0.0123, Test Loss: 0.0135\n",
      "The metrics are: 0.03422439470887184, 0.006039559065053861, and 0.010695250860104958\n",
      "Epoch [844/2000], Train Loss: 0.0119, Test Loss: 0.0138\n",
      "The metrics are: 0.036614542516569294, 0.006267343492557605, and 0.010893465019762516\n",
      "Epoch [845/2000], Train Loss: 0.0124, Test Loss: 0.0149\n",
      "The metrics are: 0.03695799348254999, 0.006298217456787825, and 0.010867575338731209\n",
      "Epoch [846/2000], Train Loss: 0.0131, Test Loss: 0.0151\n",
      "The metrics are: 0.038138993084430695, 0.006304876878857613, and 0.010848769141981999\n",
      "Epoch [847/2000], Train Loss: 0.0136, Test Loss: 0.0153\n",
      "The metrics are: 0.03817904554307461, 0.006248305551707745, and 0.010779252586265406\n",
      "Epoch [848/2000], Train Loss: 0.0138, Test Loss: 0.0151\n",
      "The metrics are: 0.03515796363353729, 0.005897917319089174, and 0.010510729781041542\n",
      "Epoch [849/2000], Train Loss: 0.0133, Test Loss: 0.0138\n",
      "The metrics are: 0.03408872957030932, 0.005803838837891817, and 0.010432784135142962\n",
      "Epoch [850/2000], Train Loss: 0.0120, Test Loss: 0.0134\n",
      "The metrics are: 0.0338316997513175, 0.005772255516300599, and 0.010378881357610226\n",
      "Epoch [851/2000], Train Loss: 0.0121, Test Loss: 0.0133\n",
      "The metrics are: 0.03318456467241049, 0.005689358959595363, and 0.010310663686444363\n",
      "Epoch [852/2000], Train Loss: 0.0117, Test Loss: 0.0132\n",
      "The metrics are: 0.034100803546607494, 0.006061779335141182, and 0.010519437647114197\n",
      "Epoch [853/2000], Train Loss: 0.0119, Test Loss: 0.0144\n",
      "The metrics are: 0.033783012380202614, 0.005919767543673515, and 0.01040709763765335\n",
      "Epoch [854/2000], Train Loss: 0.0122, Test Loss: 0.0140\n",
      "The metrics are: 0.03632642018298308, 0.006134784159560998, and 0.010583589629580578\n",
      "Epoch [855/2000], Train Loss: 0.0124, Test Loss: 0.0151\n",
      "The metrics are: 0.036484899620215096, 0.006251584893713395, and 0.010620924333731333\n",
      "Epoch [856/2000], Train Loss: 0.0131, Test Loss: 0.0154\n",
      "The metrics are: 0.03704953690369924, 0.005975613370537758, and 0.010441950211922327\n",
      "Epoch [857/2000], Train Loss: 0.0134, Test Loss: 0.0149\n",
      "The metrics are: 0.035778542359670006, 0.005871786270290613, and 0.010336784490694603\n",
      "Epoch [858/2000], Train Loss: 0.0135, Test Loss: 0.0143\n",
      "The metrics are: 0.03675635748853286, 0.005931193319459756, and 0.010371991588423649\n",
      "Epoch [859/2000], Train Loss: 0.0130, Test Loss: 0.0149\n",
      "The metrics are: 0.03627209862073263, 0.005962695615986983, and 0.010332637000828981\n",
      "Epoch [860/2000], Train Loss: 0.0133, Test Loss: 0.0147\n",
      "The metrics are: 0.03629446557412545, 0.005995481895903747, and 0.010344494134187698\n",
      "Epoch [861/2000], Train Loss: 0.0133, Test Loss: 0.0149\n",
      "The metrics are: 0.03358278082062801, 0.005568090360611677, and 0.009997615590691566\n",
      "Epoch [862/2000], Train Loss: 0.0129, Test Loss: 0.0132\n",
      "The metrics are: 0.03392407732705275, 0.005587585736066103, and 0.010001664981245995\n",
      "Epoch [863/2000], Train Loss: 0.0121, Test Loss: 0.0135\n",
      "The metrics are: 0.03472107990334431, 0.0058547019337614374, and 0.01015439877907435\n",
      "Epoch [864/2000], Train Loss: 0.0122, Test Loss: 0.0142\n",
      "The metrics are: 0.03352203437437614, 0.005696476281931003, and 0.010018575160453716\n",
      "Epoch [865/2000], Train Loss: 0.0125, Test Loss: 0.0138\n",
      "The metrics are: 0.03293482058991989, 0.005616225767880678, and 0.009931874306251606\n",
      "Epoch [866/2000], Train Loss: 0.0121, Test Loss: 0.0134\n",
      "The metrics are: 0.03311342808107535, 0.005595719131330649, and 0.009916310664266348\n",
      "Epoch [867/2000], Train Loss: 0.0118, Test Loss: 0.0136\n",
      "The metrics are: 0.03306871590514978, 0.005423007532954216, and 0.009746651786069075\n",
      "Epoch [868/2000], Train Loss: 0.0121, Test Loss: 0.0132\n",
      "The metrics are: 0.03322213515639305, 0.0055373371578752995, and 0.009832768080135187\n",
      "Epoch [869/2000], Train Loss: 0.0118, Test Loss: 0.0135\n",
      "The metrics are: 0.03346538574745258, 0.005747303211440642, and 0.009929881275941929\n",
      "Epoch [870/2000], Train Loss: 0.0122, Test Loss: 0.0140\n",
      "The metrics are: 0.032951868449648224, 0.005547793737302224, and 0.009786191241194805\n",
      "Epoch [871/2000], Train Loss: 0.0121, Test Loss: 0.0135\n",
      "The metrics are: 0.03255256420622269, 0.005434636181841294, and 0.009703204035758972\n",
      "Epoch [872/2000], Train Loss: 0.0121, Test Loss: 0.0132\n",
      "The metrics are: 0.03217318467795849, 0.005497635652621587, and 0.009728955570608377\n",
      "Epoch [873/2000], Train Loss: 0.0118, Test Loss: 0.0134\n",
      "The metrics are: 0.033799237882097564, 0.005744760235150655, and 0.00986568055426081\n",
      "Epoch [874/2000], Train Loss: 0.0121, Test Loss: 0.0144\n",
      "The metrics are: 0.03299136615047852, 0.005429363964746396, and 0.009636651258915663\n",
      "Epoch [875/2000], Train Loss: 0.0125, Test Loss: 0.0134\n",
      "The metrics are: 0.03128597512841225, 0.005420894672473271, and 0.009611250987897316\n",
      "Epoch [876/2000], Train Loss: 0.0120, Test Loss: 0.0130\n",
      "The metrics are: 0.030602375976741314, 0.005156890644381444, and 0.00931638851761818\n",
      "Epoch [877/2000], Train Loss: 0.0114, Test Loss: 0.0125\n",
      "The metrics are: 0.03142891234407822, 0.005365518853068352, and 0.009443534538149834\n",
      "Epoch [878/2000], Train Loss: 0.0112, Test Loss: 0.0130\n",
      "The metrics are: 0.031006084755063057, 0.005359921914835771, and 0.009411888817946116\n",
      "Epoch [879/2000], Train Loss: 0.0115, Test Loss: 0.0131\n",
      "The metrics are: 0.030337047763168812, 0.0052375161709884805, and 0.009293665488560995\n",
      "Epoch [880/2000], Train Loss: 0.0114, Test Loss: 0.0126\n",
      "The metrics are: 0.029110935516655445, 0.005103478829065959, and 0.009157806014021238\n",
      "Epoch [881/2000], Train Loss: 0.0109, Test Loss: 0.0120\n",
      "The metrics are: 0.028429599478840828, 0.005009488978733619, and 0.009034651021162668\n",
      "Epoch [882/2000], Train Loss: 0.0106, Test Loss: 0.0116\n",
      "The metrics are: 0.028269552625715733, 0.005204038228839636, and 0.00910289011274775\n",
      "Epoch [883/2000], Train Loss: 0.0100, Test Loss: 0.0121\n",
      "The metrics are: 0.02813010010868311, 0.0051665958017110825, and 0.008974868028114239\n",
      "Epoch [884/2000], Train Loss: 0.0105, Test Loss: 0.0118\n",
      "The metrics are: 0.027885490097105503, 0.00522337481379509, and 0.008866806980222464\n",
      "Epoch [885/2000], Train Loss: 0.0104, Test Loss: 0.0117\n",
      "The metrics are: 0.027782571812470753, 0.0051930964303513365, and 0.008728496885548035\n",
      "Epoch [886/2000], Train Loss: 0.0102, Test Loss: 0.0114\n",
      "The metrics are: 0.025945691391825676, 0.005183808971196413, and 0.00855394514898459\n",
      "Epoch [887/2000], Train Loss: 0.0100, Test Loss: 0.0106\n",
      "The metrics are: 0.024632736419637997, 0.004810689094786842, and 0.008287707343697548\n",
      "Epoch [888/2000], Train Loss: 0.0092, Test Loss: 0.0096\n",
      "The metrics are: 0.02444577341278394, 0.004886293628563483, and 0.008324296989788612\n",
      "Epoch [889/2000], Train Loss: 0.0088, Test Loss: 0.0098\n",
      "The metrics are: 0.024775225048263867, 0.005105574615299702, and 0.008412809887280067\n",
      "Epoch [890/2000], Train Loss: 0.0087, Test Loss: 0.0104\n",
      "The metrics are: 0.023728754681845505, 0.004894096714754899, and 0.008319947868585587\n",
      "Epoch [891/2000], Train Loss: 0.0088, Test Loss: 0.0099\n",
      "The metrics are: 0.023498677648603916, 0.0050288795803984, and 0.008350589157392582\n",
      "Epoch [892/2000], Train Loss: 0.0086, Test Loss: 0.0101\n",
      "The metrics are: 0.02374652245392402, 0.00490684147613744, and 0.008321629216273626\n",
      "Epoch [893/2000], Train Loss: 0.0087, Test Loss: 0.0102\n",
      "The metrics are: 0.023652538657188416, 0.0049718269146978855, and 0.008383919795354208\n",
      "Epoch [894/2000], Train Loss: 0.0089, Test Loss: 0.0104\n",
      "The metrics are: 0.02222104308505853, 0.004828846392532189, and 0.008255071627597014\n",
      "Epoch [895/2000], Train Loss: 0.0088, Test Loss: 0.0098\n",
      "The metrics are: 0.022655931611855824, 0.0050949032107989, and 0.0083637743567427\n",
      "Epoch [896/2000], Train Loss: 0.0086, Test Loss: 0.0106\n",
      "The metrics are: 0.02408357026676337, 0.005409318022429943, and 0.008560450902829567\n",
      "Epoch [897/2000], Train Loss: 0.0090, Test Loss: 0.0120\n",
      "The metrics are: 0.02326966356486082, 0.00511432330434521, and 0.008366204953442017\n",
      "Epoch [898/2000], Train Loss: 0.0095, Test Loss: 0.0113\n",
      "The metrics are: 0.02316597755998373, 0.005088333506137133, and 0.008346130916227898\n",
      "Epoch [899/2000], Train Loss: 0.0093, Test Loss: 0.0113\n",
      "The metrics are: 0.021849301643669605, 0.004944800864905119, and 0.008179114976276955\n",
      "Epoch [900/2000], Train Loss: 0.0089, Test Loss: 0.0106\n",
      "The metrics are: 0.02135631659378608, 0.004995774167279403, and 0.00814868307982882\n",
      "Epoch [901/2000], Train Loss: 0.0087, Test Loss: 0.0106\n",
      "The metrics are: 0.022477310461302597, 0.005120926691840093, and 0.008246985574563345\n",
      "Epoch [902/2000], Train Loss: 0.0087, Test Loss: 0.0114\n",
      "The metrics are: 0.022447860178848106, 0.005222444888204336, and 0.008226176723837852\n",
      "Epoch [903/2000], Train Loss: 0.0093, Test Loss: 0.0115\n",
      "The metrics are: 0.021826686958471935, 0.005018326298644145, and 0.008056879043579102\n",
      "Epoch [904/2000], Train Loss: 0.0092, Test Loss: 0.0111\n",
      "The metrics are: 0.022281937611599762, 0.005157510594775279, and 0.008118539893378815\n",
      "Epoch [905/2000], Train Loss: 0.0091, Test Loss: 0.0116\n",
      "The metrics are: 0.022907317305604618, 0.005408109941830237, and 0.00820694708575805\n",
      "Epoch [906/2000], Train Loss: 0.0094, Test Loss: 0.0124\n",
      "The metrics are: 0.023425679343442123, 0.0053701816747585935, and 0.008213982451707125\n",
      "Epoch [907/2000], Train Loss: 0.0098, Test Loss: 0.0126\n",
      "The metrics are: 0.02249272322903077, 0.005270806606858969, and 0.008076028898358345\n",
      "Epoch [908/2000], Train Loss: 0.0097, Test Loss: 0.0121\n",
      "The metrics are: 0.023847258649766445, 0.005609834101051092, and 0.008254687457034985\n",
      "Epoch [909/2000], Train Loss: 0.0098, Test Loss: 0.0133\n",
      "The metrics are: 0.022896213146547478, 0.005381141323596239, and 0.008098591274271408\n",
      "Epoch [910/2000], Train Loss: 0.0101, Test Loss: 0.0126\n",
      "The metrics are: 0.024609846994280815, 0.005508020209769408, and 0.008247764315456152\n",
      "Epoch [911/2000], Train Loss: 0.0100, Test Loss: 0.0136\n",
      "The metrics are: 0.0243379973496, 0.0056871045380830765, and 0.008245937836666902\n",
      "Epoch [912/2000], Train Loss: 0.0106, Test Loss: 0.0137\n",
      "The metrics are: 0.02403290259341399, 0.005450541929652293, and 0.008107664994895458\n",
      "Epoch [913/2000], Train Loss: 0.0107, Test Loss: 0.0134\n",
      "The metrics are: 0.024270585582902033, 0.005742794678856929, and 0.00820611355205377\n",
      "Epoch [914/2000], Train Loss: 0.0109, Test Loss: 0.0139\n",
      "The metrics are: 0.025749333202838898, 0.006051944723973672, and 0.00832932892565926\n",
      "Epoch [915/2000], Train Loss: 0.0112, Test Loss: 0.0150\n",
      "The metrics are: 0.02507056078563134, 0.005658923493077357, and 0.008101245543609062\n",
      "Epoch [916/2000], Train Loss: 0.0118, Test Loss: 0.0141\n",
      "The metrics are: 0.02381928823888302, 0.005690018956859906, and 0.00798108692591389\n",
      "Epoch [917/2000], Train Loss: 0.0112, Test Loss: 0.0135\n",
      "The metrics are: 0.024296848103404045, 0.0054353477122883005, and 0.007912577750782171\n",
      "Epoch [918/2000], Train Loss: 0.0107, Test Loss: 0.0135\n",
      "The metrics are: 0.023397138963143032, 0.00539783372854193, and 0.007800903016080459\n",
      "Epoch [919/2000], Train Loss: 0.0108, Test Loss: 0.0129\n",
      "The metrics are: 0.021771589914957683, 0.005007412905494372, and 0.007543329615145922\n",
      "Epoch [920/2000], Train Loss: 0.0101, Test Loss: 0.0117\n",
      "The metrics are: 0.022482542010645073, 0.0057188062928617, and 0.007800885320951541\n",
      "Epoch [921/2000], Train Loss: 0.0099, Test Loss: 0.0130\n",
      "The metrics are: 0.021093169537683327, 0.004991381584356229, and 0.007409168562541406\n",
      "Epoch [922/2000], Train Loss: 0.0099, Test Loss: 0.0115\n",
      "The metrics are: 0.020688324545820553, 0.005024153972044587, and 0.007406780341019233\n",
      "Epoch [923/2000], Train Loss: 0.0093, Test Loss: 0.0112\n",
      "The metrics are: 0.020093385285387438, 0.004749056417495012, and 0.0072754436793426676\n",
      "Epoch [924/2000], Train Loss: 0.0089, Test Loss: 0.0107\n",
      "The metrics are: 0.018791287516554196, 0.0046581247976670665, and 0.00715648103505373\n",
      "Epoch [925/2000], Train Loss: 0.0083, Test Loss: 0.0101\n",
      "The metrics are: 0.01943470196177562, 0.004730458293731014, and 0.007216309818128745\n",
      "Epoch [926/2000], Train Loss: 0.0081, Test Loss: 0.0108\n",
      "The metrics are: 0.02053438996275266, 0.0051875486969947815, and 0.00742074940353632\n",
      "Epoch [927/2000], Train Loss: 0.0087, Test Loss: 0.0121\n",
      "The metrics are: 0.01908693400522073, 0.005000513357420762, and 0.007227050140500069\n",
      "Epoch [928/2000], Train Loss: 0.0092, Test Loss: 0.0112\n",
      "The metrics are: 0.01879220160966118, 0.004688925032193462, and 0.007064285688102245\n",
      "Epoch [929/2000], Train Loss: 0.0085, Test Loss: 0.0107\n",
      "The metrics are: 0.01739483419805765, 0.004549673292785883, and 0.006876542543371518\n",
      "Epoch [930/2000], Train Loss: 0.0083, Test Loss: 0.0098\n",
      "The metrics are: 0.017242173819492262, 0.00444989154736201, and 0.00679762801155448\n",
      "Epoch [931/2000], Train Loss: 0.0076, Test Loss: 0.0096\n",
      "The metrics are: 0.016034653099874657, 0.0044717148412019014, and 0.006676079239696264\n",
      "Epoch [932/2000], Train Loss: 0.0074, Test Loss: 0.0091\n",
      "The metrics are: 0.015155399994303783, 0.004060902011891206, and 0.0064543938885132475\n",
      "Epoch [933/2000], Train Loss: 0.0068, Test Loss: 0.0082\n",
      "The metrics are: 0.014779191308965286, 0.00413781024205188, and 0.006394306508203347\n",
      "Epoch [934/2000], Train Loss: 0.0064, Test Loss: 0.0081\n",
      "The metrics are: 0.01522308929512898, 0.004120034398511052, and 0.006346452826013167\n",
      "Epoch [935/2000], Train Loss: 0.0063, Test Loss: 0.0084\n",
      "The metrics are: 0.015013158631821474, 0.004376446905856331, and 0.006305110330382983\n",
      "Epoch [936/2000], Train Loss: 0.0065, Test Loss: 0.0082\n",
      "The metrics are: 0.014518599336345991, 0.004124049873401721, and 0.00614530872553587\n",
      "Epoch [937/2000], Train Loss: 0.0062, Test Loss: 0.0080\n",
      "The metrics are: 0.014195816901822885, 0.0038197324611246586, and 0.005938977779199679\n",
      "Epoch [938/2000], Train Loss: 0.0059, Test Loss: 0.0071\n",
      "The metrics are: 0.013659198768436909, 0.0037441628519445658, and 0.005887599661946297\n",
      "Epoch [939/2000], Train Loss: 0.0054, Test Loss: 0.0068\n",
      "The metrics are: 0.012765026651322842, 0.0036776003738244376, and 0.005780334739635388\n",
      "Epoch [940/2000], Train Loss: 0.0052, Test Loss: 0.0061\n",
      "The metrics are: 0.011987808160483837, 0.0033842576667666435, and 0.005610374889026086\n",
      "Epoch [941/2000], Train Loss: 0.0049, Test Loss: 0.0054\n",
      "The metrics are: 0.011231743264943361, 0.003310403786599636, and 0.005486566883822282\n",
      "Epoch [942/2000], Train Loss: 0.0045, Test Loss: 0.0050\n",
      "The metrics are: 0.010326318753262361, 0.0030707514379173517, and 0.00529179551328222\n",
      "Epoch [943/2000], Train Loss: 0.0043, Test Loss: 0.0042\n",
      "The metrics are: 0.00978712442641457, 0.0029023791818569102, and 0.005149466761698325\n",
      "Epoch [944/2000], Train Loss: 0.0037, Test Loss: 0.0038\n",
      "The metrics are: 0.009306236480673155, 0.0027157768296698728, and 0.0050057657063007355\n",
      "Epoch [945/2000], Train Loss: 0.0035, Test Loss: 0.0034\n",
      "The metrics are: 0.009026750922203064, 0.0025896752097954354, and 0.004885813686996698\n",
      "Epoch [946/2000], Train Loss: 0.0032, Test Loss: 0.0031\n",
      "The metrics are: 0.00876869773492217, 0.0024520483954499164, and 0.0047727814720322686\n",
      "Epoch [947/2000], Train Loss: 0.0032, Test Loss: 0.0028\n",
      "The metrics are: 0.00831954941774408, 0.002336985431611538, and 0.0046695569374909\n",
      "Epoch [948/2000], Train Loss: 0.0029, Test Loss: 0.0026\n",
      "The metrics are: 0.008483968985577425, 0.0023089771469434104, and 0.00459783539796869\n",
      "Epoch [949/2000], Train Loss: 0.0029, Test Loss: 0.0027\n",
      "The metrics are: 0.008388567715883255, 0.0022756049099067845, and 0.004546797291065256\n",
      "Epoch [950/2000], Train Loss: 0.0028, Test Loss: 0.0026\n",
      "The metrics are: 0.008463211357593536, 0.002262741094455123, and 0.0044998531229794025\n",
      "Epoch [951/2000], Train Loss: 0.0029, Test Loss: 0.0026\n",
      "The metrics are: 0.008403022307902575, 0.002257088664919138, and 0.004433744819834828\n",
      "Epoch [952/2000], Train Loss: 0.0028, Test Loss: 0.0026\n",
      "The metrics are: 0.0081952513816456, 0.00222960797448953, and 0.004377038528521855\n",
      "Epoch [953/2000], Train Loss: 0.0027, Test Loss: 0.0026\n",
      "The metrics are: 0.008087451414515575, 0.002183312472576896, and 0.004322540946304798\n",
      "Epoch [954/2000], Train Loss: 0.0027, Test Loss: 0.0024\n",
      "The metrics are: 0.007958590829124054, 0.002173843987596532, and 0.004260441210741798\n",
      "Epoch [955/2000], Train Loss: 0.0026, Test Loss: 0.0024\n",
      "The metrics are: 0.007806563284248114, 0.0021455329454814396, and 0.004216446230808894\n",
      "Epoch [956/2000], Train Loss: 0.0026, Test Loss: 0.0024\n",
      "The metrics are: 0.007535846903920174, 0.0021155337259794274, and 0.004149687398845951\n",
      "Epoch [957/2000], Train Loss: 0.0025, Test Loss: 0.0023\n",
      "The metrics are: 0.0073718636607130366, 0.0020893434217820563, and 0.004099606691549222\n",
      "Epoch [958/2000], Train Loss: 0.0025, Test Loss: 0.0023\n",
      "The metrics are: 0.007216155684242646, 0.00207422060581545, and 0.004042045601333181\n",
      "Epoch [959/2000], Train Loss: 0.0024, Test Loss: 0.0023\n",
      "The metrics are: 0.007330453954637051, 0.002063264138996601, and 0.004000439619024594\n",
      "Epoch [960/2000], Train Loss: 0.0025, Test Loss: 0.0023\n",
      "The metrics are: 0.0071874128965040045, 0.0020486561891933284, and 0.003945049674560626\n",
      "Epoch [961/2000], Train Loss: 0.0024, Test Loss: 0.0023\n",
      "The metrics are: 0.007276008526484172, 0.0020440265458698073, and 0.0039012976145992675\n",
      "Epoch [962/2000], Train Loss: 0.0025, Test Loss: 0.0023\n",
      "The metrics are: 0.007373177446424961, 0.002047927933745086, and 0.0038457721627006927\n",
      "Epoch [963/2000], Train Loss: 0.0024, Test Loss: 0.0024\n",
      "The metrics are: 0.007312914667030175, 0.0020350816193968058, and 0.003803527137885491\n",
      "Epoch [964/2000], Train Loss: 0.0025, Test Loss: 0.0024\n",
      "The metrics are: 0.007210784281293551, 0.0020051521714776754, and 0.003763824778919419\n",
      "Epoch [965/2000], Train Loss: 0.0024, Test Loss: 0.0023\n",
      "The metrics are: 0.0074440608732402325, 0.0020047505774224796, and 0.0037262735422700644\n",
      "Epoch [966/2000], Train Loss: 0.0024, Test Loss: 0.0023\n",
      "The metrics are: 0.0072094229981303215, 0.00198277171390752, and 0.003688277443870902\n",
      "Epoch [967/2000], Train Loss: 0.0024, Test Loss: 0.0022\n",
      "The metrics are: 0.006963361209879319, 0.001958647354816397, and 0.0036559732786069312\n",
      "Epoch [968/2000], Train Loss: 0.0022, Test Loss: 0.0022\n",
      "The metrics are: 0.006717971370865901, 0.0019283018385370572, and 0.00361438716451327\n",
      "Epoch [969/2000], Train Loss: 0.0023, Test Loss: 0.0021\n",
      "The metrics are: 0.006461054086685181, 0.0019074797552699845, and 0.0035613966174423695\n",
      "Epoch [970/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.006630379085739453, 0.0019117031091203291, and 0.003523800289258361\n",
      "Epoch [971/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.006509988258282344, 0.0019018266272420685, and 0.0034723312128335238\n",
      "Epoch [972/2000], Train Loss: 0.0022, Test Loss: 0.0022\n",
      "The metrics are: 0.006687645645191272, 0.0018938447271163266, and 0.003452984926601251\n",
      "Epoch [973/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.00669907017921408, 0.0018901819906507928, and 0.0034112064943959317\n",
      "Epoch [974/2000], Train Loss: 0.0023, Test Loss: 0.0022\n",
      "The metrics are: 0.00640126255651315, 0.0018611526660000284, and 0.0033735824593653283\n",
      "Epoch [975/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.006485967586437861, 0.001856007690851887, and 0.0033486949590345225\n",
      "Epoch [976/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.0065805089349548025, 0.0018557136645540595, and 0.003315440301472942\n",
      "Epoch [977/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.006445946637541056, 0.001837800412128369, and 0.0032727126963436604\n",
      "Epoch [978/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.00638099480420351, 0.0018328699516132474, and 0.003241204113389055\n",
      "Epoch [979/2000], Train Loss: 0.0022, Test Loss: 0.0021\n",
      "The metrics are: 0.006402711073557536, 0.0018430683606614668, and 0.003204268558571736\n",
      "Epoch [980/2000], Train Loss: 0.0022, Test Loss: 0.0022\n",
      "The metrics are: 0.00619480712339282, 0.0017885451282685, and 0.0031852740018318095\n",
      "Epoch [981/2000], Train Loss: 0.0021, Test Loss: 0.0020\n",
      "The metrics are: 0.005889977949361007, 0.001757733019379278, and 0.0031658972147852182\n",
      "Epoch [982/2000], Train Loss: 0.0020, Test Loss: 0.0019\n",
      "The metrics are: 0.005836694656560819, 0.001754042614872257, and 0.0031198085440943637\n",
      "Epoch [983/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.00601986547311147, 0.0017541383470719059, and 0.0031010755337774754\n",
      "Epoch [984/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.006147490969548623, 0.0017616890060404937, and 0.0030687883651504913\n",
      "Epoch [985/2000], Train Loss: 0.0020, Test Loss: 0.0021\n",
      "The metrics are: 0.00600127549842, 0.001741314462075631, and 0.003027148855229219\n",
      "Epoch [986/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.005968927871435881, 0.001734948600642383, and 0.003005637632062038\n",
      "Epoch [987/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.006257849900672833, 0.0017394604316602151, and 0.002993454302971562\n",
      "Epoch [988/2000], Train Loss: 0.0020, Test Loss: 0.0021\n",
      "The metrics are: 0.006305338504413764, 0.001730561178798477, and 0.002965250052511692\n",
      "Epoch [989/2000], Train Loss: 0.0021, Test Loss: 0.0021\n",
      "The metrics are: 0.005859476514160633, 0.0017030686140060425, and 0.0029384410784890256\n",
      "Epoch [990/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.0056649007213612395, 0.0016895408043637872, and 0.0028959582559764385\n",
      "Epoch [991/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.00586792454123497, 0.001692271054101487, and 0.0028758319094777107\n",
      "Epoch [992/2000], Train Loss: 0.0019, Test Loss: 0.0020\n",
      "The metrics are: 0.005892792561401923, 0.0016849819803610444, and 0.002855093606437246\n",
      "Epoch [993/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.005758261463294427, 0.0016796689790983994, and 0.00282779677460591\n",
      "Epoch [994/2000], Train Loss: 0.0020, Test Loss: 0.0020\n",
      "The metrics are: 0.005692583664009969, 0.0016734820092096925, and 0.002809773199260235\n",
      "Epoch [995/2000], Train Loss: 0.0019, Test Loss: 0.0020\n",
      "The metrics are: 0.005619887883464496, 0.001656356849707663, and 0.0027798062656074762\n",
      "Epoch [996/2000], Train Loss: 0.0019, Test Loss: 0.0020\n",
      "The metrics are: 0.005660719859103362, 0.0016563209937885404, and 0.0027536734317739806\n",
      "Epoch [997/2000], Train Loss: 0.0019, Test Loss: 0.0020\n",
      "The metrics are: 0.005621397712578376, 0.0016384832561016083, and 0.0027255975486089787\n",
      "Epoch [998/2000], Train Loss: 0.0019, Test Loss: 0.0019\n",
      "The metrics are: 0.005608542822301388, 0.0016209365955243509, and 0.00271528959274292\n",
      "Epoch [999/2000], Train Loss: 0.0019, Test Loss: 0.0019\n",
      "The metrics are: 0.005451226917405923, 0.0016053729535390933, and 0.0026886146515607834\n",
      "Epoch [1000/2000], Train Loss: 0.0018, Test Loss: 0.0019\n",
      "The metrics are: 0.005238378730913003, 0.0015847243291015427, and 0.002676965125525991\n",
      "Epoch [1001/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.005333008399854104, 0.0015888568401957552, and 0.0026415239553898573\n",
      "Epoch [1002/2000], Train Loss: 0.0018, Test Loss: 0.0019\n",
      "The metrics are: 0.005439314059913158, 0.0015948227373883128, and 0.0026230490766465664\n",
      "Epoch [1003/2000], Train Loss: 0.0018, Test Loss: 0.0019\n",
      "The metrics are: 0.0054284386957685156, 0.0015749814144025247, and 0.002606891794130206\n",
      "Epoch [1004/2000], Train Loss: 0.0018, Test Loss: 0.0019\n",
      "The metrics are: 0.005326577307035525, 0.0015642217282826703, and 0.002575587791701158\n",
      "Epoch [1005/2000], Train Loss: 0.0018, Test Loss: 0.0019\n",
      "The metrics are: 0.005367896830042203, 0.0015674288927887876, and 0.0025482551039506993\n",
      "Epoch [1006/2000], Train Loss: 0.0018, Test Loss: 0.0019\n",
      "The metrics are: 0.005076369736343622, 0.001532703056000173, and 0.0025283024491121373\n",
      "Epoch [1007/2000], Train Loss: 0.0018, Test Loss: 0.0018\n",
      "The metrics are: 0.005195968473951022, 0.0015318667283281684, and 0.0025067086486766734\n",
      "Epoch [1008/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.005261857993900776, 0.0015444465291996796, and 0.002472058249016603\n",
      "Epoch [1009/2000], Train Loss: 0.0017, Test Loss: 0.0020\n",
      "The metrics are: 0.005530603850881259, 0.0015602619775260489, and 0.0024566639525194964\n",
      "Epoch [1010/2000], Train Loss: 0.0018, Test Loss: 0.0020\n",
      "The metrics are: 0.005527494164804618, 0.0015611919031168024, and 0.0024361721395204463\n",
      "Epoch [1011/2000], Train Loss: 0.0018, Test Loss: 0.0020\n",
      "The metrics are: 0.005176663243522246, 0.0015158370370045304, and 0.0024138184574743113\n",
      "Epoch [1012/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.00548440699155132, 0.0015435356569165986, and 0.00239085437109073\n",
      "Epoch [1013/2000], Train Loss: 0.0018, Test Loss: 0.0020\n",
      "The metrics are: 0.005761533199499051, 0.0015720408021782835, and 0.0023771130945533514\n",
      "Epoch [1014/2000], Train Loss: 0.0019, Test Loss: 0.0021\n",
      "The metrics are: 0.0053793382830917835, 0.001522384079483648, and 0.0023803350050002337\n",
      "Epoch [1015/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.005073421634733677, 0.0014959583058953285, and 0.002350232641523083\n",
      "Epoch [1016/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.004851227160543203, 0.0014682923210784793, and 0.002319557980323831\n",
      "Epoch [1017/2000], Train Loss: 0.0017, Test Loss: 0.0018\n",
      "The metrics are: 0.0047736382111907005, 0.0014508162857964635, and 0.0022948335390537977\n",
      "Epoch [1018/2000], Train Loss: 0.0017, Test Loss: 0.0018\n",
      "The metrics are: 0.004799389746040106, 0.001469086001937588, and 0.0022790522004167237\n",
      "Epoch [1019/2000], Train Loss: 0.0015, Test Loss: 0.0019\n",
      "The metrics are: 0.005223983433097601, 0.0015270002962400515, and 0.0022728598366181054\n",
      "Epoch [1020/2000], Train Loss: 0.0017, Test Loss: 0.0021\n",
      "The metrics are: 0.005091155568758647, 0.0014754256311183174, and 0.002265291754156351\n",
      "Epoch [1021/2000], Train Loss: 0.0018, Test Loss: 0.0019\n",
      "The metrics are: 0.004700658532480399, 0.0014477077250679333, and 0.002233504860972365\n",
      "Epoch [1022/2000], Train Loss: 0.0017, Test Loss: 0.0018\n",
      "The metrics are: 0.004735142070179184, 0.0014295577226827543, and 0.002231677140419682\n",
      "Epoch [1023/2000], Train Loss: 0.0016, Test Loss: 0.0018\n",
      "The metrics are: 0.004946346782768766, 0.0014498928794637322, and 0.002212770205611984\n",
      "Epoch [1024/2000], Train Loss: 0.0016, Test Loss: 0.0019\n",
      "The metrics are: 0.005043532776956757, 0.0014650858550642927, and 0.0021938595455139875\n",
      "Epoch [1025/2000], Train Loss: 0.0017, Test Loss: 0.0020\n",
      "The metrics are: 0.004814372087518374, 0.0014336065699656804, and 0.002189907090117534\n",
      "Epoch [1026/2000], Train Loss: 0.0016, Test Loss: 0.0019\n",
      "The metrics are: 0.00485645894271632, 0.001447651496467491, and 0.0021780934184789658\n",
      "Epoch [1027/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.004853918760394056, 0.0014419556440164645, and 0.002171104308217764\n",
      "Epoch [1028/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.004662014466399948, 0.0014550047538553674, and 0.002151386385473112\n",
      "Epoch [1029/2000], Train Loss: 0.0017, Test Loss: 0.0020\n",
      "The metrics are: 0.004725880377615492, 0.0014406917228673894, and 0.0021442934327448406\n",
      "Epoch [1030/2000], Train Loss: 0.0017, Test Loss: 0.0019\n",
      "The metrics are: 0.004971222952008247, 0.0014641884481534362, and 0.00213834794703871\n",
      "Epoch [1031/2000], Train Loss: 0.0016, Test Loss: 0.0020\n",
      "The metrics are: 0.005204022396355867, 0.0015171190801387031, and 0.00213240886417528\n",
      "Epoch [1032/2000], Train Loss: 0.0018, Test Loss: 0.0021\n",
      "The metrics are: 0.005019554169848561, 0.001433353832301994, and 0.0021224983114128313\n",
      "Epoch [1033/2000], Train Loss: 0.0017, Test Loss: 0.0018\n",
      "The metrics are: 0.004634383755425612, 0.001407755344795684, and 0.0021003367146477103\n",
      "Epoch [1034/2000], Train Loss: 0.0016, Test Loss: 0.0018\n",
      "The metrics are: 0.004515885375440121, 0.0013812028337270021, and 0.002095332408013443\n",
      "Epoch [1035/2000], Train Loss: 0.0016, Test Loss: 0.0018\n",
      "The metrics are: 0.004367229373504718, 0.0013605251054589946, and 0.0020902872007961073\n",
      "Epoch [1036/2000], Train Loss: 0.0015, Test Loss: 0.0017\n",
      "The metrics are: 0.00445137716208895, 0.0013777239558597405, and 0.0020773750729858875\n",
      "Epoch [1037/2000], Train Loss: 0.0016, Test Loss: 0.0019\n",
      "The metrics are: 0.004493779347588618, 0.0014161176513880491, and 0.0020665053743869066\n",
      "Epoch [1038/2000], Train Loss: 0.0016, Test Loss: 0.0020\n",
      "The metrics are: 0.004958288588871558, 0.001436468563042581, and 0.0020617221016436815\n",
      "Epoch [1039/2000], Train Loss: 0.0017, Test Loss: 0.0021\n",
      "The metrics are: 0.005479023947070043, 0.0014737993478775024, and 0.0020748199118922153\n",
      "Epoch [1040/2000], Train Loss: 0.0017, Test Loss: 0.0022\n",
      "The metrics are: 0.005124805029481649, 0.0014621606484676402, and 0.002058533097927769\n",
      "Epoch [1041/2000], Train Loss: 0.0018, Test Loss: 0.0022\n",
      "The metrics are: 0.005292892300834258, 0.0014579856069758534, and 0.0020569167099893093\n",
      "Epoch [1042/2000], Train Loss: 0.0018, Test Loss: 0.0021\n",
      "The metrics are: 0.00523299917889138, 0.0014943109126761556, and 0.002045645184504489\n",
      "Epoch [1043/2000], Train Loss: 0.0017, Test Loss: 0.0022\n",
      "The metrics are: 0.005130514580135544, 0.0014202480282013614, and 0.0020577733715375266\n",
      "Epoch [1044/2000], Train Loss: 0.0017, Test Loss: 0.0020\n",
      "The metrics are: 0.004232528309027354, 0.0013810365926474333, and 0.0020195746328681707\n",
      "Epoch [1045/2000], Train Loss: 0.0016, Test Loss: 0.0018\n",
      "The metrics are: 0.003975391465549667, 0.0013218286912888288, and 0.0019986488623544574\n",
      "Epoch [1046/2000], Train Loss: 0.0015, Test Loss: 0.0017\n",
      "The metrics are: 0.0038479467233022055, 0.0013092176135008533, and 0.001984950853511691\n",
      "Epoch [1047/2000], Train Loss: 0.0015, Test Loss: 0.0017\n",
      "The metrics are: 0.0040812822214017315, 0.00132313782038788, and 0.001973391122495135\n",
      "Epoch [1048/2000], Train Loss: 0.0014, Test Loss: 0.0018\n",
      "The metrics are: 0.003882001619786024, 0.0013017091744889815, and 0.0019614988705143332\n",
      "Epoch [1049/2000], Train Loss: 0.0015, Test Loss: 0.0017\n",
      "The metrics are: 0.0036518569104373455, 0.001286573203591009, and 0.001948469124423961\n",
      "Epoch [1050/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.0038824353832751513, 0.0013143834269916017, and 0.0019346250919625163\n",
      "Epoch [1051/2000], Train Loss: 0.0014, Test Loss: 0.0018\n",
      "The metrics are: 0.004195056467627485, 0.0013119421200826764, and 0.0019283782069881756\n",
      "Epoch [1052/2000], Train Loss: 0.0015, Test Loss: 0.0018\n",
      "The metrics are: 0.004328609521811207, 0.0013351972059657176, and 0.0019211993397523959\n",
      "Epoch [1053/2000], Train Loss: 0.0015, Test Loss: 0.0019\n",
      "The metrics are: 0.004257818451151252, 0.0013259380745391052, and 0.0019097294037540753\n",
      "Epoch [1054/2000], Train Loss: 0.0015, Test Loss: 0.0019\n",
      "The metrics are: 0.004237196175381541, 0.0013217271383230884, and 0.0019101050371925037\n",
      "Epoch [1055/2000], Train Loss: 0.0015, Test Loss: 0.0019\n",
      "The metrics are: 0.004148196429014206, 0.001302263039785127, and 0.0018994826435421903\n",
      "Epoch [1056/2000], Train Loss: 0.0015, Test Loss: 0.0018\n",
      "The metrics are: 0.003956490972389777, 0.001265797143181165, and 0.0018789282767102122\n",
      "Epoch [1057/2000], Train Loss: 0.0014, Test Loss: 0.0017\n",
      "The metrics are: 0.003854185420398911, 0.0012663350595782201, and 0.0018687804695218801\n",
      "Epoch [1058/2000], Train Loss: 0.0014, Test Loss: 0.0017\n",
      "The metrics are: 0.003994468754778306, 0.0012549736226598422, and 0.0018629711509371798\n",
      "Epoch [1059/2000], Train Loss: 0.0014, Test Loss: 0.0017\n",
      "The metrics are: 0.003924662557741006, 0.0012489756336435676, and 0.0018430285854265094\n",
      "Epoch [1060/2000], Train Loss: 0.0014, Test Loss: 0.0017\n",
      "The metrics are: 0.00397941330447793, 0.0012706267880275846, and 0.001833585323765874\n",
      "Epoch [1061/2000], Train Loss: 0.0015, Test Loss: 0.0018\n",
      "The metrics are: 0.003954858131085833, 0.0012622345238924026, and 0.001826386161458989\n",
      "Epoch [1062/2000], Train Loss: 0.0014, Test Loss: 0.0018\n",
      "The metrics are: 0.0040886263983945055, 0.0012520980477953951, and 0.0018257243015492957\n",
      "Epoch [1063/2000], Train Loss: 0.0015, Test Loss: 0.0017\n",
      "The metrics are: 0.004010484864314397, 0.001249379866446058, and 0.0018105367974688609\n",
      "Epoch [1064/2000], Train Loss: 0.0014, Test Loss: 0.0017\n",
      "The metrics are: 0.003888007408628861, 0.0012183964330082138, and 0.0018105546478182077\n",
      "Epoch [1065/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.0038767168298363686, 0.0012009633937850595, and 0.0018071068140367668\n",
      "Epoch [1066/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0038564965749780336, 0.0012148102978244424, and 0.0017884864549462993\n",
      "Epoch [1067/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.003952485586827, 0.0012109959498047829, and 0.0017802444053813815\n",
      "Epoch [1068/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.003933439962565899, 0.001201886838922898, and 0.001774755772203207\n",
      "Epoch [1069/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.003969902095074455, 0.001194310956634581, and 0.0017705099113906424\n",
      "Epoch [1070/2000], Train Loss: 0.0014, Test Loss: 0.0015\n",
      "The metrics are: 0.0038904962905993066, 0.0012366199710716803, and 0.0017381012439727783\n",
      "Epoch [1071/2000], Train Loss: 0.0013, Test Loss: 0.0018\n",
      "The metrics are: 0.004132815171033144, 0.0012228820317735274, and 0.0017474584359054763\n",
      "Epoch [1072/2000], Train Loss: 0.0015, Test Loss: 0.0017\n",
      "The metrics are: 0.004128457124655445, 0.0012164212142427762, and 0.0017391993897035718\n",
      "Epoch [1073/2000], Train Loss: 0.0015, Test Loss: 0.0017\n",
      "The metrics are: 0.003990461273739736, 0.001182181100981931, and 0.0017331386140237253\n",
      "Epoch [1074/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.004030012448007862, 0.0011784837891658146, and 0.0017251257474223773\n",
      "Epoch [1075/2000], Train Loss: 0.0014, Test Loss: 0.0015\n",
      "The metrics are: 0.003682036961739262, 0.0011777366744354367, and 0.0017057682077089946\n",
      "Epoch [1076/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.003815464675426483, 0.0011590862413868308, and 0.001715578759709994\n",
      "Epoch [1077/2000], Train Loss: 0.0014, Test Loss: 0.0015\n",
      "The metrics are: 0.0035478599990407624, 0.0011568859141940873, and 0.0016960356927787263\n",
      "Epoch [1078/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0034539999905973673, 0.0011475946521386504, and 0.0016983930254355073\n",
      "Epoch [1079/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.003356284461915493, 0.0011132384339968364, and 0.00169518884892265\n",
      "Epoch [1080/2000], Train Loss: 0.0013, Test Loss: 0.0013\n",
      "The metrics are: 0.0032379671465605497, 0.0011167855700477958, and 0.0016627132814998429\n",
      "Epoch [1081/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.0038215365105619035, 0.0011560491596659024, and 0.0016662485819930832\n",
      "Epoch [1082/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.003887664216260115, 0.0011646151930714648, and 0.0016690032013381522\n",
      "Epoch [1083/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.004239502362906933, 0.0011760753113776445, and 0.0016727496016149719\n",
      "Epoch [1084/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.0038770302974929414, 0.0011764894394824903, and 0.0016473345458507538\n",
      "Epoch [1085/2000], Train Loss: 0.0014, Test Loss: 0.0016\n",
      "The metrics are: 0.0037431983898083367, 0.0011433765369777877, and 0.0016531108024840553\n",
      "Epoch [1086/2000], Train Loss: 0.0014, Test Loss: 0.0015\n",
      "The metrics are: 0.003486507494623462, 0.0011118002779160936, and 0.0016429721533010404\n",
      "Epoch [1087/2000], Train Loss: 0.0013, Test Loss: 0.0014\n",
      "The metrics are: 0.003599917438502113, 0.001126795735520621, and 0.0016328156925737858\n",
      "Epoch [1088/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.00370392226614058, 0.0011315514566376805, and 0.0016218988069643576\n",
      "Epoch [1089/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.003557762751976649, 0.0011062696188067396, and 0.001614442327991128\n",
      "Epoch [1090/2000], Train Loss: 0.0013, Test Loss: 0.0014\n",
      "The metrics are: 0.0031827243510633707, 0.0010755500989034772, and 0.0015951763295258086\n",
      "Epoch [1091/2000], Train Loss: 0.0012, Test Loss: 0.0013\n",
      "The metrics are: 0.003169974156965812, 0.0010980871738865972, and 0.001578764369090398\n",
      "Epoch [1092/2000], Train Loss: 0.0012, Test Loss: 0.0015\n",
      "The metrics are: 0.0035010609620561204, 0.0011019563147177298, and 0.0015807905001565814\n",
      "Epoch [1093/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0036548832431435585, 0.001108750778560837, and 0.0015890362362066905\n",
      "Epoch [1094/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0033814255924274525, 0.001083198197496434, and 0.001569942416002353\n",
      "Epoch [1095/2000], Train Loss: 0.0013, Test Loss: 0.0014\n",
      "The metrics are: 0.003191572381183505, 0.0010668998196100195, and 0.0015611527875686686\n",
      "Epoch [1096/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.003385876693452398, 0.0010762668680399656, and 0.0015437723680709798\n",
      "Epoch [1097/2000], Train Loss: 0.0013, Test Loss: 0.0014\n",
      "The metrics are: 0.003279547051837047, 0.0010801348835229874, and 0.0015425109692538779\n",
      "Epoch [1098/2000], Train Loss: 0.0012, Test Loss: 0.0015\n",
      "The metrics are: 0.0035204941717286906, 0.001096796089162429, and 0.0015281197459747393\n",
      "Epoch [1099/2000], Train Loss: 0.0012, Test Loss: 0.0016\n",
      "The metrics are: 0.003668091492727399, 0.0011057738059510787, and 0.0015198487089946866\n",
      "Epoch [1100/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.0038780091951290765, 0.0010954208167580266, and 0.0015171549748629332\n",
      "Epoch [1101/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.003584563576926788, 0.0010753820921915274, and 0.0015007910163452227\n",
      "Epoch [1102/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0036327419026444354, 0.0010743968887254596, and 0.0015016448839257162\n",
      "Epoch [1103/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.003564706693092982, 0.0010652158331746857, and 0.0014854485634714365\n",
      "Epoch [1104/2000], Train Loss: 0.0012, Test Loss: 0.0015\n",
      "The metrics are: 0.003356719467168053, 0.0010488458598653476, and 0.0014898389345034957\n",
      "Epoch [1105/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.0030434977573653064, 0.001019295285611103, and 0.0014680114885171254\n",
      "Epoch [1106/2000], Train Loss: 0.0012, Test Loss: 0.0013\n",
      "The metrics are: 0.002923261529455582, 0.001012343040201813, and 0.0014585058282439907\n",
      "Epoch [1107/2000], Train Loss: 0.0011, Test Loss: 0.0013\n",
      "The metrics are: 0.003148024125645558, 0.0010311811541517575, and 0.0014454562139386933\n",
      "Epoch [1108/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.002932831489791473, 0.0010235147783532739, and 0.0014347652904689312\n",
      "Epoch [1109/2000], Train Loss: 0.0011, Test Loss: 0.0014\n",
      "The metrics are: 0.003227115919192632, 0.0010664064320735633, and 0.001438733112687866\n",
      "Epoch [1110/2000], Train Loss: 0.0012, Test Loss: 0.0015\n",
      "The metrics are: 0.0034567095960179963, 0.0010870516610642273, and 0.0014402533415704966\n",
      "Epoch [1111/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.003537481495489677, 0.001076355188464125, and 0.001431971788406372\n",
      "Epoch [1112/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.0033394768834114075, 0.0010386449672902625, and 0.0014196125945697229\n",
      "Epoch [1113/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.003092273138463497, 0.0010199339594691992, and 0.001394319503257672\n",
      "Epoch [1114/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.0030403463946034512, 0.0010189521902551253, and 0.001397970753411452\n",
      "Epoch [1115/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.0031582788409044347, 0.0010200938171086211, and 0.0013801940173531573\n",
      "Epoch [1116/2000], Train Loss: 0.0011, Test Loss: 0.0015\n",
      "The metrics are: 0.0033219553685436645, 0.0010267259009803336, and 0.0013785677729174495\n",
      "Epoch [1117/2000], Train Loss: 0.0012, Test Loss: 0.0015\n",
      "The metrics are: 0.0034299475761751332, 0.0010533361540486415, and 0.0013627029644946258\n",
      "Epoch [1118/2000], Train Loss: 0.0012, Test Loss: 0.0017\n",
      "The metrics are: 0.0035355858659992614, 0.0010461376902336876, and 0.0013658031433199842\n",
      "Epoch [1119/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.003682865450779597, 0.0010532617840605478, and 0.0013734296274681885\n",
      "Epoch [1120/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.0034192487752685943, 0.0010452175241274138, and 0.0013644639790679018\n",
      "Epoch [1121/2000], Train Loss: 0.0012, Test Loss: 0.0016\n",
      "The metrics are: 0.003446185728535056, 0.0010540571723443766, and 0.0013882307879005869\n",
      "Epoch [1122/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.0034001899572710195, 0.0010423872154206038, and 0.001388129428960383\n",
      "Epoch [1123/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0034917152176300683, 0.0010519086111647387, and 0.0014089306350797415\n",
      "Epoch [1124/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0032043217991789183, 0.0010488644475117326, and 0.001414393230030934\n",
      "Epoch [1125/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.0029636756516993046, 0.0010080500117813547, and 0.0013682885328307748\n",
      "Epoch [1126/2000], Train Loss: 0.0013, Test Loss: 0.0014\n",
      "The metrics are: 0.0029701432213187218, 0.001036561404665311, and 0.0013296316998700302\n",
      "Epoch [1127/2000], Train Loss: 0.0013, Test Loss: 0.0015\n",
      "The metrics are: 0.003040965103233854, 0.0009909027139656246, and 0.0012901702430099249\n",
      "Epoch [1128/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.0028435338754206896, 0.0010080831319404144, and 0.0012963639261821906\n",
      "Epoch [1129/2000], Train Loss: 0.0012, Test Loss: 0.0015\n",
      "The metrics are: 0.0037861287128180265, 0.001114805752877146, and 0.0012848250335082412\n",
      "Epoch [1130/2000], Train Loss: 0.0013, Test Loss: 0.0019\n",
      "The metrics are: 0.0039497305018206435, 0.001072230263768385, and 0.0013327539199963212\n",
      "Epoch [1131/2000], Train Loss: 0.0013, Test Loss: 0.0020\n",
      "The metrics are: 0.0044080696534365416, 0.0010759507616360982, and 0.0013136353809386492\n",
      "Epoch [1132/2000], Train Loss: 0.0014, Test Loss: 0.0021\n",
      "The metrics are: 0.00447571052548786, 0.0011033669773799677, and 0.0013076958324139316\n",
      "Epoch [1133/2000], Train Loss: 0.0014, Test Loss: 0.0021\n",
      "The metrics are: 0.00394037738442421, 0.0010294188590099413, and 0.0012294564318532746\n",
      "Epoch [1134/2000], Train Loss: 0.0013, Test Loss: 0.0016\n",
      "The metrics are: 0.0035968724793444076, 0.0009893670794554055, and 0.0012275979776556294\n",
      "Epoch [1135/2000], Train Loss: 0.0012, Test Loss: 0.0014\n",
      "The metrics are: 0.0032788668759167194, 0.0009619186942776045, and 0.0012002754568432767\n",
      "Epoch [1136/2000], Train Loss: 0.0011, Test Loss: 0.0013\n",
      "The metrics are: 0.002722282583514849, 0.0009211225745578607, and 0.001187785140549143\n",
      "Epoch [1137/2000], Train Loss: 0.0011, Test Loss: 0.0012\n",
      "The metrics are: 0.002691565779969096, 0.0008995188788200418, and 0.0011693008709698915\n",
      "Epoch [1138/2000], Train Loss: 0.0010, Test Loss: 0.0012\n",
      "The metrics are: 0.0027130125866581998, 0.0009003679927748939, and 0.0011647037463262677\n",
      "Epoch [1139/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.0028394160326570272, 0.0008921333161803583, and 0.0011453060433268547\n",
      "Epoch [1140/2000], Train Loss: 0.0010, Test Loss: 0.0012\n",
      "The metrics are: 0.0028729085655262074, 0.0009019511829440793, and 0.0011482644670953353\n",
      "Epoch [1141/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.0028869178301344314, 0.0009141489863395691, and 0.0011330069974064827\n",
      "Epoch [1142/2000], Train Loss: 0.0011, Test Loss: 0.0013\n",
      "The metrics are: 0.0030830681013564267, 0.0009099531453102827, and 0.001139807825287183\n",
      "Epoch [1143/2000], Train Loss: 0.0010, Test Loss: 0.0014\n",
      "The metrics are: 0.002796339802443981, 0.0009076926313961545, and 0.001116549945436418\n",
      "Epoch [1144/2000], Train Loss: 0.0011, Test Loss: 0.0013\n",
      "The metrics are: 0.0028245352441444993, 0.0009053517521048585, and 0.0011130493755141895\n",
      "Epoch [1145/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.0028445822341988483, 0.0009114148754936954, and 0.0011027626460418105\n",
      "Epoch [1146/2000], Train Loss: 0.0010, Test Loss: 0.0014\n",
      "The metrics are: 0.003105873785292109, 0.0009370980939517418, and 0.001104991106937329\n",
      "Epoch [1147/2000], Train Loss: 0.0011, Test Loss: 0.0015\n",
      "The metrics are: 0.0035907933488488197, 0.0009856114047579467, and 0.0011133291215325396\n",
      "Epoch [1148/2000], Train Loss: 0.0011, Test Loss: 0.0017\n",
      "The metrics are: 0.003649491428708037, 0.0009585579779619972, and 0.0011118371427680056\n",
      "Epoch [1149/2000], Train Loss: 0.0012, Test Loss: 0.0017\n",
      "The metrics are: 0.0034514154928425946, 0.0009570283388408521, and 0.0010930755912947159\n",
      "Epoch [1150/2000], Train Loss: 0.0012, Test Loss: 0.0015\n",
      "The metrics are: 0.003397467313334346, 0.000931359730505695, and 0.0010919517565829058\n",
      "Epoch [1151/2000], Train Loss: 0.0011, Test Loss: 0.0014\n",
      "The metrics are: 0.0031229530771573386, 0.0009448534110561013, and 0.0010803782109481592\n",
      "Epoch [1152/2000], Train Loss: 0.0011, Test Loss: 0.0014\n",
      "The metrics are: 0.0029393440733353295, 0.0009009026301403841, and 0.0010723739202755194\n",
      "Epoch [1153/2000], Train Loss: 0.0011, Test Loss: 0.0013\n",
      "The metrics are: 0.002826158384171625, 0.0008714248542673886, and 0.001074167957995087\n",
      "Epoch [1154/2000], Train Loss: 0.0010, Test Loss: 0.0012\n",
      "The metrics are: 0.0024198112466062107, 0.0008561840901772181, and 0.0010528246833321948\n",
      "Epoch [1155/2000], Train Loss: 0.0010, Test Loss: 0.0011\n",
      "The metrics are: 0.0023299272482593856, 0.0008444562166308364, and 0.0010511974881713588\n",
      "Epoch [1156/2000], Train Loss: 0.0009, Test Loss: 0.0011\n",
      "The metrics are: 0.0024240089502806463, 0.0008495177413957814, and 0.0010579853357436757\n",
      "Epoch [1157/2000], Train Loss: 0.0009, Test Loss: 0.0012\n",
      "The metrics are: 0.0025677658462276063, 0.0008682526531629264, and 0.0010487886029295623\n",
      "Epoch [1158/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.002575762802734971, 0.0008624741070282956, and 0.0010344163165427744\n",
      "Epoch [1159/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.0025892674069230757, 0.0008794208018419644, and 0.0010279236594215035\n",
      "Epoch [1160/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.002794757252559066, 0.0009010535820076863, and 0.001038242286692063\n",
      "Epoch [1161/2000], Train Loss: 0.0010, Test Loss: 0.0015\n",
      "The metrics are: 0.0029342723234246173, 0.0008789470496897896, and 0.001028523101316144\n",
      "Epoch [1162/2000], Train Loss: 0.0011, Test Loss: 0.0015\n",
      "The metrics are: 0.003119137603789568, 0.0008913875790312886, and 0.0010166282881982625\n",
      "Epoch [1163/2000], Train Loss: 0.0011, Test Loss: 0.0015\n",
      "The metrics are: 0.0029442391047875085, 0.0009002017322927713, and 0.0010057617328129709\n",
      "Epoch [1164/2000], Train Loss: 0.0011, Test Loss: 0.0015\n",
      "The metrics are: 0.002942603857566913, 0.0008868738077580929, and 0.0009981104522012174\n",
      "Epoch [1165/2000], Train Loss: 0.0011, Test Loss: 0.0014\n",
      "The metrics are: 0.00290737790055573, 0.0008608983286345998, and 0.0009927120991051197\n",
      "Epoch [1166/2000], Train Loss: 0.0010, Test Loss: 0.0014\n",
      "The metrics are: 0.0027186068085332713, 0.0008445938195412358, and 0.0009699240132855872\n",
      "Epoch [1167/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.002821324005102118, 0.0008668241207487881, and 0.000974255749800553\n",
      "Epoch [1168/2000], Train Loss: 0.0010, Test Loss: 0.0014\n",
      "The metrics are: 0.002777415056092044, 0.0008501618479688963, and 0.0009639232885092497\n",
      "Epoch [1169/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.0026773649733513594, 0.0008479331736452878, and 0.000967842216293017\n",
      "Epoch [1170/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.0027861617660770812, 0.0008441803705257674, and 0.0009630764834582806\n",
      "Epoch [1171/2000], Train Loss: 0.0010, Test Loss: 0.0014\n",
      "The metrics are: 0.002529211613970498, 0.0008410265824447075, and 0.0009614692923302451\n",
      "Epoch [1172/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.0024425919788579145, 0.0008234884007833898, and 0.0009405289116936425\n",
      "Epoch [1173/2000], Train Loss: 0.0009, Test Loss: 0.0012\n",
      "The metrics are: 0.002518876804970205, 0.0008511235743450621, and 0.0009531004082721969\n",
      "Epoch [1174/2000], Train Loss: 0.0010, Test Loss: 0.0013\n",
      "The metrics are: 0.002725122651706139, 0.000879623209281514, and 0.000940353978270044\n",
      "Epoch [1175/2000], Train Loss: 0.0010, Test Loss: 0.0015\n",
      "The metrics are: 0.0029842244694009423, 0.00089549282953764, and 0.0009541575564071536\n",
      "Epoch [1176/2000], Train Loss: 0.0011, Test Loss: 0.0016\n",
      "The metrics are: 0.003021337635194262, 0.0008988748498571416, and 0.0009409439905236164\n",
      "Epoch [1177/2000], Train Loss: 0.0011, Test Loss: 0.0016\n",
      "The metrics are: 0.0035806697172423205, 0.0009571113041602075, and 0.000985368329565972\n",
      "Epoch [1178/2000], Train Loss: 0.0011, Test Loss: 0.0020\n",
      "The metrics are: 0.0037499343355496726, 0.000910803423418353, and 0.0009361559447521964\n",
      "Epoch [1179/2000], Train Loss: 0.0012, Test Loss: 0.0017\n",
      "The metrics are: 0.003459763635570804, 0.0008784866658970714, and 0.0009135699171262482\n",
      "Epoch [1180/2000], Train Loss: 0.0011, Test Loss: 0.0015\n",
      "The metrics are: 0.002894977185254296, 0.000832335208542645, and 0.0008969836829540631\n",
      "Epoch [1181/2000], Train Loss: 0.0010, Test Loss: 0.0012\n",
      "The metrics are: 0.00231449205117921, 0.0008070022255803148, and 0.0008934584717887143\n",
      "Epoch [1182/2000], Train Loss: 0.0009, Test Loss: 0.0011\n",
      "The metrics are: 0.0022628421041493616, 0.0007910384253288308, and 0.0008734371125077208\n",
      "Epoch [1183/2000], Train Loss: 0.0009, Test Loss: 0.0011\n",
      "The metrics are: 0.002193979686126113, 0.0007815534481778741, and 0.0008595251711085439\n",
      "Epoch [1184/2000], Train Loss: 0.0009, Test Loss: 0.0011\n",
      "The metrics are: 0.0020065377078329525, 0.0007562552345916629, and 0.0008435141838466128\n",
      "Epoch [1185/2000], Train Loss: 0.0008, Test Loss: 0.0010\n",
      "The metrics are: 0.001916192937642336, 0.0007560514495708048, and 0.0008397206935721139\n",
      "Epoch [1186/2000], Train Loss: 0.0008, Test Loss: 0.0011\n",
      "The metrics are: 0.0019670381443575025, 0.0007592127852452298, and 0.0008308013978724679\n",
      "Epoch [1187/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002144184351588289, 0.0007645935984328389, and 0.0008347663679160178\n",
      "Epoch [1188/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.002440962397182981, 0.0008076233595299224, and 0.0008435492442610363\n",
      "Epoch [1189/2000], Train Loss: 0.0009, Test Loss: 0.0015\n",
      "The metrics are: 0.002846884618823727, 0.000839498631345729, and 0.0008675846814488372\n",
      "Epoch [1190/2000], Train Loss: 0.0010, Test Loss: 0.0017\n",
      "The metrics are: 0.003176329657435417, 0.0008585408601599435, and 0.000838939236321797\n",
      "Epoch [1191/2000], Train Loss: 0.0010, Test Loss: 0.0017\n",
      "The metrics are: 0.00346512619095544, 0.0008932732550116876, and 0.0008470028406009078\n",
      "Epoch [1192/2000], Train Loss: 0.0011, Test Loss: 0.0018\n",
      "The metrics are: 0.003566004258270065, 0.00090955471387133, and 0.0008300608024001122\n",
      "Epoch [1193/2000], Train Loss: 0.0011, Test Loss: 0.0017\n",
      "The metrics are: 0.0034981444866086044, 0.0009013309997195998, and 0.0008243294820810357\n",
      "Epoch [1194/2000], Train Loss: 0.0012, Test Loss: 0.0016\n",
      "The metrics are: 0.0028862674177313843, 0.000829081671933333, and 0.0008000347685689727\n",
      "Epoch [1195/2000], Train Loss: 0.0011, Test Loss: 0.0014\n",
      "The metrics are: 0.0027101237404470644, 0.000784773340759178, and 0.0007952308127035698\n",
      "Epoch [1196/2000], Train Loss: 0.0010, Test Loss: 0.0012\n",
      "The metrics are: 0.0025654787508149943, 0.000764019088819623, and 0.000781355076469481\n",
      "Epoch [1197/2000], Train Loss: 0.0009, Test Loss: 0.0012\n",
      "The metrics are: 0.0023106489485750594, 0.0007715232010620335, and 0.0007735713346240421\n",
      "Epoch [1198/2000], Train Loss: 0.0009, Test Loss: 0.0012\n",
      "The metrics are: 0.0020426635552818575, 0.0007435131119564176, and 0.0007621581510951122\n",
      "Epoch [1199/2000], Train Loss: 0.0008, Test Loss: 0.0011\n",
      "The metrics are: 0.0018652953052272399, 0.0007253897492773831, and 0.000752537123238047\n",
      "Epoch [1200/2000], Train Loss: 0.0008, Test Loss: 0.0011\n",
      "The metrics are: 0.00193555459069709, 0.0007271290135880312, and 0.0007502285880036652\n",
      "Epoch [1201/2000], Train Loss: 0.0008, Test Loss: 0.0011\n",
      "The metrics are: 0.0020410106129323444, 0.000739642942789942, and 0.0007566141042237481\n",
      "Epoch [1202/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.0020231475743154683, 0.0007410522472734252, and 0.000750593530635039\n",
      "Epoch [1203/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002174138673581183, 0.000754230422899127, and 0.0007603843114338815\n",
      "Epoch [1204/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0023927572571362057, 0.0007678287414213022, and 0.0007653128704987466\n",
      "Epoch [1205/2000], Train Loss: 0.0009, Test Loss: 0.0014\n",
      "The metrics are: 0.0030736130817482867, 0.0008085392764769495, and 0.0007803878009629747\n",
      "Epoch [1206/2000], Train Loss: 0.0009, Test Loss: 0.0017\n",
      "The metrics are: 0.0030485698177168765, 0.0008222442702390254, and 0.0007503326633013785\n",
      "Epoch [1207/2000], Train Loss: 0.0010, Test Loss: 0.0015\n",
      "The metrics are: 0.0026420532570530972, 0.0007930998884451886, and 0.0007327792894405624\n",
      "Epoch [1208/2000], Train Loss: 0.0009, Test Loss: 0.0014\n",
      "The metrics are: 0.0023788133015235267, 0.0007783593997980157, and 0.0007249067227045695\n",
      "Epoch [1209/2000], Train Loss: 0.0009, Test Loss: 0.0013\n",
      "The metrics are: 0.0022165750075752535, 0.0007801345782354474, and 0.0007148302781085173\n",
      "Epoch [1210/2000], Train Loss: 0.0009, Test Loss: 0.0013\n",
      "The metrics are: 0.001980558503419161, 0.0007442029697510103, and 0.0006983467028476298\n",
      "Epoch [1211/2000], Train Loss: 0.0009, Test Loss: 0.0012\n",
      "The metrics are: 0.0020424473332241178, 0.0007316747990747293, and 0.0006957228179089725\n",
      "Epoch [1212/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.0019386776257306337, 0.0007211833144538105, and 0.0006957413085425893\n",
      "Epoch [1213/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002331394935026765, 0.0007592335459776223, and 0.0007068151414083937\n",
      "Epoch [1214/2000], Train Loss: 0.0008, Test Loss: 0.0015\n",
      "The metrics are: 0.002516183303669095, 0.0007792883358585337, and 0.0007089382852427661\n",
      "Epoch [1215/2000], Train Loss: 0.0009, Test Loss: 0.0015\n",
      "The metrics are: 0.0028659493351976075, 0.0007858461661574742, and 0.0007110780376630524\n",
      "Epoch [1216/2000], Train Loss: 0.0010, Test Loss: 0.0016\n",
      "The metrics are: 0.002778774593025446, 0.0007963902899064124, and 0.0007026446304128816\n",
      "Epoch [1217/2000], Train Loss: 0.0010, Test Loss: 0.0016\n",
      "The metrics are: 0.0029705645671735206, 0.0008062073223603269, and 0.0007061231299303472\n",
      "Epoch [1218/2000], Train Loss: 0.0010, Test Loss: 0.0016\n",
      "The metrics are: 0.003025831460642318, 0.0007978287564280132, and 0.0006994400367451211\n",
      "Epoch [1219/2000], Train Loss: 0.0010, Test Loss: 0.0016\n",
      "The metrics are: 0.002516582957468927, 0.0007533387979492545, and 0.0006790474775092056\n",
      "Epoch [1220/2000], Train Loss: 0.0009, Test Loss: 0.0013\n",
      "The metrics are: 0.0026759362081065774, 0.0007578231355485817, and 0.0006768931828749677\n",
      "Epoch [1221/2000], Train Loss: 0.0009, Test Loss: 0.0013\n",
      "The metrics are: 0.0022010570392012596, 0.0007144049159251153, and 0.0006665271939709783\n",
      "Epoch [1222/2000], Train Loss: 0.0009, Test Loss: 0.0012\n",
      "The metrics are: 0.002038957318291068, 0.0006959041929803789, and 0.0006560477777384222\n",
      "Epoch [1223/2000], Train Loss: 0.0008, Test Loss: 0.0011\n",
      "The metrics are: 0.0020331142004579306, 0.0006933273398317397, and 0.0006562985945492983\n",
      "Epoch [1224/2000], Train Loss: 0.0008, Test Loss: 0.0011\n",
      "The metrics are: 0.002117836110604306, 0.0006998235864254335, and 0.0006555944952803353\n",
      "Epoch [1225/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002135097592448195, 0.0006965513651569685, and 0.0006579899442537377\n",
      "Epoch [1226/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002206741909806927, 0.0007208077392230431, and 0.0006590367702301592\n",
      "Epoch [1227/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.002443259038651983, 0.0006956804427318275, and 0.0006620849502117684\n",
      "Epoch [1228/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0025780535458276668, 0.0007194980862550437, and 0.0006559497948425511\n",
      "Epoch [1229/2000], Train Loss: 0.0008, Test Loss: 0.0014\n",
      "The metrics are: 0.002466405703065296, 0.0007306474920672675, and 0.0006451637600548565\n",
      "Epoch [1230/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0023183669351662197, 0.0007291256139675776, and 0.0006434203241951764\n",
      "Epoch [1231/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.002122014877386391, 0.000701845584747692, and 0.0006361839477904141\n",
      "Epoch [1232/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002086106726589302, 0.0007121014253546795, and 0.0006298387597780675\n",
      "Epoch [1233/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.001952733068416516, 0.000709462872085472, and 0.000617016019532457\n",
      "Epoch [1234/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.0021415011336406073, 0.0007154158277747532, and 0.0006262699122695873\n",
      "Epoch [1235/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.002462509747905036, 0.0007509381393902004, and 0.0006424344319384545\n",
      "Epoch [1236/2000], Train Loss: 0.0008, Test Loss: 0.0016\n",
      "The metrics are: 0.002569152624346316, 0.0007366759430927535, and 0.0006339904988029351\n",
      "Epoch [1237/2000], Train Loss: 0.0009, Test Loss: 0.0015\n",
      "The metrics are: 0.0026270353700965643, 0.0007202357131366929, and 0.0006391708254038045\n",
      "Epoch [1238/2000], Train Loss: 0.0009, Test Loss: 0.0015\n",
      "The metrics are: 0.0029720600383977094, 0.0007380571332760155, and 0.0006207215968364229\n",
      "Epoch [1239/2000], Train Loss: 0.0009, Test Loss: 0.0015\n",
      "The metrics are: 0.002855644755375882, 0.0007386344174544016, and 0.000624214056491231\n",
      "Epoch [1240/2000], Train Loss: 0.0009, Test Loss: 0.0015\n",
      "The metrics are: 0.00254043141224732, 0.0007175849944663545, and 0.0006050207011867315\n",
      "Epoch [1241/2000], Train Loss: 0.0009, Test Loss: 0.0013\n",
      "The metrics are: 0.0022603680457298956, 0.0006751873685667912, and 0.000603994985188668\n",
      "Epoch [1242/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002408688849148651, 0.0006855091584535936, and 0.0005993229472854485\n",
      "Epoch [1243/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002288442919962108, 0.0006625394259269038, and 0.0005883078653520594\n",
      "Epoch [1244/2000], Train Loss: 0.0008, Test Loss: 0.0011\n",
      "The metrics are: 0.001974120115240415, 0.0006402402650564909, and 0.0005775074435708424\n",
      "Epoch [1245/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.0017866644775494933, 0.0006239424304415783, and 0.0005869925565396746\n",
      "Epoch [1246/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.0017790313577279449, 0.0006341707776300609, and 0.0005771310922379295\n",
      "Epoch [1247/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019434061444674928, 0.0006346419880477091, and 0.0005793712528732916\n",
      "Epoch [1248/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.00227786332834512, 0.0006692290577727059, and 0.0005913895729463547\n",
      "Epoch [1249/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0025267071711520353, 0.0007003083204229673, and 0.0005933622790810963\n",
      "Epoch [1250/2000], Train Loss: 0.0008, Test Loss: 0.0014\n",
      "The metrics are: 0.0024859204810733595, 0.0006837065254027644, and 0.0005920108621163914\n",
      "Epoch [1251/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0022411064710468054, 0.0006865386773521701, and 0.0005804711739377429\n",
      "Epoch [1252/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0023575450759381056, 0.0006847623153589666, and 0.000589076536319529\n",
      "Epoch [1253/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.002432204782962799, 0.0006689942092634737, and 0.0005946681485511363\n",
      "Epoch [1254/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.002596526018654307, 0.0006904714197541276, and 0.0005840901091384391\n",
      "Epoch [1255/2000], Train Loss: 0.0009, Test Loss: 0.0013\n",
      "The metrics are: 0.0025403728941455483, 0.000697845631899933, and 0.0006026526971254498\n",
      "Epoch [1256/2000], Train Loss: 0.0008, Test Loss: 0.0015\n",
      "The metrics are: 0.002942148751268784, 0.0007163052214309573, and 0.0005769103299826384\n",
      "Epoch [1257/2000], Train Loss: 0.0009, Test Loss: 0.0014\n",
      "The metrics are: 0.0027805445715785027, 0.000723723826619486, and 0.0005929185814845065\n",
      "Epoch [1258/2000], Train Loss: 0.0009, Test Loss: 0.0014\n",
      "The metrics are: 0.002621573240806659, 0.000670050096232444, and 0.0005703878414351493\n",
      "Epoch [1259/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0021052886343871555, 0.000615875527728349, and 0.0005480655721233537\n",
      "Epoch [1260/2000], Train Loss: 0.0008, Test Loss: 0.0010\n",
      "The metrics are: 0.0018871931824833155, 0.0006022255402058363, and 0.0005442776503817489\n",
      "Epoch [1261/2000], Train Loss: 0.0007, Test Loss: 0.0009\n",
      "The metrics are: 0.0017631460214033723, 0.0005822579842060804, and 0.0005517510774855813\n",
      "Epoch [1262/2000], Train Loss: 0.0007, Test Loss: 0.0009\n",
      "The metrics are: 0.0017690110253170133, 0.0006025511538609862, and 0.000534382959206899\n",
      "Epoch [1263/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.001804951811209321, 0.0005998646762842933, and 0.0005421545647550374\n",
      "Epoch [1264/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.00177356010923783, 0.0005998313232945899, and 0.000535305948384727\n",
      "Epoch [1265/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.0016815986406678955, 0.0006299527982870737, and 0.0005383395570485542\n",
      "Epoch [1266/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019486823196833332, 0.000624530715867877, and 0.0005421743941648552\n",
      "Epoch [1267/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.002256222767755389, 0.0006530151586048305, and 0.0005791061363803843\n",
      "Epoch [1268/2000], Train Loss: 0.0007, Test Loss: 0.0015\n",
      "The metrics are: 0.0028406347458561263, 0.0007044318287322918, and 0.0005687750138652822\n",
      "Epoch [1269/2000], Train Loss: 0.0009, Test Loss: 0.0016\n",
      "The metrics are: 0.0031624342470119395, 0.0006938180498157939, and 0.0005914849850038687\n",
      "Epoch [1270/2000], Train Loss: 0.0009, Test Loss: 0.0017\n",
      "The metrics are: 0.003606522067760428, 0.0007216099184006453, and 0.0005626577573517958\n",
      "Epoch [1271/2000], Train Loss: 0.0010, Test Loss: 0.0015\n",
      "The metrics are: 0.0025351790245622396, 0.0006515577745934328, and 0.0005491172584394614\n",
      "Epoch [1272/2000], Train Loss: 0.0009, Test Loss: 0.0011\n",
      "The metrics are: 0.002045723842456937, 0.0006284524182168146, and 0.0005352119915187359\n",
      "Epoch [1273/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019458777193600933, 0.0005969531775917858, and 0.00052732372811685\n",
      "Epoch [1274/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.001675231324043125, 0.0005715833103749901, and 0.0005130302452016622\n",
      "Epoch [1275/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0015073243024138112, 0.0005626619094982743, and 0.0005153945239726454\n",
      "Epoch [1276/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0016299879256015022, 0.0005699466855730861, and 0.0005119154520798475\n",
      "Epoch [1277/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.001835111955491205, 0.000609471210433791, and 0.0005176526513726761\n",
      "Epoch [1278/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019243748780960839, 0.000596413427653412, and 0.0005264858773443848\n",
      "Epoch [1279/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0020720188040286303, 0.0005997089222849657, and 0.0005221941585962971\n",
      "Epoch [1280/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0023293476939822235, 0.0006292905115212003, and 0.0005280701055501898\n",
      "Epoch [1281/2000], Train Loss: 0.0007, Test Loss: 0.0013\n",
      "The metrics are: 0.0022380525479093194, 0.0006327099205615619, and 0.0005206834951726099\n",
      "Epoch [1282/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0022423582073921957, 0.0006267186060237387, and 0.0005295258791496357\n",
      "Epoch [1283/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0024514620502789817, 0.0006374215978818635, and 0.0005208421595549831\n",
      "Epoch [1284/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0022112438455224037, 0.0006078267275976638, and 0.0005186054137690613\n",
      "Epoch [1285/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0021189897088333964, 0.0005877963073241214, and 0.0005023975002889832\n",
      "Epoch [1286/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.001793019085501631, 0.0005632864582973222, and 0.0005090093375959744\n",
      "Epoch [1287/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.001990203706858059, 0.0005930971528869122, and 0.0005013943882659078\n",
      "Epoch [1288/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0018128704202050965, 0.0005800746730528772, and 0.0004973412433173507\n",
      "Epoch [1289/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0018678652898718913, 0.0005742118422252437, and 0.0004989014220579217\n",
      "Epoch [1290/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019291156592468421, 0.000611561913198481, and 0.0005035127202669779\n",
      "Epoch [1291/2000], Train Loss: 0.0007, Test Loss: 0.0013\n",
      "The metrics are: 0.002108419934908549, 0.0005933518502085159, and 0.0005108889502783617\n",
      "Epoch [1292/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.002147837852438291, 0.0006215731749155869, and 0.0005071173363830894\n",
      "Epoch [1293/2000], Train Loss: 0.0007, Test Loss: 0.0013\n",
      "The metrics are: 0.0022975632455199957, 0.0006292979621017972, and 0.0005270144417105863\n",
      "Epoch [1294/2000], Train Loss: 0.0008, Test Loss: 0.0014\n",
      "The metrics are: 0.002829697293539842, 0.0006526361879271766, and 0.0005199825876237204\n",
      "Epoch [1295/2000], Train Loss: 0.0008, Test Loss: 0.0014\n",
      "The metrics are: 0.0027063997695222497, 0.0006350302719511092, and 0.0005231263736883799\n",
      "Epoch [1296/2000], Train Loss: 0.0008, Test Loss: 0.0014\n",
      "The metrics are: 0.0025080785465737185, 0.0006362640027267238, and 0.0004997074720449746\n",
      "Epoch [1297/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.00240680070904394, 0.0006444126095933219, and 0.0005061961613440266\n",
      "Epoch [1298/2000], Train Loss: 0.0008, Test Loss: 0.0013\n",
      "The metrics are: 0.0024247791540498533, 0.0005969608416004727, and 0.0004957590038732936\n",
      "Epoch [1299/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.002441254056369265, 0.000602415578517442, and 0.0004947106256925812\n",
      "Epoch [1300/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.002372309371518592, 0.0005860881065018475, and 0.00048286015711103875\n",
      "Epoch [1301/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0020208467806999884, 0.0005936870584264398, and 0.0004766534354227285\n",
      "Epoch [1302/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.0016130279400385916, 0.0005420661861232171, and 0.000466911723682036\n",
      "Epoch [1303/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0016766348077605169, 0.0005442805316609641, and 0.00046778910715753835\n",
      "Epoch [1304/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0018428613354141514, 0.0005683036676297585, and 0.0004698324967951824\n",
      "Epoch [1305/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0019952417351305485, 0.0005517134656353543, and 0.00048031645322528976\n",
      "Epoch [1306/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0021274653651441136, 0.0005827154285119226, and 0.0004718868391743551\n",
      "Epoch [1307/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0018675085933258135, 0.0005696048319805413, and 0.0004732179707692315\n",
      "Epoch [1308/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.002054666285403073, 0.0005749451423374315, and 0.00047356312279589474\n",
      "Epoch [1309/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0022361475663880506, 0.0005919540805431703, and 0.000472512348399808\n",
      "Epoch [1310/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.001949815816866855, 0.0005471611608906338, and 0.00046128418762236834\n",
      "Epoch [1311/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.0017510930580707889, 0.0005547706581031283, and 0.00046306775766424835\n",
      "Epoch [1312/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0018294499022886157, 0.0005514283839147538, and 0.0004644248110707849\n",
      "Epoch [1313/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.00216740183532238, 0.0005649467445133874, and 0.00046972200895349186\n",
      "Epoch [1314/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.002127483293103675, 0.0005764329980593175, and 0.0004656789727353801\n",
      "Epoch [1315/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0024545053796221814, 0.0005961191491223872, and 0.0004890169657301158\n",
      "Epoch [1316/2000], Train Loss: 0.0007, Test Loss: 0.0014\n",
      "The metrics are: 0.0025457503894964852, 0.0005749580062304934, and 0.0004689036674487094\n",
      "Epoch [1317/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0021377629600465298, 0.0005589404512041559, and 0.00045833281668213505\n",
      "Epoch [1318/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.001781808406425019, 0.0005348896762977043, and 0.0004453101525238405\n",
      "Epoch [1319/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0018263066303916276, 0.0005548899935092777, and 0.0004623663747527947\n",
      "Epoch [1320/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.001998497056774795, 0.0005348193323394904, and 0.00045753095764666796\n",
      "Epoch [1321/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0020548232520620027, 0.0005515037434330831, and 0.00045474911651884514\n",
      "Epoch [1322/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0021312358245874443, 0.0005759326450061053, and 0.0004522175683329503\n",
      "Epoch [1323/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0020570121705532074, 0.0005626539253474524, and 0.00045820209197700024\n",
      "Epoch [1324/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0020707168926795325, 0.0005424161402819058, and 0.00044492032611742616\n",
      "Epoch [1325/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.00206703234774371, 0.0005767037897991637, and 0.00045022960208977264\n",
      "Epoch [1326/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0020897298818454146, 0.0005682896880898625, and 0.00045144828618504107\n",
      "Epoch [1327/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0021058546068767705, 0.0005765718718369802, and 0.00044632218972158927\n",
      "Epoch [1328/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0020959963633989296, 0.0005418912332970649, and 0.00044141593389213085\n",
      "Epoch [1329/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019997558556497097, 0.0005406094909024736, and 0.00043565941935715574\n",
      "Epoch [1330/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0017905894201248884, 0.0005248204300490519, and 0.00043858366552740335\n",
      "Epoch [1331/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0019202955688039462, 0.0005227591318544, and 0.00043489956685031456\n",
      "Epoch [1332/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0020830175296093025, 0.0005313470804442962, and 0.0004378628315559278\n",
      "Epoch [1333/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.001946877494143943, 0.0005383741809055209, and 0.00042667592060752213\n",
      "Epoch [1334/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0020215482994293175, 0.0005304203950800002, and 0.0004503581828127305\n",
      "Epoch [1335/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0023033727193251252, 0.0005354759632609785, and 0.00043098781801139313\n",
      "Epoch [1336/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019270071837430198, 0.0005263370888618132, and 0.0004266134346835315\n",
      "Epoch [1337/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.001769129380894204, 0.000517607385215039, and 0.0004199004906695336\n",
      "Epoch [1338/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.001766154736590882, 0.0005189289610522488, and 0.0004345643295285602\n",
      "Epoch [1339/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.002067409843827287, 0.0005524040898308158, and 0.0004273955225168417\n",
      "Epoch [1340/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0025085345841944218, 0.0005842847458552569, and 0.0004496364078174035\n",
      "Epoch [1341/2000], Train Loss: 0.0007, Test Loss: 0.0014\n",
      "The metrics are: 0.002516347992544373, 0.0005680309938422093, and 0.00042947283751952153\n",
      "Epoch [1342/2000], Train Loss: 0.0008, Test Loss: 0.0012\n",
      "The metrics are: 0.002364475241241356, 0.0005473700099779913, and 0.0004515771967514108\n",
      "Epoch [1343/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0024765088067700467, 0.0005312679568305612, and 0.0004326819519822796\n",
      "Epoch [1344/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.001967103026496867, 0.000488840703231593, and 0.00041276342623556655\n",
      "Epoch [1345/2000], Train Loss: 0.0006, Test Loss: 0.0008\n",
      "The metrics are: 0.001470174000132829, 0.00046410507638938725, and 0.0004039826647688945\n",
      "Epoch [1346/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0012591012637130916, 0.00045669526055765647, and 0.0004056529627026369\n",
      "Epoch [1347/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0014503110627022882, 0.0004722766946845998, and 0.0004010774913088729\n",
      "Epoch [1348/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001692810794338584, 0.0004890926162867496, and 0.0004088521527592093\n",
      "Epoch [1349/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019260101253166795, 0.000531413524489229, and 0.00041368625049168867\n",
      "Epoch [1350/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0018823850744714339, 0.0005178688831316928, and 0.00041824842143493396\n",
      "Epoch [1351/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.002187392325140536, 0.0005307331836471955, and 0.0004190754843875766\n",
      "Epoch [1352/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.002373460913076997, 0.0005613925071277966, and 0.00043191755927788716\n",
      "Epoch [1353/2000], Train Loss: 0.0007, Test Loss: 0.0014\n",
      "The metrics are: 0.002405365308125814, 0.0005460491714378198, and 0.00041893865757932264\n",
      "Epoch [1354/2000], Train Loss: 0.0007, Test Loss: 0.0013\n",
      "The metrics are: 0.002136475406587124, 0.0005272091754401723, and 0.00041205926875894267\n",
      "Epoch [1355/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.001878283607463042, 0.0005009220816039791, and 0.00039970013312995434\n",
      "Epoch [1356/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019231675347934167, 0.0005197995730365316, and 0.0004070918560804178\n",
      "Epoch [1357/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0019500480654338996, 0.0004991805471945554, and 0.00039743482678507763\n",
      "Epoch [1358/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019648987993908427, 0.0004886338526072601, and 0.0004088570033976187\n",
      "Epoch [1359/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.002194795369481047, 0.000497261188381041, and 0.00040019672208776075\n",
      "Epoch [1360/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019283761891225974, 0.000480786053230986, and 0.0003917371601952861\n",
      "Epoch [1361/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0016888832518210013, 0.00047044337649519247, and 0.0003816218231804669\n",
      "Epoch [1362/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0018175875302404165, 0.000485741028872629, and 0.00040531438814165693\n",
      "Epoch [1363/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0018938049906864762, 0.0004974594242715588, and 0.00039274771794832003\n",
      "Epoch [1364/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0019709150850151977, 0.0004874081738914053, and 0.00039389138692058623\n",
      "Epoch [1365/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019314037247871358, 0.0004893796770678213, and 0.0003887724597007036\n",
      "Epoch [1366/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019369133903334539, 0.0005066413529372463, and 0.0003930967504857108\n",
      "Epoch [1367/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0019091699893275897, 0.0004870028836497416, and 0.0003812415767849113\n",
      "Epoch [1368/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.001655592117458582, 0.0004927013845493396, and 0.00039343623211607337\n",
      "Epoch [1369/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.002197887049987912, 0.000503254928238069, and 0.0003922233348324274\n",
      "Epoch [1370/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0021040413606291017, 0.0004874062627398719, and 0.00038728277043749887\n",
      "Epoch [1371/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.0020599900356804333, 0.0004928436343713353, and 0.000378242097212933\n",
      "Epoch [1372/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0017373248313864071, 0.0004780820939534654, and 0.0003818576709212114\n",
      "Epoch [1373/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0018782169014836352, 0.00047440623166039586, and 0.00037617266934830695\n",
      "Epoch [1374/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.001765442080795765, 0.00045939953027603525, and 0.00037459435407072306\n",
      "Epoch [1375/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0018233750403548281, 0.00045231523108668625, and 0.0003706239173576857\n",
      "Epoch [1376/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0017688501781473558, 0.000456216192105785, and 0.00037824872803563875\n",
      "Epoch [1377/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.001615358516573906, 0.00045011727100548643, and 0.0003621309200146546\n",
      "Epoch [1378/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001508632053931554, 0.00043410191816898686, and 0.0003718699930080523\n",
      "Epoch [1379/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.00168104136052231, 0.0004439627130826314, and 0.0003660862421384081\n",
      "Epoch [1380/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0015828150984210272, 0.0004530393925961107, and 0.00037776945100631565\n",
      "Epoch [1381/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.0018970411814128358, 0.0004683155663466702, and 0.0003684853678957249\n",
      "Epoch [1382/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0019921694959824285, 0.0005249055296493074, and 0.00039930436954212684\n",
      "Epoch [1383/2000], Train Loss: 0.0006, Test Loss: 0.0014\n",
      "The metrics are: 0.002244193417330583, 0.0005160397558938712, and 0.00039001827826723456\n",
      "Epoch [1384/2000], Train Loss: 0.0007, Test Loss: 0.0013\n",
      "The metrics are: 0.0024023933801800013, 0.0005009896606982996, and 0.00039296745186826837\n",
      "Epoch [1385/2000], Train Loss: 0.0007, Test Loss: 0.0013\n",
      "The metrics are: 0.0023723210906609893, 0.0005075413500890136, and 0.00037561755258745205\n",
      "Epoch [1386/2000], Train Loss: 0.0007, Test Loss: 0.0012\n",
      "The metrics are: 0.0020748243744795523, 0.00047200270152340334, and 0.0003788222578198959\n",
      "Epoch [1387/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.002017116484542688, 0.00046521735688050586, and 0.0003580319947407891\n",
      "Epoch [1388/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0017460658952283363, 0.0004549400764517486, and 0.0003634212092341234\n",
      "Epoch [1389/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0018642624296868842, 0.0004679097425347815, and 0.00035681985415673506\n",
      "Epoch [1390/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0020725369880286357, 0.00048757459929523367, and 0.00038190544000826776\n",
      "Epoch [1391/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.002121080605623623, 0.0004763332544825971, and 0.00036085718602407724\n",
      "Epoch [1392/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0019763021652276316, 0.0004579291950600843, and 0.0003687364902968208\n",
      "Epoch [1393/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0016679925611242652, 0.0004439702412734429, and 0.0003447783625839899\n",
      "Epoch [1394/2000], Train Loss: 0.0006, Test Loss: 0.0008\n",
      "The metrics are: 0.0015445284661836922, 0.0004193130395530413, and 0.00036051476005620014\n",
      "Epoch [1395/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0020192269779120884, 0.00045539203953618806, and 0.00037580305070150644\n",
      "Epoch [1396/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0022480243739361563, 0.0004869790670151512, and 0.0003711697596979017\n",
      "Epoch [1397/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0025136967500050864, 0.00048688216096100706, and 0.00036524109600577503\n",
      "Epoch [1398/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0021162325671563544, 0.0004761898114035527, and 0.0003547655602839465\n",
      "Epoch [1399/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019456406395571928, 0.00048016966320574284, and 0.00035184628116743016\n",
      "Epoch [1400/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0016729057727692027, 0.0004401897022034973, and 0.00034263212971078855\n",
      "Epoch [1401/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0016943593315469723, 0.0004594700682597856, and 0.0003445521482111265\n",
      "Epoch [1402/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0018149507814086974, 0.0004264675371814519, and 0.000347311666700989\n",
      "Epoch [1403/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0016652209839473169, 0.0003949660458602011, and 0.000340950777172111\n",
      "Epoch [1404/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0013860078373303015, 0.0003882873667559276, and 0.0003259710162334765\n",
      "Epoch [1405/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.00150001491419971, 0.000404186799035718, and 0.00033768886351026595\n",
      "Epoch [1406/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015049102754953008, 0.0004108739279521008, and 0.0003380415340264638\n",
      "Epoch [1407/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001567203221687426, 0.0004279403656255454, and 0.0003372832773796593\n",
      "Epoch [1408/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001801011540616552, 0.00043297863642995554, and 0.00035056577568563324\n",
      "Epoch [1409/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.001704965136013925, 0.0004327328836855789, and 0.00034624580196881044\n",
      "Epoch [1410/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0021469169684375324, 0.0004570693999994546, and 0.00036935236130375415\n",
      "Epoch [1411/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0024711285174513855, 0.0005051340849604458, and 0.00036060321629823494\n",
      "Epoch [1412/2000], Train Loss: 0.0007, Test Loss: 0.0013\n",
      "The metrics are: 0.0022928788093850017, 0.00046833341669601697, and 0.00034819879510905594\n",
      "Epoch [1413/2000], Train Loss: 0.0007, Test Loss: 0.0011\n",
      "The metrics are: 0.0023299133560309806, 0.0004551235567002247, and 0.0003487721987767145\n",
      "Epoch [1414/2000], Train Loss: 0.0007, Test Loss: 0.0010\n",
      "The metrics are: 0.0021594391825298467, 0.00043420146297042567, and 0.0003374937950866297\n",
      "Epoch [1415/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0016897809303676088, 0.0004201877163723111, and 0.00032410764348848414\n",
      "Epoch [1416/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.001625108765438199, 0.00039387842601475614, and 0.00032359287918855745\n",
      "Epoch [1417/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015598781368074317, 0.0003919643349945545, and 0.00032226900414874155\n",
      "Epoch [1418/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0014232096921962996, 0.0003781985821357618, and 0.00031735107768327\n",
      "Epoch [1419/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0014533551875501871, 0.00037854647962376475, and 0.0003229560485730569\n",
      "Epoch [1420/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.001508445420768112, 0.000377863800774018, and 0.00031592429149895906\n",
      "Epoch [1421/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015526908876684804, 0.0003787806393423428, and 0.00032447759197869647\n",
      "Epoch [1422/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0017018927028402686, 0.00040019490794899565, and 0.00032834287170165527\n",
      "Epoch [1423/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001840870245359838, 0.0004148819425608963, and 0.00033559171424712986\n",
      "Epoch [1424/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.002001877292059362, 0.0004174660813684265, and 0.00032815787320335704\n",
      "Epoch [1425/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0022824888583272696, 0.0004483649293736865, and 0.00033834270531466853\n",
      "Epoch [1426/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0020124245202168822, 0.00043713138438761234, and 0.00032390066189691424\n",
      "Epoch [1427/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.001832391678666075, 0.00040588366876666743, and 0.00032139640340271097\n",
      "Epoch [1428/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019826781935989857, 0.0004041175222179542, and 0.000321786380178916\n",
      "Epoch [1429/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0017767106764949858, 0.0004112699340718488, and 0.00031303990302452195\n",
      "Epoch [1430/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0017043360858224332, 0.0003829876174374173, and 0.0003161678129496674\n",
      "Epoch [1431/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.00172132789157331, 0.0003990290764098366, and 0.0003141011547995731\n",
      "Epoch [1432/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0017245403723791242, 0.00039504357846453786, and 0.00031487951734258485\n",
      "Epoch [1433/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0016092637282175322, 0.0003915811733653148, and 0.0003045335130688424\n",
      "Epoch [1434/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0014425516710616648, 0.00039288018403264385, and 0.00030554591891511035\n",
      "Epoch [1435/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0017136564129032195, 0.000396525370888412, and 0.00031641155752974254\n",
      "Epoch [1436/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.0018491302616894245, 0.0003998127843563755, and 0.00031975939054973423\n",
      "Epoch [1437/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.0019652636256068945, 0.0004262583194455753, and 0.00032758219458628446\n",
      "Epoch [1438/2000], Train Loss: 0.0005, Test Loss: 0.0012\n",
      "The metrics are: 0.0023721760759751, 0.0004304015989570568, and 0.00032164457661565393\n",
      "Epoch [1439/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0021142844343557954, 0.00042056488261247676, and 0.0003144077588027964\n",
      "Epoch [1440/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019826656595493355, 0.00042499346697392565, and 0.0003050756737745057\n",
      "Epoch [1441/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0017879171840225656, 0.0003887791147766014, and 0.00031346767597521347\n",
      "Epoch [1442/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.001639851873430113, 0.00036813241119186085, and 0.0002986602339660749\n",
      "Epoch [1443/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015761041625713308, 0.00035713447141461074, and 0.0002975004172185436\n",
      "Epoch [1444/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0013345707363138597, 0.00033607535685102147, and 0.0002862159599317238\n",
      "Epoch [1445/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0011838920957719286, 0.0003275549873554458, and 0.00028624287612425786\n",
      "Epoch [1446/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0012137741432525218, 0.0003362962355216344, and 0.00028629293471264344\n",
      "Epoch [1447/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013582281341465812, 0.00035271291077757877, and 0.00029249273939058185\n",
      "Epoch [1448/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001539436149566124, 0.0003819746101119866, and 0.0003009225329151377\n",
      "Epoch [1449/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.0018587859813123941, 0.0003976113706206282, and 0.0003157185031644379\n",
      "Epoch [1450/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.001926579241019984, 0.00042205446516163647, and 0.0003112077441376944\n",
      "Epoch [1451/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.002083131189768513, 0.000416325560460488, and 0.0003105679594834025\n",
      "Epoch [1452/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0020492217348267636, 0.0004170052222131441, and 0.00031480001537905383\n",
      "Epoch [1453/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0021628588438034058, 0.00041606344166211784, and 0.00030720391562984634\n",
      "Epoch [1454/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0022089907821888724, 0.00039741810178384185, and 0.0003088108157195772\n",
      "Epoch [1455/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019402319643025596, 0.0003846186737064272, and 0.0002934609753234933\n",
      "Epoch [1456/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0015250995056703687, 0.00034967583875792724, and 0.0002836557832779363\n",
      "Epoch [1457/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0012360181232603888, 0.0003291741110539685, and 0.00027439337767039734\n",
      "Epoch [1458/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001275784239017715, 0.0003352348964350919, and 0.00027718161679028225\n",
      "Epoch [1459/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013135065479824941, 0.00033635652895706397, and 0.00027581312557837617\n",
      "Epoch [1460/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0013547373625139396, 0.000326015588749821, and 0.0002781374108356734\n",
      "Epoch [1461/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0014935565025856097, 0.0003577849129214883, and 0.00028265954460948706\n",
      "Epoch [1462/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001876878358113269, 0.0003917450861384471, and 0.0003049289613651733\n",
      "Epoch [1463/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.0023114716168493032, 0.0003919412944621096, and 0.0003277527721365914\n",
      "Epoch [1464/2000], Train Loss: 0.0006, Test Loss: 0.0013\n",
      "The metrics are: 0.0025422358885407448, 0.00040899191905433935, and 0.00029891060936885577\n",
      "Epoch [1465/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0018458830115074913, 0.00035656182444654405, and 0.00027870685638238985\n",
      "Epoch [1466/2000], Train Loss: 0.0006, Test Loss: 0.0008\n",
      "The metrics are: 0.0014816555388582249, 0.0003437209428132822, and 0.0002779032365651801\n",
      "Epoch [1467/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015905456384643912, 0.00034560426138341427, and 0.0002754482751091321\n",
      "Epoch [1468/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.001611417760917296, 0.00035944875950614613, and 0.0002754008067616572\n",
      "Epoch [1469/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0017435284098610282, 0.000362803975197797, and 0.00027356596547178924\n",
      "Epoch [1470/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.002013635511199633, 0.0004188959040523817, and 0.00028648935646439594\n",
      "Epoch [1471/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.002203737540791432, 0.0004171344335190952, and 0.00029193405255985755\n",
      "Epoch [1472/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0021898465929552913, 0.00039637226533765596, and 0.0002910987047168116\n",
      "Epoch [1473/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0024680443263302245, 0.00038305047200992703, and 0.00028058787089927745\n",
      "Epoch [1474/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019774131554489336, 0.00036127538381454843, and 0.000263775199224862\n",
      "Epoch [1475/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015741520716498296, 0.0003260905311132471, and 0.00026045988488476723\n",
      "Epoch [1476/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0013365525131424267, 0.000309250865636083, and 0.0002537529411104818\n",
      "Epoch [1477/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001414627826306969, 0.0003121269983239472, and 0.00025329743706000346\n",
      "Epoch [1478/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014150429827471573, 0.0003142645728075877, and 0.0002536709556200852\n",
      "Epoch [1479/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014657766829865675, 0.00033491692738607526, and 0.00025568621640559286\n",
      "Epoch [1480/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015455686564867694, 0.0003225754335289821, and 0.0002627101008935521\n",
      "Epoch [1481/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017066954169422388, 0.0003506240415542076, and 0.00025781250345365453\n",
      "Epoch [1482/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0017161009018309414, 0.00033597445872146636, and 0.0002619158137046422\n",
      "Epoch [1483/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0015137362061068416, 0.00031389497841397923, and 0.00025399871325741213\n",
      "Epoch [1484/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.001439143515502413, 0.00031370001670438796, and 0.0002571717098665734\n",
      "Epoch [1485/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0014791180728934705, 0.0003165055871553098, and 0.0002565137013637771\n",
      "Epoch [1486/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016528604707370202, 0.00032667009024104726, and 0.00026767047529574484\n",
      "Epoch [1487/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015461182532211144, 0.0003398044500499964, and 0.00025752672809176147\n",
      "Epoch [1488/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0016604440946442385, 0.00033843763715897995, and 0.00026045880804304034\n",
      "Epoch [1489/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0018193175977406402, 0.00034444632183294743, and 0.00026915338821709156\n",
      "Epoch [1490/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.002126457286067307, 0.0003683891554828733, and 0.0002759306613976757\n",
      "Epoch [1491/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0024892372700075307, 0.000378060998627916, and 0.0002721293324915071\n",
      "Epoch [1492/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019498132169246674, 0.00036607780687821406, and 0.0002578131582898398\n",
      "Epoch [1493/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0017528029857203364, 0.0003509386976171906, and 0.0002542980801081285\n",
      "Epoch [1494/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0015012295916676521, 0.0003125642736752828, and 0.00024794133302445215\n",
      "Epoch [1495/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0013763755171870191, 0.0002979547086094196, and 0.00023769440789086124\n",
      "Epoch [1496/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0012152818962931633, 0.0002774147966799016, and 0.00023684947033567974\n",
      "Epoch [1497/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013793820980936289, 0.0003016776851533602, and 0.00023622940352652222\n",
      "Epoch [1498/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015038472677891452, 0.00031225785399631906, and 0.000241592182040525\n",
      "Epoch [1499/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015332530989932518, 0.00031727124587632716, and 0.00024097444353780398\n",
      "Epoch [1500/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016880530553559463, 0.0003382052721766134, and 0.0002482834873565783\n",
      "Epoch [1501/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0021099701213339963, 0.0003836987792359044, and 0.00026880619407165796\n",
      "Epoch [1502/2000], Train Loss: 0.0005, Test Loss: 0.0012\n",
      "The metrics are: 0.0024549557516972222, 0.0003856750651417921, and 0.000266799601376988\n",
      "Epoch [1503/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0023019007639959455, 0.0003446145322717105, and 0.00025111038121394813\n",
      "Epoch [1504/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0018952085132089753, 0.00033850749120271456, and 0.00023709559657921395\n",
      "Epoch [1505/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0016285614886631568, 0.0003110728624354427, and 0.0002415437726691986\n",
      "Epoch [1506/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0014889758895151317, 0.0002903143419340874, and 0.00023401908886929354\n",
      "Epoch [1507/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014564812493820984, 0.0002877354127122089, and 0.00022801054001320153\n",
      "Epoch [1508/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0012843327325147886, 0.0002809709937234099, and 0.00022326444741338491\n",
      "Epoch [1509/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013154512271285057, 0.0002934109846440454, and 0.00022716125628600517\n",
      "Epoch [1510/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016319151036441326, 0.0003175410383846611, and 0.0002344305394217372\n",
      "Epoch [1511/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018470456125214696, 0.00035025189572479576, and 0.00024510008612802875\n",
      "Epoch [1512/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.0017359325429424644, 0.0003168128168908879, and 0.00023465329043877622\n",
      "Epoch [1513/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0016658199213755627, 0.00030907852730403346, and 0.00023456775428106388\n",
      "Epoch [1514/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015353558119386435, 0.00029656459325148415, and 0.00022609423710188517\n",
      "Epoch [1515/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001490818588839223, 0.00028604911737299216, and 0.00022841982233027616\n",
      "Epoch [1516/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015801572008058429, 0.00029557237576227635, and 0.00023210147628560662\n",
      "Epoch [1517/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016242849718158443, 0.0003008161390122647, and 0.00022663485530453423\n",
      "Epoch [1518/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015771979233250022, 0.0002992638716629396, and 0.00022616938804276288\n",
      "Epoch [1519/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015917814259106915, 0.00030607269824637723, and 0.00022953931087007126\n",
      "Epoch [1520/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015549128487085302, 0.00029626398948797333, and 0.00022798373053471246\n",
      "Epoch [1521/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014527411937403183, 0.00030961597318916273, and 0.00022361797164194286\n",
      "Epoch [1522/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0018414978209572534, 0.0003248007269576192, and 0.00023715643328614533\n",
      "Epoch [1523/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.002004371451524397, 0.0003408009458022813, and 0.0002374878094997257\n",
      "Epoch [1524/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.002049657302753379, 0.00035139750980306417, and 0.00024384068577395132\n",
      "Epoch [1525/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.0021282908273860812, 0.00038174255557047826, and 0.0002459690731484443\n",
      "Epoch [1526/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.0021846138406544924, 0.00032399506017100066, and 0.0002357213331076006\n",
      "Epoch [1527/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.0021287185178759196, 0.000309921049241287, and 0.00023359401287355772\n",
      "Epoch [1528/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0017328148630137246, 0.00029090370420211303, and 0.00022210024083809307\n",
      "Epoch [1529/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015585793880745769, 0.0002826556786506747, and 0.00021460171653113017\n",
      "Epoch [1530/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.00133664298725004, 0.0002622938579103599, and 0.0002081448765238747\n",
      "Epoch [1531/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001232688615952308, 0.000264430113020353, and 0.0002084833880265554\n",
      "Epoch [1532/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0012953074571366112, 0.00025432733915901434, and 0.00021585334616247565\n",
      "Epoch [1533/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013028900527084868, 0.0002550655238640805, and 0.0002125584384581695\n",
      "Epoch [1534/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0012688202356609206, 0.00025722863695894677, and 0.00021158752982349446\n",
      "Epoch [1535/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001313251870063444, 0.00025373911679101485, and 0.00020891151022321233\n",
      "Epoch [1536/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0014052201295271516, 0.00027566786350992817, and 0.0002144707104889676\n",
      "Epoch [1537/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015034241951070726, 0.0002867931470973417, and 0.00022129924521626285\n",
      "Epoch [1538/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.002024265006184578, 0.00032016257076368976, and 0.0002454183462153499\n",
      "Epoch [1539/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.0022684137414519987, 0.0003659536208336552, and 0.0002455876674503088\n",
      "Epoch [1540/2000], Train Loss: 0.0006, Test Loss: 0.0012\n",
      "The metrics are: 0.0021542435279116035, 0.00033325900343091536, and 0.00023002543215019008\n",
      "Epoch [1541/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.001998470164835453, 0.0003174113614174227, and 0.0002171320617586995\n",
      "Epoch [1542/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001786044449545443, 0.00029319234696837765, and 0.00021615125297103077\n",
      "Epoch [1543/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.001596322050318122, 0.0002715847755704696, and 0.00021169847847583392\n",
      "Epoch [1544/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001430037897080183, 0.0002600868707910801, and 0.00020304135493158051\n",
      "Epoch [1545/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013835589634254575, 0.00027324730763211846, and 0.00020400298914561668\n",
      "Epoch [1546/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014276562142185867, 0.00027632309259691584, and 0.00021114819780147323\n",
      "Epoch [1547/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015533405045668285, 0.0002709703209499518, and 0.00021893529143805304\n",
      "Epoch [1548/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015246461844071746, 0.0002680871936415012, and 0.00020876917308972528\n",
      "Epoch [1549/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0012721016925449173, 0.0002514952260147159, and 0.00020234076752482602\n",
      "Epoch [1550/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0011503100007151563, 0.00024040922289714217, and 0.00019767709697286287\n",
      "Epoch [1551/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0011328458203934133, 0.00024054715565095344, and 0.00019610877401040247\n",
      "Epoch [1552/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0011634732169720035, 0.00024734561156947166, and 0.00019722471673352024\n",
      "Epoch [1553/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0017346080858260393, 0.00029079021866588545, and 0.00022368372689622143\n",
      "Epoch [1554/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018956737282375495, 0.00034242232019702595, and 0.00022929210778481016\n",
      "Epoch [1555/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.0022866205933193364, 0.0003199557492431874, and 0.00022391483556323996\n",
      "Epoch [1556/2000], Train Loss: 0.0006, Test Loss: 0.0011\n",
      "The metrics are: 0.002458711814445754, 0.00034157606326819706, and 0.00022113486678184321\n",
      "Epoch [1557/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0019821671303361654, 0.00034274008066859096, and 0.0002140247185404102\n",
      "Epoch [1558/2000], Train Loss: 0.0006, Test Loss: 0.0009\n",
      "The metrics are: 0.001810732064768672, 0.00030695798341184855, and 0.00021230686494770148\n",
      "Epoch [1559/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0020306557028864822, 0.00033107308748488623, and 0.00021823250669209907\n",
      "Epoch [1560/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.002295687018583218, 0.0003267785117107754, and 0.00021861784140734622\n",
      "Epoch [1561/2000], Train Loss: 0.0006, Test Loss: 0.0010\n",
      "The metrics are: 0.0016822689794935286, 0.0002707617337970684, and 0.00019931218897302946\n",
      "Epoch [1562/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0013786426085668306, 0.0002467013206720973, and 0.00018930149478061745\n",
      "Epoch [1563/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0011197574203833938, 0.0002269602361290405, and 0.00018712986396470418\n",
      "Epoch [1564/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012147245385373633, 0.00023590148581812778, and 0.0001837976354484757\n",
      "Epoch [1565/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012580750044435263, 0.00024402099855554601, and 0.00018545884328583875\n",
      "Epoch [1566/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012649472337216139, 0.00023606884254453084, and 0.00018571283241423467\n",
      "Epoch [1567/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012300595990382135, 0.00023386576503980905, and 0.00018423566749940315\n",
      "Epoch [1568/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013737891955922048, 0.0002456399185272555, and 0.00018573573470348492\n",
      "Epoch [1569/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015139364210578303, 0.0002557631426801284, and 0.00018868095988485342\n",
      "Epoch [1570/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015208571373174589, 0.00025900055091672886, and 0.0001917729435566192\n",
      "Epoch [1571/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014363106068534155, 0.0002618250340068092, and 0.00019040943880099803\n",
      "Epoch [1572/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016617958123485248, 0.0002696904509017865, and 0.00019497287091022977\n",
      "Epoch [1573/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017598864700024326, 0.0002874030324164778, and 0.00020397214878660938\n",
      "Epoch [1574/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018321459259216983, 0.000286729783207799, and 0.00019815820996882394\n",
      "Epoch [1575/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0019365974391500156, 0.0002835329166070248, and 0.0001988381021268045\n",
      "Epoch [1576/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015943032534172137, 0.0002663229388417676, and 0.0001864852626264716\n",
      "Epoch [1577/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016582602790246408, 0.0002794647977376978, and 0.00018965005438076332\n",
      "Epoch [1578/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001761224082050224, 0.00027584852068684995, and 0.00019364120331980908\n",
      "Epoch [1579/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001731578241257618, 0.0002589230425655842, and 0.00019107898939788962\n",
      "Epoch [1580/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017637374500433605, 0.0002810591880309706, and 0.00019135275215376168\n",
      "Epoch [1581/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0018692264954249065, 0.0002703508410680418, and 0.00019025830746007463\n",
      "Epoch [1582/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0016374610907708604, 0.0002540454491584872, and 0.00018139606011876216\n",
      "Epoch [1583/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001453766676907738, 0.00026187081918275606, and 0.00017794276451847205\n",
      "Epoch [1584/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0017380684342545767, 0.00029871746179802966, and 0.000186434255738277\n",
      "Epoch [1585/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001934177086999019, 0.0002937532311383014, and 0.00019187935928736502\n",
      "Epoch [1586/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001927926205098629, 0.00028562877560034394, and 0.00018702151040391377\n",
      "Epoch [1587/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.001857114548329264, 0.00027179291161398095, and 0.00019271434333253032\n",
      "Epoch [1588/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015760889315667252, 0.00024260215286631137, and 0.000184944753224651\n",
      "Epoch [1589/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013001507225756843, 0.00022154018127669892, and 0.00017429631164607903\n",
      "Epoch [1590/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012663901822331052, 0.00021462621225509793, and 0.0001674661956106623\n",
      "Epoch [1591/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011365893296897411, 0.0002168055895405511, and 0.00016296853088230515\n",
      "Epoch [1592/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011405047747151305, 0.00021156076400075108, and 0.00016660017475563413\n",
      "Epoch [1593/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014229071869825323, 0.00024024147811966637, and 0.00017193694657180458\n",
      "Epoch [1594/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014121585409156978, 0.0002549709558176498, and 0.00017773145130680254\n",
      "Epoch [1595/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0018589217603827517, 0.0002806375656897823, and 0.00019548302952898666\n",
      "Epoch [1596/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.002002142524967591, 0.0002840306357635806, and 0.000188434416486416\n",
      "Epoch [1597/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001741768637051185, 0.00025468420547743637, and 0.00018457640544511378\n",
      "Epoch [1598/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0013846528017893434, 0.00021927009705298892, and 0.00016740745437952378\n",
      "Epoch [1599/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013001246164397646, 0.00021393635446050516, and 0.0001684288751372757\n",
      "Epoch [1600/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001359242790689071, 0.00022624396175766984, and 0.00017077120962009454\n",
      "Epoch [1601/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014956560917198658, 0.00023056441083705673, and 0.00017242714481350654\n",
      "Epoch [1602/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013869073785220583, 0.00022493230062536895, and 0.0001699425071516695\n",
      "Epoch [1603/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013108763960190117, 0.00023774159490130842, and 0.0001671141387002232\n",
      "Epoch [1604/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016102807712741196, 0.00024521151984420914, and 0.00017746861703926697\n",
      "Epoch [1605/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.002030386395441989, 0.0002986420295201242, and 0.00018447020071713874\n",
      "Epoch [1606/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.002066010182412962, 0.0002638719112534697, and 0.00018529017931238437\n",
      "Epoch [1607/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0016936719572792451, 0.00025147661411513883, and 0.00016894023186371973\n",
      "Epoch [1608/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016002748161554337, 0.00023922598241673162, and 0.00017315773341882354\n",
      "Epoch [1609/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014764660930571456, 0.0002294838292679439, and 0.0001678609405644238\n",
      "Epoch [1610/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014438666985370219, 0.00022984781632355103, and 0.00016213307389989495\n",
      "Epoch [1611/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001215334205577771, 0.00021767575526610017, and 0.0001583485136507079\n",
      "Epoch [1612/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013815598213113844, 0.0002376006693035985, and 0.00016352279635611922\n",
      "Epoch [1613/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014821768660719197, 0.00023663143413917473, and 0.00016920937438650677\n",
      "Epoch [1614/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001645481213927269, 0.0002536113897804171, and 0.00017197140793238455\n",
      "Epoch [1615/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001557627033131818, 0.000236801992286928, and 0.00016764997417340055\n",
      "Epoch [1616/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0014926729685006042, 0.00022339922240159163, and 0.0001665401529559555\n",
      "Epoch [1617/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014327748795039952, 0.00024305325738775233, and 0.00015962194690170387\n",
      "Epoch [1618/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001466435962356627, 0.00023628379373500744, and 0.00016387140203732997\n",
      "Epoch [1619/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014682174272214372, 0.00023212650557979941, and 0.0001627376016889078\n",
      "Epoch [1620/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016759948145287733, 0.00024806334113236517, and 0.00017364505038131028\n",
      "Epoch [1621/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018018994402761261, 0.00024365787976421416, and 0.0001710431218574134\n",
      "Epoch [1622/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001710529070502768, 0.00024714769097045064, and 0.0001703600307034018\n",
      "Epoch [1623/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018344562655935686, 0.0002778660273179412, and 0.0001711188864040499\n",
      "Epoch [1624/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0017712217328759532, 0.0002773175753342609, and 0.00017040191596606746\n",
      "Epoch [1625/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0016908733329425256, 0.0002487262390786782, and 0.00016913743456825614\n",
      "Epoch [1626/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001690552899769197, 0.00024357247457373887, and 0.00016423521204463518\n",
      "Epoch [1627/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001734516175929457, 0.0002343753343059992, and 0.0001633272913750261\n",
      "Epoch [1628/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013870190208156903, 0.0002083103609038517, and 0.00015686641806193316\n",
      "Epoch [1629/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0012949226850954194, 0.0002140457606098304, and 0.00015042340237414464\n",
      "Epoch [1630/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012350041652098298, 0.0002040980034507811, and 0.00015138847569081312\n",
      "Epoch [1631/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001191805718311419, 0.00018848394392989576, and 0.0001515958744372862\n",
      "Epoch [1632/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014301577466540039, 0.0002270998666062951, and 0.0001567228367396941\n",
      "Epoch [1633/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.001528431350986163, 0.00024261069969118884, and 0.00015972234056486437\n",
      "Epoch [1634/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016486170934513211, 0.00024049319229864827, and 0.00016280374984489754\n",
      "Epoch [1635/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0018066222352596621, 0.00029018002775652957, and 0.00016741722113996124\n",
      "Epoch [1636/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.001890800738086303, 0.0002918265575620656, and 0.00017360307295651486\n",
      "Epoch [1637/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.0018163521696502964, 0.00026562592150488246, and 0.00016346932049297416\n",
      "Epoch [1638/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0019177669892087579, 0.0002520545628309871, and 0.0001649873762895974\n",
      "Epoch [1639/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015674813960989316, 0.00022513442187725255, and 0.00015347777177036429\n",
      "Epoch [1640/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013162562972865999, 0.00019872218157009533, and 0.00015058673792130625\n",
      "Epoch [1641/2000], Train Loss: 0.0004, Test Loss: 0.0005\n",
      "The metrics are: 0.0012495391614114244, 0.0001959944008073459, and 0.00014665650572472563\n",
      "Epoch [1642/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011897906467008095, 0.00020481152751017362, and 0.0001436923945827099\n",
      "Epoch [1643/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0011479350505396724, 0.0001962608463751773, and 0.00014484579636094472\n",
      "Epoch [1644/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013678240356966853, 0.00020218520755103478, and 0.00015083575029469407\n",
      "Epoch [1645/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001497164349226902, 0.00020729816363503536, and 0.00015507688416012874\n",
      "Epoch [1646/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001448694965802133, 0.00021068456893165907, and 0.00015285465876028562\n",
      "Epoch [1647/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001362135886059453, 0.00020727716522136083, and 0.0001536229052968944\n",
      "Epoch [1648/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014999608780878286, 0.00020885360815251866, and 0.0001549925315581883\n",
      "Epoch [1649/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015854486264288425, 0.0002304155689974626, and 0.00015698891608432555\n",
      "Epoch [1650/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0014893683643701177, 0.00022034418361727148, and 0.0001520542379391069\n",
      "Epoch [1651/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013712512833687167, 0.0002181840924701343, and 0.0001462951986468397\n",
      "Epoch [1652/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001412723174629112, 0.00023912385222502053, and 0.0001487587263303188\n",
      "Epoch [1653/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001504047152896722, 0.00021018690798276415, and 0.0001484658059780486\n",
      "Epoch [1654/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014245717126565676, 0.00022886066290084273, and 0.00014909751674470803\n",
      "Epoch [1655/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0014910445315763354, 0.0002143186138710007, and 0.00015232839844732857\n",
      "Epoch [1656/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016893119900487363, 0.00025155796902254224, and 0.00015700271372528127\n",
      "Epoch [1657/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018551432294771075, 0.0002612610599802186, and 0.00016133263852680102\n",
      "Epoch [1658/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.0019881040401135883, 0.0002605903525060664, and 0.0001613975230914851\n",
      "Epoch [1659/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0022101161691049733, 0.00029125075282839436, and 0.00016295907941336432\n",
      "Epoch [1660/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001966281638791164, 0.0002491491565403218, and 0.00015814953803783283\n",
      "Epoch [1661/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015709489428748686, 0.0002260377223137766, and 0.00014613793852428594\n",
      "Epoch [1662/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0011006982628411304, 0.00017935210053110495, and 0.00013511245439682776\n",
      "Epoch [1663/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0010894331790041178, 0.00016825179530618092, and 0.00013731516567834964\n",
      "Epoch [1664/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.00116936915825742, 0.00018193545110989362, and 0.00013465399873287728\n",
      "Epoch [1665/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001172167268426468, 0.00017748558699774245, and 0.0001345851705991663\n",
      "Epoch [1666/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011552141319649916, 0.000179050582422254, and 0.0001369415913359262\n",
      "Epoch [1667/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012822566592755418, 0.00019246571658489606, and 0.00014028923518101996\n",
      "Epoch [1668/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0013641064676145713, 0.00020969793937789896, and 0.00013911885374303287\n",
      "Epoch [1669/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0013453384744934738, 0.00019322124232227603, and 0.00013883651263313368\n",
      "Epoch [1670/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001223942400732388, 0.00018731104743589336, and 0.0001345207832249192\n",
      "Epoch [1671/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013931626842046778, 0.00023701039996619025, and 0.0001437156849230329\n",
      "Epoch [1672/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015416474003965657, 0.0002675966873842602, and 0.0001547805683609719\n",
      "Epoch [1673/2000], Train Loss: 0.0004, Test Loss: 0.0010\n",
      "The metrics are: 0.001941807024801771, 0.00025312003466145444, and 0.00016180938352287436\n",
      "Epoch [1674/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.002017251953172187, 0.00025771027624917525, and 0.0001550595261505805\n",
      "Epoch [1675/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0018928003264591098, 0.0002469363098498434, and 0.00015039209877916923\n",
      "Epoch [1676/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0014669548836536705, 0.00021734834687473872, and 0.00013832220914385593\n",
      "Epoch [1677/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013210358835446339, 0.0002010516570104907, and 0.00013616726694939038\n",
      "Epoch [1678/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001468542623721684, 0.00020270268093251312, and 0.0001402790512656793\n",
      "Epoch [1679/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0013918480059752862, 0.0001990783906270129, and 0.00014414886148491254\n",
      "Epoch [1680/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0015670207988781233, 0.00021651706386667988, and 0.000146301101873784\n",
      "Epoch [1681/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017137210040042798, 0.0002312344586243853, and 0.00015907319902908057\n",
      "Epoch [1682/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0017502105329185724, 0.00022305516661920896, and 0.00014672443649033085\n",
      "Epoch [1683/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.001630672214863201, 0.00020788558079705885, and 0.00013988690382878607\n",
      "Epoch [1684/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001394638849887997, 0.00018993990912955874, and 0.00013500276691047475\n",
      "Epoch [1685/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012452962109819055, 0.00017766919336281717, and 0.000130967809430634\n",
      "Epoch [1686/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001250525441719219, 0.0001684133288411734, and 0.0001340014326463764\n",
      "Epoch [1687/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012835710658691823, 0.00019848720209362605, and 0.0001316908722704587\n",
      "Epoch [1688/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014819235657341778, 0.0002271446477000912, and 0.00014129356956497455\n",
      "Epoch [1689/2000], Train Loss: 0.0003, Test Loss: 0.0008\n",
      "The metrics are: 0.0016963278564314048, 0.00022906306548975408, and 0.00014349979028338566\n",
      "Epoch [1690/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0018312563188374043, 0.00024288101606847098, and 0.00014193188447582847\n",
      "Epoch [1691/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001481174510748436, 0.0002096626049024053, and 0.00013306930971642336\n",
      "Epoch [1692/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015674868676190574, 0.0002074652050699418, and 0.00013649810231678808\n",
      "Epoch [1693/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001611269040343662, 0.00020439045814176401, and 0.00013619066400375837\n",
      "Epoch [1694/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015600074354248743, 0.00020697981623622277, and 0.00013277571997605264\n",
      "Epoch [1695/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013280634690696995, 0.0001949364013853483, and 0.00012903899187222123\n",
      "Epoch [1696/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013032397934390854, 0.0001751357024962393, and 0.00013049271850225827\n",
      "Epoch [1697/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013117103565794725, 0.0001785336595882351, and 0.0001289106827850143\n",
      "Epoch [1698/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014228736787724, 0.000183999611181207, and 0.0001309103608946316\n",
      "Epoch [1699/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.00134288240224123, 0.00018087613473956785, and 0.00012748075823765248\n",
      "Epoch [1700/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012567034282255918, 0.0001778209989424795, and 0.00012608412847233316\n",
      "Epoch [1701/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001450488130406787, 0.0002102580814001461, and 0.00013454910852791122\n",
      "Epoch [1702/2000], Train Loss: 0.0003, Test Loss: 0.0008\n",
      "The metrics are: 0.0015185682762724657, 0.00019196684782703718, and 0.0001374332957008543\n",
      "Epoch [1703/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016487285611219704, 0.00019634088675957173, and 0.0001383285659054915\n",
      "Epoch [1704/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015638345503248274, 0.00019268404381970564, and 0.00013311236155762648\n",
      "Epoch [1705/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016317706904374063, 0.0002142031468489828, and 0.00013430896312153587\n",
      "Epoch [1706/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016261485676902037, 0.00019289385333346823, and 0.00013427114754449576\n",
      "Epoch [1707/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014219986818109949, 0.00018705165469630933, and 0.0001292161517388498\n",
      "Epoch [1708/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0014427405743238826, 0.00019446262983061993, and 0.0001271976022205005\n",
      "Epoch [1709/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014574167241031926, 0.00021281383912234256, and 0.00013180894165998325\n",
      "Epoch [1710/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0017108786075065534, 0.0002050775001407601, and 0.0001375174664038544\n",
      "Epoch [1711/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016126927609244983, 0.00020360562727243328, and 0.00013355332096883407\n",
      "Epoch [1712/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0019491924710261326, 0.0002273074690795814, and 0.00014332604526619738\n",
      "Epoch [1713/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0021068109587455788, 0.0002371020940093634, and 0.0001512628781104771\n",
      "Epoch [1714/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0019753732485696673, 0.00022571539254082987, and 0.00013768647477263585\n",
      "Epoch [1715/2000], Train Loss: 0.0005, Test Loss: 0.0007\n",
      "The metrics are: 0.0016667129239067435, 0.0002010469906963408, and 0.00013239102069443712\n",
      "Epoch [1716/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001357146034327646, 0.00016886935918591917, and 0.00012709093183123818\n",
      "Epoch [1717/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0010952999776539702, 0.00016124913721190146, and 0.00011970094540932526\n",
      "Epoch [1718/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0010858382156584412, 0.0001538347035724049, and 0.00012108741308717678\n",
      "Epoch [1719/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011109186161775142, 0.00014728696987731382, and 0.00011858073169908796\n",
      "Epoch [1720/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011754675263849397, 0.00016026892020211866, and 0.00011945049239632984\n",
      "Epoch [1721/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011775628857625027, 0.0001581336255185306, and 0.00011895776697201654\n",
      "Epoch [1722/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001147121035804351, 0.00015900973327613124, and 0.00012165410347127666\n",
      "Epoch [1723/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0010973477619700134, 0.00015387213837432986, and 0.00011756739938088383\n",
      "Epoch [1724/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001349260312660287, 0.0001877694642947366, and 0.00012376900849631056\n",
      "Epoch [1725/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014000680724469323, 0.0002093911898555234, and 0.00012953122010609755\n",
      "Epoch [1726/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001790178978505234, 0.00021195583152196681, and 0.0001410640810111848\n",
      "Epoch [1727/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018239501708497603, 0.00021310459608988216, and 0.00013350104563869536\n",
      "Epoch [1728/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.002020161075051874, 0.00024123195422968516, and 0.00014250238746171817\n",
      "Epoch [1729/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0016871154075488448, 0.00022060424331963682, and 0.00013300800249756625\n",
      "Epoch [1730/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.0015655575746980805, 0.00020178666697271788, and 0.00012909506040159613\n",
      "Epoch [1731/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014470588066615164, 0.0001802621676082102, and 0.00012694205361185595\n",
      "Epoch [1732/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013660921637589734, 0.00017000058384534592, and 0.00012252392480149865\n",
      "Epoch [1733/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012813806242775172, 0.00017194680064373338, and 0.00012324995865734914\n",
      "Epoch [1734/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0016171788059485455, 0.00018485668503368893, and 0.00012832010300674787\n",
      "Epoch [1735/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016473168119167287, 0.0002013657140196301, and 0.00012771275942213833\n",
      "Epoch [1736/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014294888242147863, 0.0001765685883583501, and 0.0001213062641909346\n",
      "Epoch [1737/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0012838942542051275, 0.0001708102208795026, and 0.00011871182020210351\n",
      "Epoch [1738/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014557799828859668, 0.00017773277795640752, and 0.00012091912261287992\n",
      "Epoch [1739/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0011955318914260715, 0.0001538744181743823, and 0.00011533309104076277\n",
      "Epoch [1740/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011804750344405572, 0.00015342177842588475, and 0.00011477618924497317\n",
      "Epoch [1741/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013785071787424386, 0.00016400691189725572, and 0.00011853720449532072\n",
      "Epoch [1742/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013107439735904336, 0.00018447215309909856, and 0.00011846397683257237\n",
      "Epoch [1743/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015097801224328578, 0.0001834111002002222, and 0.00012405822296083593\n",
      "Epoch [1744/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001716914683735619, 0.00020131454706036797, and 0.0001359662516430641\n",
      "Epoch [1745/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0017553291205937664, 0.0002121539412958858, and 0.0001304092220379971\n",
      "Epoch [1746/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0018468201354456444, 0.00020833904757940522, and 0.00012862518876014897\n",
      "Epoch [1747/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0015834102329487603, 0.00019135213369736448, and 0.0001245614475919865\n",
      "Epoch [1748/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0015586109948344529, 0.00019460413265430057, and 0.00012159770509848992\n",
      "Epoch [1749/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013915592474707712, 0.0001709700251619021, and 0.00011972455104114488\n",
      "Epoch [1750/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014958217507228255, 0.00018019089717806006, and 0.00012390376165664443\n",
      "Epoch [1751/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0017077446294327576, 0.00018699134428364536, and 0.00012794773889860758\n",
      "Epoch [1752/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014382601075340062, 0.000163402539328672, and 0.00012010794550102825\n",
      "Epoch [1753/2000], Train Loss: 0.0004, Test Loss: 0.0005\n",
      "The metrics are: 0.0012563544247920315, 0.0001553358257903407, and 0.00011517687138014783\n",
      "Epoch [1754/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012393454477811854, 0.00016006722338109589, and 0.00011516749024546395\n",
      "Epoch [1755/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014737854750516515, 0.0001900402203318663, and 0.00012433077305710563\n",
      "Epoch [1756/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014873305917717516, 0.00018081180072234324, and 0.00012382758480574316\n",
      "Epoch [1757/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014933929584609966, 0.0001912223572920387, and 0.00011969710734168378\n",
      "Epoch [1758/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015987060614861548, 0.00020347068493720144, and 0.0001230791604029946\n",
      "Epoch [1759/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0014677014745151002, 0.00018300864273138964, and 0.00012115966577160482\n",
      "Epoch [1760/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015694641624577343, 0.00016933936664524177, and 0.0001233014918398112\n",
      "Epoch [1761/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014530721819028258, 0.00016879798931768164, and 0.00011675293353619054\n",
      "Epoch [1762/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014295584793823461, 0.0001588076823585046, and 0.000115708203035562\n",
      "Epoch [1763/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014576124667655677, 0.0001624970609555021, and 0.00011750150830872978\n",
      "Epoch [1764/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012755090817033003, 0.00016487846248007068, and 0.00011361568613210693\n",
      "Epoch [1765/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013757237854103248, 0.00015384198923129588, and 0.00012142150808358565\n",
      "Epoch [1766/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014056843744280438, 0.00016191347094718367, and 0.00011773531878134236\n",
      "Epoch [1767/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013417010777629912, 0.00016616449283901602, and 0.00011788779132378598\n",
      "Epoch [1768/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001594245220379283, 0.00018674579284076268, and 0.00012153827507669727\n",
      "Epoch [1769/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0014527539412180583, 0.00017295598566609746, and 0.0001149930455236851\n",
      "Epoch [1770/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0014697445246080558, 0.00017131661297753453, and 0.00011590542514265205\n",
      "Epoch [1771/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014539370701337855, 0.00018362323802042133, and 0.00011389418068574741\n",
      "Epoch [1772/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014162145865460236, 0.000163999049012394, and 0.00011326693008110549\n",
      "Epoch [1773/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013214351686959465, 0.00016674642877963683, and 0.00011094534905472149\n",
      "Epoch [1774/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001451904943678528, 0.00016383484520095712, and 0.00011376288239262067\n",
      "Epoch [1775/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012455548567231745, 0.0001576348367962055, and 0.00010962674908417587\n",
      "Epoch [1776/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013889836651893954, 0.0001729120461580654, and 0.00011550675602241729\n",
      "Epoch [1777/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.001606635768742611, 0.00017480601430482542, and 0.00012293048348510638\n",
      "Epoch [1778/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0017639255383983254, 0.0002042467191737766, and 0.00013472652062773705\n",
      "Epoch [1779/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0018982812374209364, 0.00021960894082440063, and 0.00012689566574408673\n",
      "Epoch [1780/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0020544248400256038, 0.00020898420916637406, and 0.0001281688916302907\n",
      "Epoch [1781/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017436475221378107, 0.00020598131231963634, and 0.00012413507890111455\n",
      "Epoch [1782/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001483554602600634, 0.00018217678007204086, and 0.00011388517790085946\n",
      "Epoch [1783/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0013232300601278741, 0.0001532084061182104, and 0.00011106996195546041\n",
      "Epoch [1784/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012921394178799044, 0.00014843947186212367, and 0.00011185884795850143\n",
      "Epoch [1785/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001379499735776335, 0.00015900299088874212, and 0.00011090940703676704\n",
      "Epoch [1786/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001225073045740525, 0.00014621789644782743, and 0.00010891023945684235\n",
      "Epoch [1787/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013020891152943175, 0.00014749398057271415, and 0.00010745572096008497\n",
      "Epoch [1788/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012582648002232115, 0.0001412554750762259, and 0.00010921932456161206\n",
      "Epoch [1789/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011939425409461062, 0.00014258090474565202, and 0.00010546553433717538\n",
      "Epoch [1790/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011170627840328962, 0.00013355758225467676, and 0.00010277642286382616\n",
      "Epoch [1791/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.00103883066913113, 0.00014256494614528492, and 9.896892152028158e-05\n",
      "Epoch [1792/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012270772034147133, 0.0001539992226753384, and 0.00010371958463413951\n",
      "Epoch [1793/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0011545383895281702, 0.00014232406344187135, and 0.00010298337050092717\n",
      "Epoch [1794/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013394247507676482, 0.00016047089593484998, and 0.00011564947635633871\n",
      "Epoch [1795/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.001658502248271058, 0.0001942317709714795, and 0.0001277032946139419\n",
      "Epoch [1796/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0021539600177978477, 0.00022659751994069666, and 0.0001401895339464924\n",
      "Epoch [1797/2000], Train Loss: 0.0005, Test Loss: 0.0011\n",
      "The metrics are: 0.002520791837014258, 0.0002450960867766601, and 0.0001369631839528059\n",
      "Epoch [1798/2000], Train Loss: 0.0005, Test Loss: 0.0010\n",
      "The metrics are: 0.0017935543437488377, 0.00018912354183460897, and 0.00011822391631236921\n",
      "Epoch [1799/2000], Train Loss: 0.0005, Test Loss: 0.0006\n",
      "The metrics are: 0.001550052547827363, 0.00018949709192384034, and 0.00011335655411433739\n",
      "Epoch [1800/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0014504127805897344, 0.0001538850823029255, and 0.00011027535947505385\n",
      "Epoch [1801/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011040704945723216, 0.00013637009639448175, and 0.00010215913789579645\n",
      "Epoch [1802/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0010576072284796585, 0.00012816958769690245, and 9.922509586128096e-05\n",
      "Epoch [1803/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0009899911237880588, 0.00012480042641982436, and 9.934865374816582e-05\n",
      "Epoch [1804/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0010365287695700924, 0.00012972252685964727, and 9.895843444004034e-05\n",
      "Epoch [1805/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0010424600720095138, 0.0001253662776434794, and 0.00010291859750092651\n",
      "Epoch [1806/2000], Train Loss: 0.0002, Test Loss: 0.0005\n",
      "The metrics are: 0.001302051842988779, 0.00014592535202003395, and 0.00010985709620096411\n",
      "Epoch [1807/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0013948945561423898, 0.00016263968427665532, and 0.00011432320752646774\n",
      "Epoch [1808/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016918521141633391, 0.0001908746489789337, and 0.00011970653213211335\n",
      "Epoch [1809/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.001718907985681047, 0.00018284345424035564, and 0.00011574272502912208\n",
      "Epoch [1810/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0017696062568575144, 0.00020877213440447426, and 0.00011584534149733372\n",
      "Epoch [1811/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017221125114398699, 0.00021747139059395218, and 0.00011628729771473445\n",
      "Epoch [1812/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0018253519277398784, 0.00020508051238721237, and 0.00011974107110290788\n",
      "Epoch [1813/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017055592422063153, 0.00018137293227482587, and 0.00011412750609451905\n",
      "Epoch [1814/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016518802343246837, 0.00017622224307463816, and 0.00011399828993792956\n",
      "Epoch [1815/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015878928049157064, 0.00016836472544431066, and 0.00011378401662417066\n",
      "Epoch [1816/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0015544431904951732, 0.00016101490958438566, and 0.00011176698293032435\n",
      "Epoch [1817/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014384365446555118, 0.0001417025511424678, and 0.00011024467191115643\n",
      "Epoch [1818/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011767660616897047, 0.00013254029909148812, and 0.00010006593705232565\n",
      "Epoch [1819/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.000965764270707344, 0.00011653278003601979, and 9.579559506770845e-05\n",
      "Epoch [1820/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0010856777565398563, 0.00012661770597333089, and 9.760133495243888e-05\n",
      "Epoch [1821/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0011080382197784882, 0.0001226448657689616, and 9.815719749894924e-05\n",
      "Epoch [1822/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0011474451166577637, 0.0001305399249152591, and 9.769010648597032e-05\n",
      "Epoch [1823/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001202054098636533, 0.00013337316340766847, and 9.926152294307637e-05\n",
      "Epoch [1824/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011592579636878024, 0.00013448393292492256, and 0.00010142636165255681\n",
      "Epoch [1825/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013645246896582346, 0.0001570795260098142, and 0.00010958031392268215\n",
      "Epoch [1826/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0017436981628028054, 0.00019272724118006104, and 0.00011729872615736288\n",
      "Epoch [1827/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0021039098501205444, 0.00022445143258664757, and 0.00012892537415609695\n",
      "Epoch [1828/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.0018568808833758037, 0.00021198021568125114, and 0.00011621386875049211\n",
      "Epoch [1829/2000], Train Loss: 0.0005, Test Loss: 0.0008\n",
      "The metrics are: 0.001676522835623473, 0.00017175984976347536, and 0.0001094384933821857\n",
      "Epoch [1830/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0012936913893402864, 0.00016018703414980942, and 9.975502325687557e-05\n",
      "Epoch [1831/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012302501709200442, 0.00014720620917311558, and 9.848079692649965e-05\n",
      "Epoch [1832/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001243172853719443, 0.00014298520545708016, and 0.00010041472948311518\n",
      "Epoch [1833/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013583409405934315, 0.00014922735620833313, and 0.00010477318695241895\n",
      "Epoch [1834/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0016276857738072674, 0.00017367088973211745, and 0.00010863449764049922\n",
      "Epoch [1835/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016147939022630453, 0.00017511983848332116, and 0.00010625257588496122\n",
      "Epoch [1836/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0013469021262911458, 0.00016217611603982127, and 0.00010120065053342842\n",
      "Epoch [1837/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001418996718712151, 0.00014448189176619053, and 0.00010283522715326399\n",
      "Epoch [1838/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0016167719149962068, 0.00017443502535267422, and 0.00010521209575623895\n",
      "Epoch [1839/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0013197528508802254, 0.00015057338653908422, and 9.992558504260766e-05\n",
      "Epoch [1840/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014406401411785434, 0.0001536627702686625, and 0.00010384819446092781\n",
      "Epoch [1841/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001681556401308626, 0.0001757350328261964, and 0.00010884502868672523\n",
      "Epoch [1842/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0016177076613530517, 0.00017199238694350547, and 0.00010876615488086827\n",
      "Epoch [1843/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0015408390124017994, 0.00015045668017895272, and 0.0001029127949247292\n",
      "Epoch [1844/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015616512391716242, 0.00015490644000237808, and 0.00010363938417867757\n",
      "Epoch [1845/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013452218651461105, 0.0001469399818840126, and 0.00010577832775500913\n",
      "Epoch [1846/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013644175487570465, 0.00010835789968647684, and 0.00023950732429511845\n",
      "Epoch [1847/2000], Train Loss: 0.0003, Test Loss: 0.0013\n",
      "The metrics are: 0.001957489992491901, 0.0001947118119763521, and 0.00014713556205000108\n",
      "Epoch [1848/2000], Train Loss: 0.0005, Test Loss: 0.0004\n",
      "The metrics are: 0.0009157176925024638, 0.00012824233999708667, and 0.0001107487211508366\n",
      "Epoch [1849/2000], Train Loss: 0.0002, Test Loss: 0.0003\n",
      "The metrics are: 0.0010223490729307134, 0.00012416421911135936, and 9.637737336258094e-05\n",
      "Epoch [1850/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0010566968412604183, 0.00012838160910177976, and 9.52208198820396e-05\n",
      "Epoch [1851/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.001342328090686351, 0.0001544485033567374, and 0.00010186118743149564\n",
      "Epoch [1852/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015019829540203016, 0.00017705832093876475, and 0.00010976718355474684\n",
      "Epoch [1853/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0017323427794811626, 0.00017849073871426904, and 0.00011186066452258576\n",
      "Epoch [1854/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015348220864931743, 0.00017220046720467508, and 0.0001076031173094331\n",
      "Epoch [1855/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0017713650595396757, 0.00018172601266996935, and 0.00011438533814119485\n",
      "Epoch [1856/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0018406177405267954, 0.0001879497964788849, and 0.00011017023037614611\n",
      "Epoch [1857/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0018361765348042052, 0.00019989213130126396, and 0.00011174708197358996\n",
      "Epoch [1858/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0016835121593127649, 0.00021583856141660362, and 0.00010787999417516403\n",
      "Epoch [1859/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0017235443907945107, 0.00018187288272505006, and 0.00011046852281045479\n",
      "Epoch [1860/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0016026803059503436, 0.0001719808642519638, and 0.00010699702761485241\n",
      "Epoch [1861/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.001528566557681188, 0.00014929858055741838, and 0.00010591521398358357\n",
      "Epoch [1862/2000], Train Loss: 0.0004, Test Loss: 0.0005\n",
      "The metrics are: 0.0014132493524812162, 0.0001364851753654269, and 0.00010347723339994748\n",
      "Epoch [1863/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012461960335106899, 0.00013188814045861363, and 9.753805958704713e-05\n",
      "Epoch [1864/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0010737934110996623, 0.00011303611487771074, and 9.474309141902874e-05\n",
      "Epoch [1865/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0009041283337865025, 0.00010098311274001996, and 9.08091072536384e-05\n",
      "Epoch [1866/2000], Train Loss: 0.0002, Test Loss: 0.0003\n",
      "The metrics are: 0.0009463265887461603, 0.00010530586102201293, and 8.90408300620038e-05\n",
      "Epoch [1867/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.001015594636555761, 0.00011980659473920241, and 9.157845367250654e-05\n",
      "Epoch [1868/2000], Train Loss: 0.0002, Test Loss: 0.0005\n",
      "The metrics are: 0.0013981880232070882, 0.00014632692909799516, and 9.821162651254174e-05\n",
      "Epoch [1869/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014433962254164119, 0.00014735976583324373, and 9.908903545389573e-05\n",
      "Epoch [1870/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001382974461497118, 0.00014215893073317906, and 9.819916279714865e-05\n",
      "Epoch [1871/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001214246479018281, 0.0001379795115402279, and 9.28821476312199e-05\n",
      "Epoch [1872/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001211482488239805, 0.00012623139385444423, and 9.363506008715679e-05\n",
      "Epoch [1873/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0010953301195210468, 0.00012078502913936973, and 9.050200484731856e-05\n",
      "Epoch [1874/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0011257447282938908, 0.00012852374493377283, and 9.215807585860603e-05\n",
      "Epoch [1875/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012826748522153746, 0.00014116271146728346, and 9.640768500200163e-05\n",
      "Epoch [1876/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001332060870481655, 0.00014708302236006907, and 0.00010165867570322007\n",
      "Epoch [1877/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0017373533143351476, 0.00018686130109320706, and 0.00012889655287532756\n",
      "Epoch [1878/2000], Train Loss: 0.0003, Test Loss: 0.0010\n",
      "The metrics are: 0.0021139351883903146, 0.00021599863248411566, and 0.00011801709964250524\n",
      "Epoch [1879/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.002682150031129519, 0.00026481021389675635, and 0.00012463898383430205\n",
      "Epoch [1880/2000], Train Loss: 0.0005, Test Loss: 0.0009\n",
      "The metrics are: 0.001742914377246052, 0.00017695063191543645, and 0.00011151625706891839\n",
      "Epoch [1881/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0016283464695637424, 0.00017444256809540093, and 0.0001023873458810461\n",
      "Epoch [1882/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0014316846694176395, 0.00016035124766252315, and 9.816355183526564e-05\n",
      "Epoch [1883/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001331464455385382, 0.00014180814954064166, and 9.538024338932398e-05\n",
      "Epoch [1884/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013919047293408464, 0.00014554850592200333, and 9.560886125351924e-05\n",
      "Epoch [1885/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014205110977248598, 0.0001393970160279423, and 9.623347674884523e-05\n",
      "Epoch [1886/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013773698592558503, 0.00013270574709167704, and 9.562048217048869e-05\n",
      "Epoch [1887/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0012200617832907785, 0.00011534814620972611, and 9.303418482886627e-05\n",
      "Epoch [1888/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0011414409091230482, 0.0001229491075112795, and 8.870659924771947e-05\n",
      "Epoch [1889/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0011312671219153951, 0.00012686178524745628, and 8.999705823953263e-05\n",
      "Epoch [1890/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012739931019799162, 0.00012988744735290916, and 9.60521671610574e-05\n",
      "Epoch [1891/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013796140750249226, 0.00013076489267405123, and 9.508967195870355e-05\n",
      "Epoch [1892/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013501491824475427, 0.00013701673378818668, and 9.475964422260101e-05\n",
      "Epoch [1893/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012105579662602395, 0.00012214594001610143, and 9.464417113728511e-05\n",
      "Epoch [1894/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0013604865525849164, 0.00015200563211692497, and 9.687640461682652e-05\n",
      "Epoch [1895/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0016242251731455326, 0.00017604045327364778, and 0.00010920432881296922\n",
      "Epoch [1896/2000], Train Loss: 0.0003, Test Loss: 0.0008\n",
      "The metrics are: 0.0018917587973798315, 0.00018729358513761932, and 0.00011237319752884407\n",
      "Epoch [1897/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0021422842983156443, 0.0002082954354894658, and 0.0001200310204391523\n",
      "Epoch [1898/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0019283909156608086, 0.00017231120364158414, and 0.00010637951102883865\n",
      "Epoch [1899/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0012973319389857352, 0.0001295421679969877, and 9.794417686255959e-05\n",
      "Epoch [1900/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0010220828407909721, 0.00011380189365202871, and 8.739917999870765e-05\n",
      "Epoch [1901/2000], Train Loss: 0.0002, Test Loss: 0.0003\n",
      "The metrics are: 0.0010709347649632643, 0.00011258574159001, and 8.717862510820851e-05\n",
      "Epoch [1902/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.001079363952158019, 0.00011258730713355665, and 8.898711287959789e-05\n",
      "Epoch [1903/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0012099728919565678, 0.00011523171027268593, and 9.644521196605638e-05\n",
      "Epoch [1904/2000], Train Loss: 0.0002, Test Loss: 0.0005\n",
      "The metrics are: 0.001415985927451402, 0.0001304432395651626, and 9.587979366187938e-05\n",
      "Epoch [1905/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013214015828755994, 0.00013417504912164682, and 9.079844191243562e-05\n",
      "Epoch [1906/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013711299203957121, 0.00013314717701481035, and 9.49769443347274e-05\n",
      "Epoch [1907/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013810277838880818, 0.00013752038163753846, and 9.30514870560728e-05\n",
      "Epoch [1908/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013392838106180231, 0.0001472017441604597, and 9.170056364382617e-05\n",
      "Epoch [1909/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013100134674459696, 0.00014653032606778046, and 9.059689667386313e-05\n",
      "Epoch [1910/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001312865080156674, 0.0001520067138092903, and 9.57946516185378e-05\n",
      "Epoch [1911/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0016386519030978282, 0.00017810586238435158, and 0.00010369144971870507\n",
      "Epoch [1912/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0018171359164019425, 0.00018880329541085908, and 0.0001100923461005247\n",
      "Epoch [1913/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017947635302941005, 0.0001686883442744147, and 0.00010913473427838956\n",
      "Epoch [1914/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.0015809234076490004, 0.00016289244983151244, and 0.00010060801408447635\n",
      "Epoch [1915/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0014597710299616058, 0.00014321698351219916, and 9.98352164363799e-05\n",
      "Epoch [1916/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013418837916105986, 0.000132359862618614, and 9.713132264247785e-05\n",
      "Epoch [1917/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001480762497521937, 0.00013893171004989804, and 9.32431854986741e-05\n",
      "Epoch [1918/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012915691477246583, 0.00012553034078640243, and 9.112362628608632e-05\n",
      "Epoch [1919/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0011972482898272574, 0.00012028203733886282, and 8.928106763050891e-05\n",
      "Epoch [1920/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0010304943813631933, 0.00010286259202985093, and 8.606181169549625e-05\n",
      "Epoch [1921/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.001132584671722725, 0.00011207529072028895, and 8.872597633550565e-05\n",
      "Epoch [1922/2000], Train Loss: 0.0002, Test Loss: 0.0005\n",
      "The metrics are: 0.0012471450803180535, 0.00011518728448815334, and 9.04324660950806e-05\n",
      "Epoch [1923/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012195891079803307, 0.00011777580099684808, and 8.933720770680036e-05\n",
      "Epoch [1924/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012089773081243038, 0.00012507986320997588, and 8.771032056150337e-05\n",
      "Epoch [1925/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001485053663297246, 0.000148568621322435, and 9.987301746150479e-05\n",
      "Epoch [1926/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0015354397473856807, 0.0001480281716794707, and 9.462547556419547e-05\n",
      "Epoch [1927/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015594458091072738, 0.00014195266097279577, and 9.51924472853231e-05\n",
      "Epoch [1928/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014566266230152298, 0.00013667333769262768, and 9.299539791148466e-05\n",
      "Epoch [1929/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014190663544771571, 0.00013884282331370437, and 9.094455284260523e-05\n",
      "Epoch [1930/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014391795460445185, 0.00015059418850190318, and 9.430223629654695e-05\n",
      "Epoch [1931/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0018588321981951594, 0.0001764317239576485, and 0.00010754113342651787\n",
      "Epoch [1932/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017967841704376042, 0.00016366491642353745, and 0.00010394796845503151\n",
      "Epoch [1933/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001549568686944743, 0.00013509900115119913, and 9.776115257409401e-05\n",
      "Epoch [1934/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014189471063824992, 0.0001393717769436383, and 9.002950173453428e-05\n",
      "Epoch [1935/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.00124711977938811, 0.00012843252746582343, and 8.768821984025028e-05\n",
      "Epoch [1936/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013623873237520456, 0.00013601237151306123, and 8.854754681427342e-05\n",
      "Epoch [1937/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012205727010344465, 0.00012675900870817713, and 8.593716362762886e-05\n",
      "Epoch [1938/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0010596673625210922, 0.00010753995957202278, and 8.279249717209798e-05\n",
      "Epoch [1939/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0009529702559423944, 0.00010064951978468646, and 8.051117886983168e-05\n",
      "Epoch [1940/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.001015132690857475, 0.0001024227846452656, and 8.257229759086233e-05\n",
      "Epoch [1941/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0010910177273520578, 0.0001122013612378699, and 8.522470307070762e-05\n",
      "Epoch [1942/2000], Train Loss: 0.0002, Test Loss: 0.0005\n",
      "The metrics are: 0.0014628476734894018, 0.00014063879643799737, and 9.959089463033403e-05\n",
      "Epoch [1943/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016982243202316265, 0.00018179500087474784, and 0.0001080134097719565\n",
      "Epoch [1944/2000], Train Loss: 0.0004, Test Loss: 0.0009\n",
      "The metrics are: 0.0019331379250312846, 0.00018249178659364892, and 0.00010939036656054668\n",
      "Epoch [1945/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0020262206283708415, 0.00019442698127628924, and 0.00010750228951413494\n",
      "Epoch [1946/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.001785356745434304, 0.00015207732697793594, and 0.00010193928149722827\n",
      "Epoch [1947/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0011961038010971, 0.00012053793155549404, and 8.775428311006787e-05\n",
      "Epoch [1948/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0011332503248316546, 0.000112923190802879, and 8.43054161426456e-05\n",
      "Epoch [1949/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0011432658648118377, 0.00011306159528127561, and 8.526110468665138e-05\n",
      "Epoch [1950/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.001174543615585814, 0.0001102454771171324, and 8.743316114608508e-05\n",
      "Epoch [1951/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0011193146153042715, 0.00010514628229429945, and 8.786588659859262e-05\n",
      "Epoch [1952/2000], Train Loss: 0.0002, Test Loss: 0.0005\n",
      "The metrics are: 0.0012244762813982863, 0.00012290867744013667, and 8.908901872928254e-05\n",
      "Epoch [1953/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012958179771279295, 0.00013141323506715707, and 9.213466061434399e-05\n",
      "Epoch [1954/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015479791909456253, 0.00014002720854477957, and 9.656848487793468e-05\n",
      "Epoch [1955/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0014792539489765961, 0.0001495499564043712, and 8.82692390102117e-05\n",
      "Epoch [1956/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013472079881466925, 0.00012303593393880874, and 8.7107984048392e-05\n",
      "Epoch [1957/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012397596923013527, 0.00012040855896581586, and 8.385981103250136e-05\n",
      "Epoch [1958/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0012586200706815969, 0.00012791893580773225, and 8.540325749587889e-05\n",
      "Epoch [1959/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001370093086734414, 0.00013927186106836112, and 8.798127358507675e-05\n",
      "Epoch [1960/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013594107197908063, 0.00013011504658303844, and 8.729782469648247e-05\n",
      "Epoch [1961/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013255229180989165, 0.0001325029952568002, and 8.704796952467102e-05\n",
      "Epoch [1962/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013691143443187077, 0.00012939500569094284, and 8.864435585564934e-05\n",
      "Epoch [1963/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015127164660952985, 0.00014974652731325477, and 9.428013314997467e-05\n",
      "Epoch [1964/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016402999171987176, 0.00016961733247929564, and 9.964055667902964e-05\n",
      "Epoch [1965/2000], Train Loss: 0.0004, Test Loss: 0.0008\n",
      "The metrics are: 0.0017372235694589715, 0.00015974388588801958, and 9.681258719259252e-05\n",
      "Epoch [1966/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0015559835980335872, 0.00015616307913054092, and 9.39105375437066e-05\n",
      "Epoch [1967/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016255377364965777, 0.00015808518461805457, and 9.352400593343191e-05\n",
      "Epoch [1968/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0015431719948537648, 0.00014263245369268893, and 8.970035560196266e-05\n",
      "Epoch [1969/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0013784295006189495, 0.00012582470420359945, and 8.78052414918784e-05\n",
      "Epoch [1970/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0010876119195017964, 0.00010192927584284917, and 8.133998441432293e-05\n",
      "Epoch [1971/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0009710187635694941, 9.822852249878149e-05, and 7.748427863892478e-05\n",
      "Epoch [1972/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.00102055657771416, 9.571615858779599e-05, and 8.110680209938437e-05\n",
      "Epoch [1973/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0012309294543229043, 0.00012523000744598298, and 8.464584971079603e-05\n",
      "Epoch [1974/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013003369482855003, 0.00012497567392225997, and 8.773970694164746e-05\n",
      "Epoch [1975/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015561638865619898, 0.00014712467843006985, and 9.016485394871172e-05\n",
      "Epoch [1976/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014938566212852795, 0.00014672536902556507, and 8.920568628430677e-05\n",
      "Epoch [1977/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0011168545170221478, 0.00012362371126073413, and 7.966214252519421e-05\n",
      "Epoch [1978/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013313077312583725, 0.0001317673086305149, and 8.528041871613823e-05\n",
      "Epoch [1979/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0013813561430045713, 0.00013983482616216256, and 8.803098535281606e-05\n",
      "Epoch [1980/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014605029524924855, 0.0001420248117938172, and 9.226887292849521e-05\n",
      "Epoch [1981/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0014280278313284118, 0.00013649150059791282, and 8.737371414705801e-05\n",
      "Epoch [1982/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0012083029917751749, 0.00012263336247997358, and 8.220732100501967e-05\n",
      "Epoch [1983/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.0014506184961646795, 0.00014849280463143563, and 8.904563704466757e-05\n",
      "Epoch [1984/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001394965579189981, 0.0001394533367905145, and 8.922026002740797e-05\n",
      "Epoch [1985/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0015857411975351472, 0.00014899677747356085, and 9.390548075316474e-05\n",
      "Epoch [1986/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016868738263535004, 0.00015441190286461884, and 9.842119228172426e-05\n",
      "Epoch [1987/2000], Train Loss: 0.0004, Test Loss: 0.0007\n",
      "The metrics are: 0.001632555911783129, 0.00015382233444446078, and 9.324330191399592e-05\n",
      "Epoch [1988/2000], Train Loss: 0.0004, Test Loss: 0.0006\n",
      "The metrics are: 0.0015811847988516092, 0.000135688762384234, and 9.531660665137072e-05\n",
      "Epoch [1989/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.0016139915290599067, 0.00014706495251933424, and 9.204569869325496e-05\n",
      "Epoch [1990/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "The metrics are: 0.001458597156063964, 0.00012278406696471697, and 9.004091043607332e-05\n",
      "Epoch [1991/2000], Train Loss: 0.0003, Test Loss: 0.0005\n",
      "The metrics are: 0.001127034939903145, 0.00010471280984347686, and 8.207889914046973e-05\n",
      "Epoch [1992/2000], Train Loss: 0.0003, Test Loss: 0.0004\n",
      "The metrics are: 0.0010025247077768047, 9.378650429425761e-05, and 8.071006232057698e-05\n",
      "Epoch [1993/2000], Train Loss: 0.0002, Test Loss: 0.0003\n",
      "The metrics are: 0.0007589053711853921, 7.987588105606847e-05, and 7.35312908849058e-05\n",
      "Epoch [1994/2000], Train Loss: 0.0002, Test Loss: 0.0003\n",
      "The metrics are: 0.0009229465698202451, 0.00010152436637630065, and 7.542494616548841e-05\n",
      "Epoch [1995/2000], Train Loss: 0.0002, Test Loss: 0.0004\n",
      "The metrics are: 0.0011543170548975468, 0.00010933323695401971, and 8.451103349216282e-05\n",
      "Epoch [1996/2000], Train Loss: 0.0002, Test Loss: 0.0005\n",
      "The metrics are: 0.0014890241824711363, 0.0001482318366470281, and 8.93558584114847e-05\n",
      "Epoch [1997/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0016207714409877856, 0.00015392809533902133, and 9.524044192706545e-05\n",
      "Epoch [1998/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0015543345167922478, 0.0001528490089791982, and 8.948376853368245e-05\n",
      "Epoch [1999/2000], Train Loss: 0.0003, Test Loss: 0.0007\n",
      "The metrics are: 0.0013077259063720703, 0.0001341840616078116, and 8.375587155266355e-05\n",
      "Epoch [2000/2000], Train Loss: 0.0003, Test Loss: 0.0006\n",
      "Training finished for firstst derivative\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "L3ModelK3_low = SimpleCNN(n_layers=3, kernel_size=3)\n",
    "\n",
    "train_losses, test_losses = model_training(L3ModelK3_low, train_dataloader_g, test_dataloader_g,\\\n",
    "    num_epochs=2000, split_freq=1, filename='../plots/spectral_bias/f0_E2000_phased_training',\\\n",
    "    save=save, order='first', nmse=True)\n",
    "plot_losses(train_losses, test_losses, save_dir='../plots/spectral_bias', filename='f0_E2000_phased_training', save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using MSE instead of NMSE for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics are: 67.76434707641602, 2515.4547526041665, and 359.87697347005206\n",
      "Epoch [1/2000], Train Loss: 143.5308, Test Loss: 132.8331\n",
      "The metrics are: 7.21807066599528, 51.83710861206055, and 77.6314926147461\n",
      "Epoch [2/2000], Train Loss: 143.9456, Test Loss: 38.3470\n",
      "The metrics are: 4.737960497538249, 29.7270991007487, and 48.9631462097168\n",
      "Epoch [3/2000], Train Loss: 148.0793, Test Loss: 24.5107\n",
      "The metrics are: 3.6069489320119223, 20.603495279947918, and 35.29757817586263\n",
      "Epoch [4/2000], Train Loss: 147.1393, Test Loss: 18.0428\n",
      "The metrics are: 3.134800831476847, 16.692273139953613, and 29.65964635213216\n",
      "Epoch [5/2000], Train Loss: 147.8933, Test Loss: 15.4108\n",
      "The metrics are: 2.9550161361694336, 15.251157760620117, and 27.29354413350423\n",
      "Epoch [6/2000], Train Loss: 149.5857, Test Loss: 14.1970\n",
      "The metrics are: 2.900189161300659, 14.669439315795898, and 26.831218719482422\n",
      "Epoch [7/2000], Train Loss: 150.3215, Test Loss: 14.0647\n",
      "The metrics are: 2.8945343494415283, 14.639824867248535, and 26.73215166727702\n",
      "Epoch [8/2000], Train Loss: 150.9133, Test Loss: 14.0343\n",
      "The metrics are: 2.8699002265930176, 14.46886952718099, and 26.313648859659832\n",
      "Epoch [9/2000], Train Loss: 150.3716, Test Loss: 13.7968\n",
      "The metrics are: 2.830970605214437, 14.16128412882487, and 25.661897659301758\n",
      "Epoch [10/2000], Train Loss: 148.5328, Test Loss: 13.3737\n",
      "The metrics are: 2.8517030080159507, 14.220815976460775, and 25.981496810913086\n",
      "Epoch [11/2000], Train Loss: 150.3350, Test Loss: 13.5848\n",
      "The metrics are: 2.8479809761047363, 14.257984479268393, and 25.76378122965495\n",
      "Epoch [12/2000], Train Loss: 150.3773, Test Loss: 13.4593\n",
      "The metrics are: 2.8137025833129883, 14.001697222391764, and 25.084959665934246\n",
      "Epoch [13/2000], Train Loss: 149.9774, Test Loss: 13.0110\n",
      "The metrics are: 2.8254545529683432, 13.968997637430826, and 25.256556193033855\n",
      "Epoch [14/2000], Train Loss: 149.2642, Test Loss: 13.1916\n",
      "The metrics are: 2.78260604540507, 13.765388488769531, and 24.268937428792317\n",
      "Epoch [15/2000], Train Loss: 146.8639, Test Loss: 12.5318\n",
      "The metrics are: 2.803496519724528, 13.73094113667806, and 24.51293690999349\n",
      "Epoch [16/2000], Train Loss: 146.2574, Test Loss: 12.7479\n",
      "The metrics are: 2.7644553979237876, 13.504116376241049, and 23.640928904215496\n",
      "Epoch [17/2000], Train Loss: 145.7167, Test Loss: 12.2472\n",
      "The metrics are: 2.7583951155344644, 13.277036348978678, and 23.431968053181965\n",
      "Epoch [18/2000], Train Loss: 146.1216, Test Loss: 12.2002\n",
      "The metrics are: 2.733752727508545, 13.073329289754232, and 22.73528544108073\n",
      "Epoch [19/2000], Train Loss: 141.9549, Test Loss: 11.8252\n",
      "The metrics are: 2.739556153615316, 13.02490202585856, and 22.386698404947918\n",
      "Epoch [20/2000], Train Loss: 140.6410, Test Loss: 11.6529\n",
      "The metrics are: 2.753838062286377, 13.059688250223795, and 21.866796493530273\n",
      "Epoch [21/2000], Train Loss: 139.2765, Test Loss: 11.3377\n",
      "The metrics are: 2.718834559122721, 12.539358456929525, and 21.171248118082683\n",
      "Epoch [22/2000], Train Loss: 137.3292, Test Loss: 11.0966\n",
      "The metrics are: 2.7945600350697837, 13.02128823598226, and 20.751834869384766\n",
      "Epoch [23/2000], Train Loss: 136.2883, Test Loss: 10.7450\n",
      "The metrics are: 2.8258341948191323, 12.768684069315592, and 20.18324089050293\n",
      "Epoch [24/2000], Train Loss: 134.0631, Test Loss: 10.4858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The metrics are: 2.893608013788859, 12.911405881245932, and 19.50047429402669\n",
      "Epoch [25/2000], Train Loss: 130.4098, Test Loss: 10.2231\n",
      "The metrics are: 2.96793802579244, 12.842650095621744, and 18.638694763183594\n",
      "Epoch [26/2000], Train Loss: 126.3994, Test Loss: 10.0322\n",
      "The metrics are: 3.2862680753072104, 13.715038299560547, and 18.106032689412434\n",
      "Epoch [27/2000], Train Loss: 124.2795, Test Loss: 10.0898\n",
      "The metrics are: 3.286524852116903, 12.352684338887533, and 16.168738683064777\n",
      "Epoch [28/2000], Train Loss: 115.5057, Test Loss: 10.0704\n",
      "The metrics are: 3.2755469481150308, 10.891847928365072, and 13.361158688863119\n",
      "Epoch [29/2000], Train Loss: 108.3926, Test Loss: 9.3364\n",
      "The metrics are: 3.143996477127075, 8.87634531656901, and 10.1432523727417\n",
      "Epoch [30/2000], Train Loss: 98.5416, Test Loss: 7.7220\n",
      "The metrics are: 2.8217102686564126, 6.654412428538005, and 7.2952728271484375\n",
      "Epoch [31/2000], Train Loss: 91.3347, Test Loss: 5.9124\n",
      "The metrics are: 2.444009780883789, 4.736306985219319, and 4.901674747467041\n",
      "Epoch [32/2000], Train Loss: 80.4782, Test Loss: 4.0593\n",
      "The metrics are: 2.1246397495269775, 3.375403642654419, and 3.47577436765035\n",
      "Epoch [33/2000], Train Loss: 70.8459, Test Loss: 2.9774\n",
      "The metrics are: 1.682777206103007, 2.2846553325653076, and 2.314324378967285\n",
      "Epoch [34/2000], Train Loss: 60.2840, Test Loss: 2.0041\n",
      "The metrics are: 1.1958819230397542, 1.4990782737731934, and 1.5097802082697551\n",
      "Epoch [35/2000], Train Loss: 51.0678, Test Loss: 1.2990\n",
      "The metrics are: 0.7924161752065023, 0.9492407639821371, and 0.9570209582646688\n",
      "Epoch [36/2000], Train Loss: 41.5846, Test Loss: 0.8129\n",
      "The metrics are: 0.5085143744945526, 0.5766549110412598, and 0.5876457889874777\n",
      "Epoch [37/2000], Train Loss: 33.2508, Test Loss: 0.4891\n",
      "The metrics are: 0.3531101544698079, 0.35126522183418274, and 0.36475472648938495\n",
      "Epoch [38/2000], Train Loss: 24.5563, Test Loss: 0.3021\n",
      "The metrics are: 0.26170042157173157, 0.22224244475364685, and 0.23463453849156699\n",
      "Epoch [39/2000], Train Loss: 18.9881, Test Loss: 0.1923\n",
      "The metrics are: 0.2026676138242086, 0.14437354604403177, and 0.15619038542111716\n",
      "Epoch [40/2000], Train Loss: 14.0779, Test Loss: 0.1266\n",
      "The metrics are: 0.16633198658625284, 0.09703479210535686, and 0.10721205174922943\n",
      "Epoch [41/2000], Train Loss: 10.8800, Test Loss: 0.0864\n",
      "The metrics are: 0.14205661912759146, 0.06904094914595287, and 0.07785971214373906\n",
      "Epoch [42/2000], Train Loss: 8.1769, Test Loss: 0.0629\n",
      "The metrics are: 0.128193328777949, 0.05243870864311854, and 0.05966237187385559\n",
      "Epoch [43/2000], Train Loss: 6.7370, Test Loss: 0.0489\n",
      "The metrics are: 0.12086960176626842, 0.042615762601296105, and 0.048250955839951835\n",
      "Epoch [44/2000], Train Loss: 5.6371, Test Loss: 0.0405\n",
      "The metrics are: 0.11873816947142284, 0.036565493792295456, and 0.041532800843318306\n",
      "Epoch [45/2000], Train Loss: 4.9618, Test Loss: 0.0362\n",
      "The metrics are: 0.12684960663318634, 0.032987319553891815, and 0.037918321788311005\n",
      "Epoch [46/2000], Train Loss: 4.4677, Test Loss: 0.0367\n",
      "The metrics are: 0.13397938013076782, 0.030435460930069286, and 0.03791270156701406\n",
      "Epoch [47/2000], Train Loss: 4.2987, Test Loss: 0.0413\n",
      "The metrics are: 0.12599357217550278, 0.028548468525211017, and 0.033889499182502426\n",
      "Epoch [48/2000], Train Loss: 4.5394, Test Loss: 0.0380\n",
      "The metrics are: 0.11038226634263992, 0.027787520239750545, and 0.0289923461774985\n",
      "Epoch [49/2000], Train Loss: 4.2336, Test Loss: 0.0278\n",
      "The metrics are: 0.10982302327950795, 0.026132329056660335, and 0.027236069242159527\n",
      "Epoch [50/2000], Train Loss: 3.6804, Test Loss: 0.0258\n",
      "The metrics are: 0.10943609476089478, 0.02520664967596531, and 0.02605418488383293\n",
      "Epoch [51/2000], Train Loss: 3.6028, Test Loss: 0.0250\n",
      "The metrics are: 0.1092446967959404, 0.024575333421428997, and 0.02510642136136691\n",
      "Epoch [52/2000], Train Loss: 3.4232, Test Loss: 0.0244\n",
      "The metrics are: 0.10912970701853435, 0.02407827538748582, and 0.024349639813105266\n",
      "Epoch [53/2000], Train Loss: 3.4464, Test Loss: 0.0239\n",
      "The metrics are: 0.10882588227589925, 0.023646850759784382, and 0.023696817457675934\n",
      "Epoch [54/2000], Train Loss: 3.3445, Test Loss: 0.0235\n",
      "The metrics are: 0.1087818443775177, 0.023254561548431713, and 0.023092464233438175\n",
      "Epoch [55/2000], Train Loss: 3.2440, Test Loss: 0.0232\n",
      "The metrics are: 0.10855300972859065, 0.022938338418801624, and 0.022635186091065407\n",
      "Epoch [56/2000], Train Loss: 3.2585, Test Loss: 0.0229\n",
      "The metrics are: 0.10866604497035344, 0.02264588139951229, and 0.022160798932115238\n",
      "Epoch [57/2000], Train Loss: 3.2498, Test Loss: 0.0227\n",
      "The metrics are: 0.10834993918736775, 0.02240621546904246, and 0.021856512874364853\n",
      "Epoch [58/2000], Train Loss: 3.1222, Test Loss: 0.0225\n",
      "The metrics are: 0.10828094184398651, 0.022166689857840538, and 0.021391605337460835\n",
      "Epoch [59/2000], Train Loss: 3.1433, Test Loss: 0.0222\n",
      "The metrics are: 0.1078698883454005, 0.021939049785335858, and 0.021082287654280663\n",
      "Epoch [60/2000], Train Loss: 3.0954, Test Loss: 0.0220\n",
      "The metrics are: 0.1081265111764272, 0.02173881232738495, and 0.02074330175916354\n",
      "Epoch [61/2000], Train Loss: 3.0753, Test Loss: 0.0218\n",
      "The metrics are: 0.10788041104873021, 0.021578022589286167, and 0.020639482885599136\n",
      "Epoch [62/2000], Train Loss: 3.0922, Test Loss: 0.0219\n",
      "The metrics are: 0.1091727614402771, 0.0214226171374321, and 0.02034633109966914\n",
      "Epoch [63/2000], Train Loss: 3.0888, Test Loss: 0.0220\n",
      "The metrics are: 0.10969122499227524, 0.021263826017578442, and 0.020667307699720066\n",
      "Epoch [64/2000], Train Loss: 3.0128, Test Loss: 0.0228\n",
      "The metrics are: 0.11789607008298238, 0.021285141507784527, and 0.021301588664452236\n",
      "Epoch [65/2000], Train Loss: 3.0137, Test Loss: 0.0253\n",
      "The metrics are: 0.1246776853998502, 0.02129214194913705, and 0.023687082653244335\n",
      "Epoch [66/2000], Train Loss: 3.1607, Test Loss: 0.0308\n",
      "The metrics are: 0.1524903525908788, 0.021634689221779507, and 0.028316868469119072\n",
      "Epoch [67/2000], Train Loss: 3.4580, Test Loss: 0.0441\n",
      "The metrics are: 0.11046436429023743, 0.02244037203490734, and 0.02208550771077474\n",
      "Epoch [68/2000], Train Loss: 4.0913, Test Loss: 0.0292\n",
      "The metrics are: 0.10600994775692622, 0.021373098095258076, and 0.01913161699970563\n",
      "Epoch [69/2000], Train Loss: 3.3140, Test Loss: 0.0212\n",
      "The metrics are: 0.1068691611289978, 0.0205929030974706, and 0.018769921734929085\n",
      "Epoch [70/2000], Train Loss: 2.8621, Test Loss: 0.0205\n",
      "The metrics are: 0.10514423747857411, 0.02026168319086234, and 0.01848838695635398\n",
      "Epoch [71/2000], Train Loss: 2.8485, Test Loss: 0.0202\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m set_seed(seed)\n\u001b[1;32m      2\u001b[0m L3ModelK3_low \u001b[38;5;241m=\u001b[39m SimpleCNN(n_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL3ModelK3_low\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../plots/spectral_bias/f0_E2000_phased_training\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnmse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m plot_losses(train_losses, test_losses, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../plots/spectral_bias\u001b[39m\u001b[38;5;124m'\u001b[39m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf0_E2000_phased_training\u001b[39m\u001b[38;5;124m'\u001b[39m, save\u001b[38;5;241m=\u001b[39msave)\n",
      "Cell \u001b[0;32mIn[19], line 38\u001b[0m, in \u001b[0;36mmodel_training\u001b[0;34m(model, train_dataloader, test_dataloader, num_epochs, split_freq, filename, save, order, nmse)\u001b[0m\n\u001b[1;32m     35\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion2(outputs, batch_derivatives, nmse\u001b[38;5;241m=\u001b[39mnmse)\n\u001b[1;32m     37\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 38\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     40\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Conda/sciml2/lib/python3.9/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Conda/sciml2/lib/python3.9/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "L3ModelK3_low = SimpleCNN(n_layers=3, kernel_size=3)\n",
    "\n",
    "train_losses, test_losses = model_training(L3ModelK3_low, train_dataloader_g, test_dataloader_g,\\\n",
    "    num_epochs=2000, split_freq=1, filename='../plots/spectral_bias/f0_E2000_phased_training',\\\n",
    "    save=save, order='first', nmse=False)\n",
    "plot_losses(train_losses, test_losses, save_dir='../plots/spectral_bias', filename='f0_E2000_phased_training', save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IGNORE BELOW, 9/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- Does training on high freq data lead to better performance on low freq data, or vice-versa? I.e., is the performance delta larger or smaller? \n",
    "    - Yes: training on high freq data leads to a smaller performance gap on the low freq data than vice-versa.\n",
    "    - However, training on the general freq dataset leads to the best performance overall, **but there is a an opposite bias for some reason: high freq data has lower NMSE than low freq data, which is counterintuitive**\n",
    "    - And, the general freq NMSE is almost identical to the high freq NMSE\n",
    "- Need to plot the heatmap over epochs\n",
    "- Is this happening because the **MSE** is larger for high freq data and therefore learning that better?\n",
    "- Does changing the model architecture (layers or kernel size) change this bias?\n",
    "- Can \"fine-tuning\" a model that was trained on high freq data with low freq data lead to better performance than just training on general freq?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
