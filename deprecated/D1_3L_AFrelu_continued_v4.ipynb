{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training continued learning with learning rate scheduler, 7/30\n",
    "\n",
    "First derivative, 3-layer CNN, relu activation, multistage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import heapq\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = True\n",
    "cluster = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset using the second derivative instead of the first\n",
    "\n",
    "The code currently loads a previously created dataset instead of creating a new one each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierSeriesDataset(Dataset):\n",
    "    def __init__(self, num_samples, num_points, max_terms=10):\n",
    "        self.num_samples = num_samples\n",
    "        self.num_points = num_points\n",
    "        self.max_terms = max_terms\n",
    "        self.x = torch.linspace(0, 2*np.pi, num_points, requires_grad=True)\n",
    "        self.functions, self.first_derivatives, self.second_derivatives = self.generate_data()\n",
    "\n",
    "    def generate_data(self):\n",
    "        functions = []\n",
    "        first_derivatives = []\n",
    "        second_derivatives = []\n",
    "\n",
    "        for _ in range(self.num_samples):\n",
    "            # Generate random complex coefficients\n",
    "            n_terms = np.random.randint(1, self.max_terms + 1)\n",
    "            c = torch.complex(torch.randn(2*n_terms+1), torch.randn(2*n_terms+1))\n",
    "\n",
    "            # Compute function values\n",
    "            y = self.complex_fourier_series(self.x, c)\n",
    "            functions.append(y.detach().numpy())\n",
    "\n",
    "            # Compute derivative\n",
    "            dy_dx = torch.autograd.grad(y, self.x, grad_outputs=torch.ones_like(y), create_graph=True)[0]\n",
    "            first_derivatives.append(dy_dx.detach().numpy())\n",
    "\n",
    "            d2y_dx2 = torch.autograd.grad(outputs=dy_dx, inputs=self.x, grad_outputs=torch.ones_like(dy_dx), create_graph=True)[0]\n",
    "            second_derivatives.append(d2y_dx2.detach().numpy())\n",
    "\n",
    "        return np.array(functions), np.array(first_derivatives), np.array(second_derivatives)\n",
    "\n",
    "    def complex_fourier_series(self, x, c, P=2*np.pi):\n",
    "        result = torch.zeros_like(x, dtype=torch.complex64)\n",
    "        n_terms = (len(c) - 1) // 2\n",
    "        for n in range(-n_terms, n_terms+1):\n",
    "            result += c[n + len(c)//2] * torch.exp(1j * 2 * np.pi * n * x / P)\n",
    "        return result.real\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.functions[idx]), torch.FloatTensor(self.first_derivatives[idx]), torch.FloatTensor(self.second_derivatives[idx])\n",
    "\n",
    "# Generate dataset\n",
    "num_samples = 10000\n",
    "num_points = 1000\n",
    "\n",
    "# Uncomment below to create dataset\n",
    "# dataset = FourierSeriesDataset(num_samples, num_points)\n",
    "\n",
    "# batch_size = 32\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "# torch.save(dataset, 'datasets/both_derivatives_dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load previously saved dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.load('datasets/both_derivatives_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "test_size = total_size - train_size\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size], generator=generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataloader))\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_function_and_derivative(dataloader):\n",
    "    # Get a single sample from the dataloader\n",
    "    dataiter = iter(dataloader)\n",
    "    function, derivative, second_derivative = next(dataiter)\n",
    "\n",
    "    # Since we're dealing with batches, let's take the first item in the batch\n",
    "    function = function[0].numpy()\n",
    "    derivative = derivative[0].numpy()\n",
    "    second_derivative = second_derivative[0].numpy()\n",
    "\n",
    "    # Create x-axis values (assuming the domain is [0, 2Ï€])\n",
    "    x = torch.linspace(0, 2*torch.pi, len(function)).numpy()\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(x, function, label='Function', color='blue')\n",
    "    plt.plot(x, derivative, label='First Derivative', linestyle='--')\n",
    "    plt.plot(x, second_derivative, label='Second Derivative', color='red', linestyle='--')\n",
    "    \n",
    "    plt.title('Fourier Series Function and its Second Derivative')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have already created your dataset and dataloader as before\n",
    "# dataset = FourierSeriesDataset(num_samples, num_points)\n",
    "\n",
    "def get_random_function(dataset, shuffle=True):\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=shuffle)\n",
    "\n",
    "train_dataloader_viz = get_random_function(dataset=train_dataset, shuffle=False)\n",
    "plot_function_and_derivative(train_dataloader_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This version of the CNN uses three layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple 1D CNN\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(64, 1, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "model1 = SimpleCNN()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use model from cluster, use\n",
    "model1.load_state_dict(torch.load('models/E1000_D1_3L_AFrelu_1S.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(epoch):\n",
    "    if epoch < 1000:\n",
    "        return 1.0  # Keep initial learning rate as 0.001\n",
    "    elif 1000 <= epoch < 1100:\n",
    "        # Increase LR from 0.001 to 0.1 over 100 epochs\n",
    "        return 1 + (99 * (epoch - 1000) / 99)\n",
    "    else:\n",
    "        return 100.0  # After epoch 1100, maintain LR at 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = [], []\n",
    "\n",
    "def model_training(model, num_epochs, lr_factor=1, order=None):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "\n",
    "    lr = 1e-3 / lr_factor\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        test_loss = 0.0\n",
    "\n",
    "        for batch_functions, batch_derivatives, _ in train_dataloader:\n",
    "            # Reshape input: [batch_size, 1, num_points]\n",
    "            batch_functions = batch_functions.unsqueeze(1)\n",
    "            batch_derivatives = batch_derivatives.unsqueeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_functions)\n",
    "            loss = criterion(outputs, batch_derivatives)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_dataloader)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for b_test_functions, b_test_derivatives, _ in test_dataloader:\n",
    "                b_test_functions = b_test_functions.unsqueeze(1)\n",
    "                b_test_derivatives = b_test_derivatives.unsqueeze(1)\n",
    "\n",
    "                test_outputs = model(b_test_functions)\n",
    "                batch_test_loss = criterion(test_outputs, b_test_derivatives)\n",
    "\n",
    "                test_loss += batch_test_loss.item()\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "    \n",
    "    print(f\"Training finished for {order}st derivative\")\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Uncomment below to train and save the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, test_losses = model_training(model1, 2000, order='first')\n",
    "torch.save(model1.state_dict(), 'models/E2000_D1_3L_AFrelu_1S_continued.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, test_losses, save_dir='plots', filename=None, save=False):\n",
    "    if not train_losses:\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, train_losses, linestyle='-', color='b', label='Training Loss')\n",
    "    plt.plot(epochs, test_losses, linestyle='-', label='Test Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.yscale('log')  # Set the y-axis to logarithmic scale\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_losses(train_losses=train_losses, test_losses=test_losses,\\\n",
    "    save_dir='plots/continued', filename='D1_3L_AFrelu_1S_loss', save=save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output(model1, order=None, save_dir='plots', filename=None, save=False): \n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "    model1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    train_dataloader_viz = get_random_function(dataset=train_dataset, shuffle=True)\n",
    "    # Get a random sample from the dataloader\n",
    "    dataiter = iter(train_dataloader_viz)\n",
    "    function, true_derivative, true_second_derivative = next(dataiter)\n",
    "\n",
    "    # Reshape the input for the model\n",
    "    function = function.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        if order == 1 or order == 2:\n",
    "            predicted_derivative = model1(function)\n",
    "        \n",
    "        if order == 'rollout':\n",
    "            predicted_derivative = model1(function)\n",
    "            predicted_derivative = model1(predicted_derivative)\n",
    "\n",
    "    # Convert tensors to numpy arrays for plotting\n",
    "    x = torch.linspace(0, 2*torch.pi, 1000).numpy()\n",
    "    function = function.squeeze().numpy()\n",
    "\n",
    "    predicted_derivative = predicted_derivative.squeeze().numpy()\n",
    "\n",
    "    true_derivative = true_derivative.squeeze().numpy()\n",
    "    true_second_derivative = true_second_derivative.squeeze().numpy()\n",
    "\n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.plot(x, function, label='Original Function', color='blue')\n",
    "    if order == 1:\n",
    "        plt.plot(x, true_derivative, label=f'True {order}st derivative')\n",
    "    if order == 2:\n",
    "        plt.plot(x, true_second_derivative, label=f'True {order}nd derivative')\n",
    "\n",
    "    plt.plot(x[10:-10], predicted_derivative[10:-10], label=f'Predicted {order}nd Derivative', linestyle='--')\n",
    "\n",
    "    plt.title('Function, True Derivatives, and Predicted Derivatives')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    filename = f\"{filename}_{current_date}.png\"\n",
    "\n",
    "    save_path = os.path.join(save_dir, filename)\n",
    "    if save:\n",
    "        plt.savefig(save_path)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_output(model1, order=1, save_dir='plots/continued', filename='D1_3L_AFrelu_1S_output', save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate accuracy (MSE)\n",
    "\n",
    "MSE is computed as: $\\frac{1}{n} \\sum (y-f(x))^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_combined_output(model1, model2, function_input, true_derivative):\n",
    "    # Predict the derivative from the first model\n",
    "    output = model1(function_input)\n",
    "\n",
    "    # Compute the residual and root mean squared error\n",
    "    residual = output.squeeze() - true_derivative\n",
    "    rms = torch.sqrt(torch.mean(residual**2))\n",
    "\n",
    "    # Predict the derivative from the second model\n",
    "    output2 = model2(function_input)\n",
    "\n",
    "    # Calculate the combined model output\n",
    "    combined_model_output = output + rms * output2\n",
    "\n",
    "    return combined_model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(dataloader, model):\n",
    "    \"\"\"\n",
    "    Takes in a dataloader and a model to compute MSE.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    for function, deriv, _ in dataloader:\n",
    "        function = function.unsqueeze(1)\n",
    "        deriv = deriv.unsqueeze(1)\n",
    "\n",
    "        # Compute model output\n",
    "        model_output = model(function)\n",
    "        all_targets.append(deriv)\n",
    "\n",
    "        # Collect outputs\n",
    "        all_outputs.append(model_output)\n",
    "\n",
    "    # Concatenate all collected outputs and targets\n",
    "    all_outputs = torch.cat(all_outputs, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "\n",
    "    # Compute MSE\n",
    "    mse = torch.mean((all_targets - all_outputs) ** 2)\n",
    "    nmse = mse / torch.mean(all_targets ** 2)\n",
    "\n",
    "    return mse.item(), nmse.item()\n",
    "\n",
    "print(f\"MSE over all test functions: {compute_mse(train_dataloader, model1)[0]}\")\n",
    "print(f\"NMSE over all test functions: {compute_mse(train_dataloader, model1)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized MSE\n",
    "\n",
    "NMSE is computed as: $\\frac{1}{n} \\frac{\\sum (y-f(x))^2}{\\sum y^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral biases from Fourier Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_median_frequency(function):\n",
    "    fft_coeffs = np.fft.fft(function)\n",
    "    freqs = np.fft.fftfreq(len(function))\n",
    "    power_spectrum = np.abs(fft_coeffs)**2\n",
    "    significant_freqs = freqs[power_spectrum > (np.max(power_spectrum) * 0.01)]\n",
    "    return np.median(np.abs(significant_freqs))\n",
    "\n",
    "def categorize_functions(dataloader):\n",
    "    functions_with_freqs = []\n",
    "    \n",
    "    for functions, derivatives, sec_derivative in dataloader:\n",
    "        for idx, function in enumerate(functions):\n",
    "            median_frequency = calculate_median_frequency(function.numpy())\n",
    "            functions_with_freqs.append((function.numpy(), derivatives[idx].numpy(), sec_derivative[idx].numpy(), median_frequency))\n",
    "    \n",
    "    # Sort by median frequency\n",
    "    functions_with_freqs.sort(key=lambda x: x[3])\n",
    "    \n",
    "    # Split into low and high frequency datasets\n",
    "    mid_index = len(functions_with_freqs) // 2\n",
    "    low_freq_dataset = functions_with_freqs[:mid_index]\n",
    "    high_freq_dataset = functions_with_freqs[mid_index:]\n",
    "    \n",
    "    # Create new DataLoaders, excluding the median frequency from the data\n",
    "    # Each dataloader contains the function, deriv, and second deriv\n",
    "    low_freq_dataloader = [(f[0], f[1], f[2]) for f in low_freq_dataset]\n",
    "    high_freq_dataloader = [(f[0], f[1], f[2]) for f in high_freq_dataset]\n",
    "    \n",
    "    return low_freq_dataloader, high_freq_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the test dataset to compute frequencies\n",
    "# Should be half of full dataset in each dataloader\n",
    "low_freq_dataset, high_freq_dataset = categorize_functions(test_dataloader)\n",
    "\n",
    "print(f\"Low frequency dataset size: {len(low_freq_dataset)}\")\n",
    "print(f\"High frequency dataset size: {len(high_freq_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_freq_dataloader = DataLoader(low_freq_dataset, batch_size=32, shuffle=True)\n",
    "high_freq_dataloader = DataLoader(high_freq_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE over low freq functions: {compute_mse(low_freq_dataloader, model1)[0]}\")\n",
    "print(f\"NMSE over low freq functions: {compute_mse(low_freq_dataloader, model1)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"MSE over high freq functions: {compute_mse(high_freq_dataloader, model1)[0]}\")\n",
    "print(f\"NMSE over high freq functions: {compute_mse(high_freq_dataloader, model1)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference(model1, dataset, save_dir='plots', filename=None, save=False):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model1.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "    current_date = datetime.now().strftime(\"%m-%d\")\n",
    "\n",
    "    def plot_sliced(x, y, label, linestyle='-'):\n",
    "        plt.plot(x[10:-10], y[10:-10], label=label, linestyle=linestyle)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))  # Adjust figure size for a 2x2 grid\n",
    "    \n",
    "    for i in range(1, 5):  # Loop over four different functions\n",
    "        train_dataloader_viz = get_random_function(dataset, shuffle=True)\n",
    "        dataiter = iter(train_dataloader_viz)\n",
    "        function, true_derivative, true_second_derivative = next(dataiter)\n",
    "\n",
    "        function = function.unsqueeze(1)  # Add channel dimension\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            predicted_derivative = model1(function)\n",
    "            first_deriv_diff = true_derivative - predicted_derivative\n",
    "\n",
    "            predicted_second_derivative = model1(predicted_derivative)\n",
    "            second_deriv_diff = true_second_derivative - predicted_second_derivative\n",
    "\n",
    "        # Convert tensors to numpy arrays for plotting\n",
    "        x = torch.linspace(0, 2*torch.pi, 1000).numpy()\n",
    "        function = function.squeeze().numpy()\n",
    "        true_derivative = true_derivative.squeeze().numpy()\n",
    "        true_second_derivative = true_second_derivative.squeeze().numpy()\n",
    "        \n",
    "        first_deriv_diff = first_deriv_diff.squeeze().numpy()\n",
    "        second_deriv_diff = second_deriv_diff.squeeze().numpy()\n",
    "\n",
    "        plt.subplot(2, 2, i)  # Adjust subplot position\n",
    "        plot_sliced(x, function, '$u$')\n",
    "        plot_sliced(x, first_deriv_diff, \"$u'_g - u'_{\\\\theta}$\", linestyle='--')\n",
    "        # plot_sliced(x, true_derivative, \"$u'_g$\")\n",
    "        # plot_sliced(x, true_second_derivative, \"$u''_g$\", linestyle='--')\n",
    "\n",
    "        plt.title(f'Difference for Function {i}')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        mse = np.mean((first_deriv_diff) ** 2)\n",
    "        nmse = mse / np.mean(true_derivative ** 2)\n",
    "\n",
    "        print(f\"MSE for function {i} is: {mse}\")        \n",
    "        print(f\"NMSE for function {i} is: {nmse}\\n\")        \n",
    "    \n",
    "    if save:\n",
    "        filename = f\"{filename}_{current_date}.png\"\n",
    "        save_path = os.path.join(save_dir, filename if filename else 'multi_plot.png')\n",
    "        plt.savefig(save_path)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sciml2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
